2015-07-05 06:31:03,537 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-07-05 06:31:03,543 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-07-05 06:31:03,887 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-07-05 06:31:04,023 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-07-05 06:31:04,088 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-07-05 06:31:04,088 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-07-05 06:31:04,290 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/liyaohui/hadoop/tmp/dfs/namesecondary/in_use.lock acquired by nodename 11547@ubuntu01
2015-07-05 06:31:04,323 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2015-07-05 06:31:04,324 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2015-07-05 06:31:04,326 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-07-05 06:31:04,328 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-07-05 06:31:04,329 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-07-05 06:31:04,329 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2015-07-05 06:31:04,329 INFO org.apache.hadoop.util.GSet: capacity      = 2^22 = 4194304 entries
2015-07-05 06:31:04,354 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-07-05 06:31:04,355 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-07-05 06:31:04,355 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-07-05 06:31:04,355 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-07-05 06:31:04,355 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-07-05 06:31:04,355 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-07-05 06:31:04,355 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-07-05 06:31:04,355 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-07-05 06:31:04,355 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = liyaohui (auth:SIMPLE)
2015-07-05 06:31:04,356 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-07-05 06:31:04,356 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-07-05 06:31:04,356 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-07-05 06:31:04,358 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-07-05 06:31:04,545 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-07-05 06:31:04,545 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-07-05 06:31:04,545 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2015-07-05 06:31:04,545 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-07-05 06:31:04,619 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-07-05 06:31:04,623 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-07-05 06:31:04,623 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-07-05 06:31:04,623 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-07-05 06:31:04,657 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-07-05 06:31:04,707 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-07-05 06:31:04,708 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-07-05 06:31:04,709 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-07-05 06:31:04,709 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-07-05 06:31:04,718 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50090
2015-07-05 06:31:04,718 INFO org.mortbay.log: jetty-6.1.26
2015-07-05 06:31:04,963 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50090
2015-07-05 06:31:04,963 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-07-05 06:31:04,963 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Secondary Web-server up at: 0.0.0.0:50090
2015-07-05 06:31:04,963 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-07-05 06:31:04,963 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-07-05 06:31:34,539 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-07-05 06:31:34,541 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at ubuntu01/127.0.1.1
************************************************************/
2015-07-15 10:59:47,375 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-07-15 10:59:47,393 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-07-15 10:59:47,742 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-07-15 10:59:47,882 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-07-15 10:59:47,947 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-07-15 10:59:47,947 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-07-15 10:59:48,167 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/liyaohui/hadoop/tmp/dfs/namesecondary/in_use.lock acquired by nodename 3876@ubuntu01
2015-07-15 10:59:48,201 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2015-07-15 10:59:48,201 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2015-07-15 10:59:48,203 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-07-15 10:59:48,206 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-07-15 10:59:48,206 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-07-15 10:59:48,207 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2015-07-15 10:59:48,207 INFO org.apache.hadoop.util.GSet: capacity      = 2^22 = 4194304 entries
2015-07-15 10:59:48,231 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-07-15 10:59:48,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-07-15 10:59:48,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-07-15 10:59:48,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-07-15 10:59:48,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-07-15 10:59:48,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-07-15 10:59:48,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-07-15 10:59:48,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-07-15 10:59:48,233 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = liyaohui (auth:SIMPLE)
2015-07-15 10:59:48,233 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-07-15 10:59:48,233 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-07-15 10:59:48,233 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-07-15 10:59:48,235 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-07-15 10:59:48,421 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-07-15 10:59:48,421 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-07-15 10:59:48,421 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2015-07-15 10:59:48,421 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-07-15 10:59:48,497 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-07-15 10:59:48,501 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-07-15 10:59:48,501 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-07-15 10:59:48,501 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-07-15 10:59:48,536 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-07-15 10:59:48,585 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-07-15 10:59:48,587 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-07-15 10:59:48,587 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-07-15 10:59:48,587 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-07-15 10:59:48,596 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50090
2015-07-15 10:59:48,596 INFO org.mortbay.log: jetty-6.1.26
2015-07-15 10:59:48,836 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50090
2015-07-15 10:59:48,836 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-07-15 10:59:48,836 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Secondary Web-server up at: 0.0.0.0:50090
2015-07-15 10:59:48,836 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-07-15 10:59:48,836 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-07-15 11:00:49,088 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-07-15 11:00:49,091 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getimage=1&txid=1&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 11:00:49,205 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.11s at 0.00 KB/s
2015-07-15 11:00:49,206 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000001 size 200 bytes.
2015-07-15 11:00:49,237 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=2&endTxId=3&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 11:00:49,258 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 0.00 KB/s
2015-07-15 11:00:49,258 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000002-0000000000000000003_0000001436929249237 size 0 bytes.
2015-07-15 11:00:49,281 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000000001 using no compression
2015-07-15 11:00:49,281 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 1
2015-07-15 11:00:49,286 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2015-07-15 11:00:49,286 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000000001 of size 200 bytes loaded in 0 seconds.
2015-07-15 11:00:49,286 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 1 from /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000000001
2015-07-15 11:00:49,286 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-07-15 11:00:49,293 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-07-15 11:00:49,297 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000000002-0000000000000000003 expecting start txid #2
2015-07-15 11:00:49,297 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000000002-0000000000000000003
2015-07-15 11:00:49,314 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000000002-0000000000000000003 of size 30 edits # 2 loaded in 0 seconds
2015-07-15 11:00:49,322 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000000003 using no compression
2015-07-15 11:00:49,359 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000000003 of size 200 bytes saved in 0 seconds.
2015-07-15 11:00:49,392 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /home/liyaohui/hadoop/tmp/dfs/namesecondary
2015-07-15 11:00:49,432 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=3&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 11:00:49,601 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.17s at 0.00 KB/s
2015-07-15 11:00:49,601 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3 to namenode at ubuntu01:50070
2015-07-15 11:00:49,601 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 200
2015-07-15 12:00:50,023 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-07-15 12:00:50,023 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=4&endTxId=3009&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 12:00:50,073 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 6469.39 KB/s
2015-07-15 12:00:50,073 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000004-0000000000000003009_0000001436932850023 size 0 bytes.
2015-07-15 12:00:50,074 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-07-15 12:00:50,074 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000000004-0000000000000003009 expecting start txid #4
2015-07-15 12:00:50,074 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000000004-0000000000000003009
2015-07-15 12:00:50,243 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000000004-0000000000000003009 of size 325626 edits # 3006 loaded in 0 seconds
2015-07-15 12:00:50,246 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000003009 using no compression
2015-07-15 12:00:50,287 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000003009 of size 64940 bytes saved in 0 seconds.
2015-07-15 12:00:50,320 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3
2015-07-15 12:00:50,320 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000000001, cpktTxId=0000000000000000001)
2015-07-15 12:00:50,334 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=3009&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 12:00:50,425 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.09s at 0.00 KB/s
2015-07-15 12:00:50,425 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3009 to namenode at ubuntu01:50070
2015-07-15 12:00:50,425 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 64940
2015-07-15 13:00:50,848 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-07-15 13:00:50,848 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=3010&endTxId=3011&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 13:00:50,876 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-07-15 13:00:50,876 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003010-0000000000000003011_0000001436936450848 size 0 bytes.
2015-07-15 13:00:50,877 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-07-15 13:00:50,877 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000003010-0000000000000003011 expecting start txid #3010
2015-07-15 13:00:50,877 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000003010-0000000000000003011
2015-07-15 13:00:50,877 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000003010-0000000000000003011 of size 30 edits # 2 loaded in 0 seconds
2015-07-15 13:00:50,878 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000003011 using no compression
2015-07-15 13:00:50,918 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000003011 of size 64940 bytes saved in 0 seconds.
2015-07-15 13:00:50,949 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3009
2015-07-15 13:00:50,949 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000000003, cpktTxId=0000000000000000003)
2015-07-15 13:00:50,956 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=3011&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 13:00:51,034 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.08s at 0.00 KB/s
2015-07-15 13:00:51,034 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3011 to namenode at ubuntu01:50070
2015-07-15 13:00:51,034 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 64940
2015-07-15 14:00:51,430 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-07-15 14:00:51,430 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=3012&endTxId=3013&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 14:00:51,460 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-07-15 14:00:51,460 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003012-0000000000000003013_0000001436940051430 size 0 bytes.
2015-07-15 14:00:51,460 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-07-15 14:00:51,461 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000003012-0000000000000003013 expecting start txid #3012
2015-07-15 14:00:51,461 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000003012-0000000000000003013
2015-07-15 14:00:51,461 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000003012-0000000000000003013 of size 30 edits # 2 loaded in 0 seconds
2015-07-15 14:00:51,462 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000003013 using no compression
2015-07-15 14:00:51,491 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000003013 of size 64940 bytes saved in 0 seconds.
2015-07-15 14:00:51,523 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3011
2015-07-15 14:00:51,523 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000003009, cpktTxId=0000000000000003009)
2015-07-15 14:00:51,538 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=3013&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 14:00:51,606 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.07s at 0.00 KB/s
2015-07-15 14:00:51,606 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3013 to namenode at ubuntu01:50070
2015-07-15 14:00:51,606 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 64940
2015-07-15 14:22:37,021 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-07-15 14:22:37,024 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at ubuntu01/127.0.1.1
************************************************************/
2015-07-15 14:27:57,243 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-07-15 14:27:57,249 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-07-15 14:27:57,588 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-07-15 14:27:57,723 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-07-15 14:27:57,788 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-07-15 14:27:57,788 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-07-15 14:27:58,019 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/liyaohui/hadoop/tmp/dfs/namesecondary/in_use.lock acquired by nodename 10250@ubuntu01
2015-07-15 14:27:58,083 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2015-07-15 14:27:58,083 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2015-07-15 14:27:58,086 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-07-15 14:27:58,088 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-07-15 14:27:58,088 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-07-15 14:27:58,089 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2015-07-15 14:27:58,089 INFO org.apache.hadoop.util.GSet: capacity      = 2^22 = 4194304 entries
2015-07-15 14:27:58,116 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-07-15 14:27:58,116 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-07-15 14:27:58,116 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-07-15 14:27:58,116 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-07-15 14:27:58,116 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-07-15 14:27:58,116 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-07-15 14:27:58,117 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-07-15 14:27:58,117 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-07-15 14:27:58,117 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = liyaohui (auth:SIMPLE)
2015-07-15 14:27:58,117 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-07-15 14:27:58,117 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-07-15 14:27:58,117 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-07-15 14:27:58,119 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-07-15 14:27:58,298 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-07-15 14:27:58,298 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-07-15 14:27:58,298 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2015-07-15 14:27:58,298 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-07-15 14:27:58,371 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-07-15 14:27:58,375 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-07-15 14:27:58,375 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-07-15 14:27:58,375 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-07-15 14:27:58,410 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-07-15 14:27:58,459 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-07-15 14:27:58,461 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-07-15 14:27:58,461 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-07-15 14:27:58,461 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-07-15 14:27:58,470 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50090
2015-07-15 14:27:58,470 INFO org.mortbay.log: jetty-6.1.26
2015-07-15 14:27:58,756 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50090
2015-07-15 14:27:58,757 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-07-15 14:27:58,757 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Secondary Web-server up at: 0.0.0.0:50090
2015-07-15 14:27:58,757 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-07-15 14:27:58,757 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-07-15 14:28:59,030 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-07-15 14:28:59,035 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getimage=1&txid=3013&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 14:28:59,185 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.15s at 420.00 KB/s
2015-07-15 14:28:59,185 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000003013 size 64940 bytes.
2015-07-15 14:28:59,217 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=3014&endTxId=3014&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 14:28:59,278 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.06s at 16786.89 KB/s
2015-07-15 14:28:59,278 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003014-0000000000000003014_0000001436941739216 size 0 bytes.
2015-07-15 14:28:59,279 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=3015&endTxId=3016&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 14:28:59,309 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-07-15 14:28:59,309 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003015-0000000000000003016_0000001436941739278 size 0 bytes.
2015-07-15 14:28:59,324 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000003013 using no compression
2015-07-15 14:28:59,324 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 604
2015-07-15 14:28:59,361 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2015-07-15 14:28:59,361 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000003013 of size 64940 bytes loaded in 0 seconds.
2015-07-15 14:28:59,361 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 3013 from /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000003013
2015-07-15 14:28:59,361 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 3 entries 45 lookups
2015-07-15 14:28:59,368 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2015-07-15 14:28:59,372 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000003014-0000000000000003014 expecting start txid #3014
2015-07-15 14:28:59,372 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000003014-0000000000000003014
2015-07-15 14:28:59,391 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000003014-0000000000000003014 of size 1048576 edits # 1 loaded in 0 seconds
2015-07-15 14:28:59,391 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000003015-0000000000000003016 expecting start txid #3015
2015-07-15 14:28:59,391 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000003015-0000000000000003016
2015-07-15 14:28:59,391 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000003015-0000000000000003016 of size 30 edits # 2 loaded in 0 seconds
2015-07-15 14:28:59,398 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000003016 using no compression
2015-07-15 14:28:59,452 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000003016 of size 64940 bytes saved in 0 seconds.
2015-07-15 14:28:59,485 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3013
2015-07-15 14:28:59,485 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000003011, cpktTxId=0000000000000003011)
2015-07-15 14:28:59,505 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=3016&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 14:28:59,683 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.18s at 0.00 KB/s
2015-07-15 14:28:59,683 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3016 to namenode at ubuntu01:50070
2015-07-15 14:28:59,684 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 64940
2015-07-15 15:29:00,221 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-07-15 15:29:00,221 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=3017&endTxId=3019&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 15:29:00,267 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 0.00 KB/s
2015-07-15 15:29:00,267 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003017-0000000000000003019_0000001436945340221 size 0 bytes.
2015-07-15 15:29:00,268 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-07-15 15:29:00,268 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000003017-0000000000000003019 expecting start txid #3017
2015-07-15 15:29:00,268 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000003017-0000000000000003019
2015-07-15 15:29:00,271 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000003017-0000000000000003019 of size 68 edits # 3 loaded in 0 seconds
2015-07-15 15:29:00,272 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000003019 using no compression
2015-07-15 15:29:00,308 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000003019 of size 64940 bytes saved in 0 seconds.
2015-07-15 15:29:00,340 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3016
2015-07-15 15:29:00,340 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000003013, cpktTxId=0000000000000003013)
2015-07-15 15:29:00,350 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=3019&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 15:29:00,436 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.09s at 0.00 KB/s
2015-07-15 15:29:00,436 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3019 to namenode at ubuntu01:50070
2015-07-15 15:29:00,436 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 64940
2015-07-15 16:29:00,827 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-07-15 16:29:00,835 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=3020&endTxId=3127&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 16:29:00,878 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 255.81 KB/s
2015-07-15 16:29:00,878 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003020-0000000000000003127_0000001436948940835 size 0 bytes.
2015-07-15 16:29:00,878 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-07-15 16:29:00,878 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000003020-0000000000000003127 expecting start txid #3020
2015-07-15 16:29:00,878 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000003020-0000000000000003127
2015-07-15 16:29:00,895 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000003020-0000000000000003127 of size 12181 edits # 108 loaded in 0 seconds
2015-07-15 16:29:00,896 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000003127 using no compression
2015-07-15 16:29:00,929 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000003127 of size 66857 bytes saved in 0 seconds.
2015-07-15 16:29:00,960 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3019
2015-07-15 16:29:00,961 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000003016, cpktTxId=0000000000000003016)
2015-07-15 16:29:00,972 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=3127&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 16:29:01,046 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.07s at 0.00 KB/s
2015-07-15 16:29:01,046 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 3127 to namenode at ubuntu01:50070
2015-07-15 16:29:01,046 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 66857
2015-07-15 17:29:01,483 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-07-15 17:29:01,483 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=3128&endTxId=4227&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 17:29:01,513 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 4724.14 KB/s
2015-07-15 17:29:01,513 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000003128-0000000000000004227_0000001436952541483 size 0 bytes.
2015-07-15 17:29:01,513 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-07-15 17:29:01,513 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000003128-0000000000000004227 expecting start txid #3128
2015-07-15 17:29:01,513 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000003128-0000000000000004227
2015-07-15 17:29:01,587 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000003128-0000000000000004227 of size 141187 edits # 1100 loaded in 0 seconds
2015-07-15 17:29:01,589 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004227 using no compression
2015-07-15 17:29:01,625 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004227 of size 78851 bytes saved in 0 seconds.
2015-07-15 17:29:01,657 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3127
2015-07-15 17:29:01,657 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000003019, cpktTxId=0000000000000003019)
2015-07-15 17:29:01,666 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=4227&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 17:29:01,741 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.08s at 0.00 KB/s
2015-07-15 17:29:01,741 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 4227 to namenode at ubuntu01:50070
2015-07-15 17:29:01,741 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 78851
2015-07-15 18:29:02,129 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-07-15 18:29:02,130 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=4228&endTxId=4229&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 18:29:02,169 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 0.00 KB/s
2015-07-15 18:29:02,169 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000004228-0000000000000004229_0000001436956142130 size 0 bytes.
2015-07-15 18:29:02,170 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-07-15 18:29:02,170 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004228-0000000000000004229 expecting start txid #4228
2015-07-15 18:29:02,170 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004228-0000000000000004229
2015-07-15 18:29:02,170 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004228-0000000000000004229 of size 30 edits # 2 loaded in 0 seconds
2015-07-15 18:29:02,171 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004229 using no compression
2015-07-15 18:29:02,211 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004229 of size 78851 bytes saved in 0 seconds.
2015-07-15 18:29:02,242 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4227
2015-07-15 18:29:02,242 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000003127, cpktTxId=0000000000000003127)
2015-07-15 18:29:02,257 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=4229&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 18:29:02,336 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.08s at 0.00 KB/s
2015-07-15 18:29:02,336 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 4229 to namenode at ubuntu01:50070
2015-07-15 18:29:02,337 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 78851
2015-07-15 19:29:02,691 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-07-15 19:29:02,692 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=4230&endTxId=4234&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 19:29:02,731 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 0.00 KB/s
2015-07-15 19:29:02,731 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000004230-0000000000000004234_0000001436959742692 size 0 bytes.
2015-07-15 19:29:02,731 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-07-15 19:29:02,731 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004230-0000000000000004234 expecting start txid #4230
2015-07-15 19:29:02,732 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004230-0000000000000004234
2015-07-15 19:29:02,732 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004230-0000000000000004234 of size 262 edits # 5 loaded in 0 seconds
2015-07-15 19:29:02,733 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004234 using no compression
2015-07-15 19:29:02,772 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004234 of size 78851 bytes saved in 0 seconds.
2015-07-15 19:29:02,804 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4229
2015-07-15 19:29:02,804 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004227, cpktTxId=0000000000000004227)
2015-07-15 19:29:02,819 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=4234&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 19:29:02,898 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.08s at 0.00 KB/s
2015-07-15 19:29:02,898 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 4234 to namenode at ubuntu01:50070
2015-07-15 19:29:02,898 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 78851
2015-07-15 20:29:03,262 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-07-15 20:29:03,262 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=4235&endTxId=4236&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 20:29:03,292 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-07-15 20:29:03,292 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000004235-0000000000000004236_0000001436963343262 size 0 bytes.
2015-07-15 20:29:03,293 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-07-15 20:29:03,293 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004235-0000000000000004236 expecting start txid #4235
2015-07-15 20:29:03,293 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004235-0000000000000004236
2015-07-15 20:29:03,293 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004235-0000000000000004236 of size 30 edits # 2 loaded in 0 seconds
2015-07-15 20:29:03,296 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004236 using no compression
2015-07-15 20:29:03,323 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004236 of size 78851 bytes saved in 0 seconds.
2015-07-15 20:29:03,354 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4234
2015-07-15 20:29:03,355 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004229, cpktTxId=0000000000000004229)
2015-07-15 20:29:03,370 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=4236&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 20:29:03,449 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.08s at 0.00 KB/s
2015-07-15 20:29:03,449 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 4236 to namenode at ubuntu01:50070
2015-07-15 20:29:03,449 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 78851
2015-07-15 21:29:03,811 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-07-15 21:29:03,811 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=4237&endTxId=4238&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 21:29:03,866 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 0.00 KB/s
2015-07-15 21:29:03,866 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000004237-0000000000000004238_0000001436966943811 size 0 bytes.
2015-07-15 21:29:03,866 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-07-15 21:29:03,866 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004237-0000000000000004238 expecting start txid #4237
2015-07-15 21:29:03,872 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004237-0000000000000004238
2015-07-15 21:29:03,873 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004237-0000000000000004238 of size 30 edits # 2 loaded in 0 seconds
2015-07-15 21:29:03,873 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004238 using no compression
2015-07-15 21:29:03,907 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004238 of size 78851 bytes saved in 0 seconds.
2015-07-15 21:29:03,938 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4236
2015-07-15 21:29:03,938 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004234, cpktTxId=0000000000000004234)
2015-07-15 21:29:03,952 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=4238&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 21:29:04,023 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.07s at 0.00 KB/s
2015-07-15 21:29:04,023 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 4238 to namenode at ubuntu01:50070
2015-07-15 21:29:04,023 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 78851
2015-07-15 22:29:04,390 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-07-15 22:29:04,391 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=4239&endTxId=4240&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 22:29:04,420 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-07-15 22:29:04,421 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000004239-0000000000000004240_0000001436970544391 size 0 bytes.
2015-07-15 22:29:04,421 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-07-15 22:29:04,421 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004239-0000000000000004240 expecting start txid #4239
2015-07-15 22:29:04,421 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004239-0000000000000004240
2015-07-15 22:29:04,421 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004239-0000000000000004240 of size 30 edits # 2 loaded in 0 seconds
2015-07-15 22:29:04,422 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004240 using no compression
2015-07-15 22:29:04,451 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004240 of size 78851 bytes saved in 0 seconds.
2015-07-15 22:29:04,483 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4238
2015-07-15 22:29:04,483 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004236, cpktTxId=0000000000000004236)
2015-07-15 22:29:04,492 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=4240&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 22:29:04,579 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.09s at 0.00 KB/s
2015-07-15 22:29:04,579 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 4240 to namenode at ubuntu01:50070
2015-07-15 22:29:04,579 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 78851
2015-07-15 22:31:41,971 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-07-15 22:31:41,974 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at ubuntu01/127.0.1.1
************************************************************/
2015-07-17 21:56:32,160 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-07-17 21:56:32,189 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-07-17 21:56:32,539 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-07-17 21:56:32,681 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-07-17 21:56:32,751 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-07-17 21:56:32,751 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-07-17 21:56:32,983 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/liyaohui/hadoop/tmp/dfs/namesecondary/in_use.lock acquired by nodename 6638@ubuntu01
2015-07-17 21:56:33,059 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2015-07-17 21:56:33,059 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2015-07-17 21:56:33,062 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-07-17 21:56:33,065 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-07-17 21:56:33,065 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-07-17 21:56:33,066 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2015-07-17 21:56:33,066 INFO org.apache.hadoop.util.GSet: capacity      = 2^22 = 4194304 entries
2015-07-17 21:56:33,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-07-17 21:56:33,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-07-17 21:56:33,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-07-17 21:56:33,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-07-17 21:56:33,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-07-17 21:56:33,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-07-17 21:56:33,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-07-17 21:56:33,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-07-17 21:56:33,092 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = liyaohui (auth:SIMPLE)
2015-07-17 21:56:33,092 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-07-17 21:56:33,092 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-07-17 21:56:33,092 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-07-17 21:56:33,094 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-07-17 21:56:33,277 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-07-17 21:56:33,277 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-07-17 21:56:33,277 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2015-07-17 21:56:33,277 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-07-17 21:56:33,351 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-07-17 21:56:33,355 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-07-17 21:56:33,355 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-07-17 21:56:33,355 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-07-17 21:56:33,391 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-07-17 21:56:33,443 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-07-17 21:56:33,445 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-07-17 21:56:33,445 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-07-17 21:56:33,445 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-07-17 21:56:33,455 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50090
2015-07-17 21:56:33,455 INFO org.mortbay.log: jetty-6.1.26
2015-07-17 21:56:33,753 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50090
2015-07-17 21:56:33,753 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-07-17 21:56:33,753 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Secondary Web-server up at: 0.0.0.0:50090
2015-07-17 21:56:33,753 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-07-17 21:56:33,753 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-07-17 21:57:34,043 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-07-17 21:57:34,046 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getimage=1&txid=4241&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-17 21:57:34,253 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.21s at 373.79 KB/s
2015-07-17 21:57:34,253 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000004241 size 78851 bytes.
2015-07-17 21:57:34,285 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=4242&endTxId=4243&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-17 21:57:34,315 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-07-17 21:57:34,315 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000004242-0000000000000004243_0000001437141454284 size 0 bytes.
2015-07-17 21:57:34,330 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004241 using no compression
2015-07-17 21:57:34,330 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 721
2015-07-17 21:57:34,366 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2015-07-17 21:57:34,366 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004241 of size 78851 bytes loaded in 0 seconds.
2015-07-17 21:57:34,366 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 4241 from /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004241
2015-07-17 21:57:34,366 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 6 entries 81 lookups
2015-07-17 21:57:34,372 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-07-17 21:57:34,375 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004242-0000000000000004243 expecting start txid #4242
2015-07-17 21:57:34,376 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004242-0000000000000004243
2015-07-17 21:57:34,390 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004242-0000000000000004243 of size 30 edits # 2 loaded in 0 seconds
2015-07-17 21:57:34,397 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004243 using no compression
2015-07-17 21:57:34,448 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004243 of size 78851 bytes saved in 0 seconds.
2015-07-17 21:57:34,481 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4241
2015-07-17 21:57:34,481 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004238, cpktTxId=0000000000000004238)
2015-07-17 21:57:34,482 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004240, cpktTxId=0000000000000004240)
2015-07-17 21:57:34,504 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=4243&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-17 21:57:34,677 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.17s at 0.00 KB/s
2015-07-17 21:57:34,677 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 4243 to namenode at ubuntu01:50070
2015-07-17 21:57:34,677 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 78851
2015-07-17 22:15:55,000 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-07-17 22:15:55,002 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at ubuntu01/127.0.1.1
************************************************************/
2015-07-27 15:30:56,427 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-07-27 15:30:56,460 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-07-27 15:30:56,802 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-07-27 15:30:56,939 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-07-27 15:30:57,003 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-07-27 15:30:57,003 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-07-27 15:30:57,225 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/liyaohui/hadoop/tmp/dfs/namesecondary/in_use.lock acquired by nodename 3171@ubuntu01
2015-07-27 15:30:57,297 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2015-07-27 15:30:57,297 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2015-07-27 15:30:57,300 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-07-27 15:30:57,303 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-07-27 15:30:57,303 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-07-27 15:30:57,303 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2015-07-27 15:30:57,303 INFO org.apache.hadoop.util.GSet: capacity      = 2^22 = 4194304 entries
2015-07-27 15:30:57,330 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-07-27 15:30:57,331 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-07-27 15:30:57,331 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-07-27 15:30:57,331 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-07-27 15:30:57,331 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-07-27 15:30:57,331 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-07-27 15:30:57,331 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-07-27 15:30:57,331 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-07-27 15:30:57,332 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = liyaohui (auth:SIMPLE)
2015-07-27 15:30:57,332 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-07-27 15:30:57,332 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-07-27 15:30:57,332 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-07-27 15:30:57,334 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-07-27 15:30:57,517 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-07-27 15:30:57,518 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-07-27 15:30:57,518 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2015-07-27 15:30:57,518 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-07-27 15:30:57,590 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-07-27 15:30:57,594 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-07-27 15:30:57,594 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-07-27 15:30:57,594 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-07-27 15:30:57,629 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-07-27 15:30:57,678 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-07-27 15:30:57,680 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-07-27 15:30:57,680 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-07-27 15:30:57,680 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-07-27 15:30:57,690 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50090
2015-07-27 15:30:57,690 INFO org.mortbay.log: jetty-6.1.26
2015-07-27 15:30:57,995 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50090
2015-07-27 15:30:57,995 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-07-27 15:30:57,996 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Secondary Web-server up at: 0.0.0.0:50090
2015-07-27 15:30:57,996 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-07-27 15:30:57,996 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-07-27 15:31:58,299 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-07-27 15:31:58,303 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getimage=1&txid=4244&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-27 15:31:58,486 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.18s at 423.08 KB/s
2015-07-27 15:31:58,486 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000004244 size 78851 bytes.
2015-07-27 15:31:58,518 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=4245&endTxId=4246&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-27 15:31:58,548 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-07-27 15:31:58,549 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000004245-0000000000000004246_0000001437982318518 size 0 bytes.
2015-07-27 15:31:58,563 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004244 using no compression
2015-07-27 15:31:58,564 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 721
2015-07-27 15:31:58,612 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2015-07-27 15:31:58,613 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004244 of size 78851 bytes loaded in 0 seconds.
2015-07-27 15:31:58,613 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 4244 from /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004244
2015-07-27 15:31:58,613 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 6 entries 81 lookups
2015-07-27 15:31:58,619 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-07-27 15:31:58,623 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004245-0000000000000004246 expecting start txid #4245
2015-07-27 15:31:58,623 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004245-0000000000000004246
2015-07-27 15:31:58,638 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004245-0000000000000004246 of size 30 edits # 2 loaded in 0 seconds
2015-07-27 15:31:58,646 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004246 using no compression
2015-07-27 15:31:58,702 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004246 of size 78851 bytes saved in 0 seconds.
2015-07-27 15:31:58,747 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4244
2015-07-27 15:31:58,747 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004243, cpktTxId=0000000000000004243)
2015-07-27 15:31:58,747 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004241, cpktTxId=0000000000000004241)
2015-07-27 15:31:58,764 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=4246&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-27 15:31:58,943 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.18s at 0.00 KB/s
2015-07-27 15:31:58,943 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 4246 to namenode at ubuntu01:50070
2015-07-27 15:31:58,943 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 78851
2015-07-27 16:31:59,503 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-07-27 16:31:59,504 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=4247&endTxId=4249&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-27 16:31:59,532 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-07-27 16:31:59,532 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000004247-0000000000000004249_0000001437985919504 size 0 bytes.
2015-07-27 16:31:59,534 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-07-27 16:31:59,534 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004247-0000000000000004249 expecting start txid #4247
2015-07-27 16:31:59,534 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004247-0000000000000004249
2015-07-27 16:31:59,537 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004247-0000000000000004249 of size 88 edits # 3 loaded in 0 seconds
2015-07-27 16:31:59,540 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004249 using no compression
2015-07-27 16:31:59,575 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004249 of size 78851 bytes saved in 0 seconds.
2015-07-27 16:31:59,606 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4246
2015-07-27 16:31:59,607 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004244, cpktTxId=0000000000000004244)
2015-07-27 16:31:59,619 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=4249&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-27 16:31:59,692 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.07s at 0.00 KB/s
2015-07-27 16:31:59,692 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 4249 to namenode at ubuntu01:50070
2015-07-27 16:31:59,692 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 78851
2015-07-27 17:32:00,134 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-07-27 17:32:00,135 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=4250&endTxId=4281&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-27 17:32:00,175 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 50.00 KB/s
2015-07-27 17:32:00,175 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000004250-0000000000000004281_0000001437989520135 size 0 bytes.
2015-07-27 17:32:00,175 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-07-27 17:32:00,175 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004250-0000000000000004281 expecting start txid #4250
2015-07-27 17:32:00,175 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004250-0000000000000004281
2015-07-27 17:32:00,184 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004250-0000000000000004281 of size 2751 edits # 32 loaded in 0 seconds
2015-07-27 17:32:00,185 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004281 using no compression
2015-07-27 17:32:00,216 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004281 of size 79436 bytes saved in 0 seconds.
2015-07-27 17:32:00,247 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4249
2015-07-27 17:32:00,247 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004246, cpktTxId=0000000000000004246)
2015-07-27 17:32:00,260 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=4281&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-27 17:32:00,343 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.08s at 0.00 KB/s
2015-07-27 17:32:00,343 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 4281 to namenode at ubuntu01:50070
2015-07-27 17:32:00,343 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 79436
2015-07-27 18:32:00,780 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-07-27 18:32:00,780 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=4282&endTxId=4284&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-27 18:32:00,811 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-07-27 18:32:00,811 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000004282-0000000000000004284_0000001437993120780 size 0 bytes.
2015-07-27 18:32:00,811 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-07-27 18:32:00,811 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004282-0000000000000004284 expecting start txid #4282
2015-07-27 18:32:00,811 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004282-0000000000000004284
2015-07-27 18:32:00,812 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004282-0000000000000004284 of size 88 edits # 3 loaded in 0 seconds
2015-07-27 18:32:00,813 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004284 using no compression
2015-07-27 18:32:00,842 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004284 of size 79436 bytes saved in 0 seconds.
2015-07-27 18:32:00,873 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4281
2015-07-27 18:32:00,873 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004249, cpktTxId=0000000000000004249)
2015-07-27 18:32:00,882 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=4284&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-27 18:32:00,958 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.08s at 0.00 KB/s
2015-07-27 18:32:00,958 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 4284 to namenode at ubuntu01:50070
2015-07-27 18:32:00,958 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 79436
2015-07-27 19:32:01,370 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-07-27 19:32:01,370 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=4285&endTxId=4286&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-27 19:32:01,400 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-07-27 19:32:01,400 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000004285-0000000000000004286_0000001437996721370 size 0 bytes.
2015-07-27 19:32:01,400 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-07-27 19:32:01,400 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004285-0000000000000004286 expecting start txid #4285
2015-07-27 19:32:01,400 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004285-0000000000000004286
2015-07-27 19:32:01,400 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004285-0000000000000004286 of size 30 edits # 2 loaded in 0 seconds
2015-07-27 19:32:01,404 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004286 using no compression
2015-07-27 19:32:01,441 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004286 of size 79436 bytes saved in 0 seconds.
2015-07-27 19:32:01,472 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4284
2015-07-27 19:32:01,472 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004281, cpktTxId=0000000000000004281)
2015-07-27 19:32:01,484 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=4286&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-27 19:32:01,547 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.06s at 0.00 KB/s
2015-07-27 19:32:01,547 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 4286 to namenode at ubuntu01:50070
2015-07-27 19:32:01,548 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 79436
2015-07-27 20:32:01,912 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-07-27 20:32:01,913 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=4287&endTxId=4288&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-27 20:32:01,942 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-07-27 20:32:01,942 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000004287-0000000000000004288_0000001438000321912 size 0 bytes.
2015-07-27 20:32:01,943 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-07-27 20:32:01,943 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004287-0000000000000004288 expecting start txid #4287
2015-07-27 20:32:01,943 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004287-0000000000000004288
2015-07-27 20:32:01,943 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004287-0000000000000004288 of size 30 edits # 2 loaded in 0 seconds
2015-07-27 20:32:01,944 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004288 using no compression
2015-07-27 20:32:01,973 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004288 of size 79436 bytes saved in 0 seconds.
2015-07-27 20:32:02,005 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4286
2015-07-27 20:32:02,005 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004284, cpktTxId=0000000000000004284)
2015-07-27 20:32:02,014 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=4288&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-27 20:32:02,089 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.08s at 0.00 KB/s
2015-07-27 20:32:02,090 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 4288 to namenode at ubuntu01:50070
2015-07-27 20:32:02,090 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 79436
2015-07-27 21:32:02,464 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-07-27 21:32:02,464 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=4289&endTxId=4290&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-27 21:32:02,494 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-07-27 21:32:02,494 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000004289-0000000000000004290_0000001438003922464 size 0 bytes.
2015-07-27 21:32:02,494 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-07-27 21:32:02,494 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004289-0000000000000004290 expecting start txid #4289
2015-07-27 21:32:02,494 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004289-0000000000000004290
2015-07-27 21:32:02,495 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004289-0000000000000004290 of size 30 edits # 2 loaded in 0 seconds
2015-07-27 21:32:02,495 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004290 using no compression
2015-07-27 21:32:02,525 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004290 of size 79436 bytes saved in 0 seconds.
2015-07-27 21:32:02,556 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4288
2015-07-27 21:32:02,557 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004286, cpktTxId=0000000000000004286)
2015-07-27 21:32:02,574 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=4290&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-27 21:32:02,651 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.08s at 0.00 KB/s
2015-07-27 21:32:02,651 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 4290 to namenode at ubuntu01:50070
2015-07-27 21:32:02,651 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 79436
2015-07-27 21:50:55,724 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-07-27 21:50:55,730 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at ubuntu01/127.0.1.1
************************************************************/
2015-08-25 16:42:49,930 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-08-25 16:42:49,955 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-08-25 16:42:50,315 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-08-25 16:42:50,454 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-08-25 16:42:50,524 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-08-25 16:42:50,524 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-08-25 16:42:50,759 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/liyaohui/hadoop/tmp/dfs/namesecondary/in_use.lock acquired by nodename 2802@ubuntu01
2015-08-25 16:42:50,839 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2015-08-25 16:42:50,839 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2015-08-25 16:42:50,842 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-08-25 16:42:50,845 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-08-25 16:42:50,845 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-08-25 16:42:50,845 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2015-08-25 16:42:50,845 INFO org.apache.hadoop.util.GSet: capacity      = 2^22 = 4194304 entries
2015-08-25 16:42:50,870 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-08-25 16:42:50,870 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-08-25 16:42:50,870 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-08-25 16:42:50,870 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-08-25 16:42:50,870 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-08-25 16:42:50,870 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-08-25 16:42:50,870 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-08-25 16:42:50,870 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-08-25 16:42:50,871 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = liyaohui (auth:SIMPLE)
2015-08-25 16:42:50,871 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-08-25 16:42:50,871 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-08-25 16:42:50,871 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-08-25 16:42:50,873 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-08-25 16:42:51,056 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-08-25 16:42:51,056 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-08-25 16:42:51,056 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2015-08-25 16:42:51,056 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-08-25 16:42:51,129 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-08-25 16:42:51,133 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-08-25 16:42:51,133 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-08-25 16:42:51,133 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-08-25 16:42:51,169 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-08-25 16:42:51,220 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-08-25 16:42:51,222 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-08-25 16:42:51,222 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-08-25 16:42:51,222 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-08-25 16:42:51,232 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50090
2015-08-25 16:42:51,232 INFO org.mortbay.log: jetty-6.1.26
2015-08-25 16:42:51,511 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50090
2015-08-25 16:42:51,511 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-08-25 16:42:51,511 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Secondary Web-server up at: 0.0.0.0:50090
2015-08-25 16:42:51,511 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-08-25 16:42:51,511 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-08-25 16:43:51,785 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-08-25 16:43:51,788 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getimage=1&txid=4291&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-08-25 16:43:51,936 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.15s at 523.81 KB/s
2015-08-25 16:43:51,936 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000004291 size 79436 bytes.
2015-08-25 16:43:51,968 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=4292&endTxId=4295&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-08-25 16:43:51,998 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-08-25 16:43:51,998 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000004292-0000000000000004295_0000001440492231968 size 0 bytes.
2015-08-25 16:43:52,013 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004291 using no compression
2015-08-25 16:43:52,013 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 727
2015-08-25 16:43:52,050 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2015-08-25 16:43:52,050 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004291 of size 79436 bytes loaded in 0 seconds.
2015-08-25 16:43:52,050 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 4291 from /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004291
2015-08-25 16:43:52,051 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 6 entries 83 lookups
2015-08-25 16:43:52,056 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-08-25 16:43:52,060 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004292-0000000000000004295 expecting start txid #4292
2015-08-25 16:43:52,060 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004292-0000000000000004295
2015-08-25 16:43:52,081 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004292-0000000000000004295 of size 173 edits # 4 loaded in 0 seconds
2015-08-25 16:43:52,087 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004295 using no compression
2015-08-25 16:43:52,141 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004295 of size 79436 bytes saved in 0 seconds.
2015-08-25 16:43:52,175 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4291
2015-08-25 16:43:52,175 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004290, cpktTxId=0000000000000004290)
2015-08-25 16:43:52,175 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004288, cpktTxId=0000000000000004288)
2015-08-25 16:43:52,192 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=4295&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-08-25 16:43:52,371 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.18s at 0.00 KB/s
2015-08-25 16:43:52,371 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 4295 to namenode at ubuntu01:50070
2015-08-25 16:43:52,371 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 79436
2015-08-25 17:43:52,820 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-08-25 17:43:52,820 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=4296&endTxId=4602&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-08-25 17:43:52,849 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 1275.86 KB/s
2015-08-25 17:43:52,849 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000004296-0000000000000004602_0000001440495832820 size 0 bytes.
2015-08-25 17:43:52,849 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-08-25 17:43:52,849 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004296-0000000000000004602 expecting start txid #4296
2015-08-25 17:43:52,849 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004296-0000000000000004602
2015-08-25 17:43:52,880 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004296-0000000000000004602 of size 38473 edits # 307 loaded in 0 seconds
2015-08-25 17:43:52,882 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004602 using no compression
2015-08-25 17:43:52,920 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004602 of size 75319 bytes saved in 0 seconds.
2015-08-25 17:43:52,963 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4295
2015-08-25 17:43:52,963 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004291, cpktTxId=0000000000000004291)
2015-08-25 17:43:52,976 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=4602&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-08-25 17:43:53,048 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.07s at 0.00 KB/s
2015-08-25 17:43:53,049 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 4602 to namenode at ubuntu01:50070
2015-08-25 17:43:53,049 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 75319
2015-08-25 18:43:53,461 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-08-25 18:43:53,461 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=4603&endTxId=4604&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-08-25 18:43:53,491 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-08-25 18:43:53,491 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000004603-0000000000000004604_0000001440499433461 size 0 bytes.
2015-08-25 18:43:53,491 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-08-25 18:43:53,491 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004603-0000000000000004604 expecting start txid #4603
2015-08-25 18:43:53,491 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004603-0000000000000004604
2015-08-25 18:43:53,491 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004603-0000000000000004604 of size 30 edits # 2 loaded in 0 seconds
2015-08-25 18:43:53,493 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004604 using no compression
2015-08-25 18:43:53,522 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004604 of size 75319 bytes saved in 0 seconds.
2015-08-25 18:43:53,553 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4602
2015-08-25 18:43:53,553 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004295, cpktTxId=0000000000000004295)
2015-08-25 18:43:53,568 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=4604&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-08-25 18:43:53,660 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.09s at 0.00 KB/s
2015-08-25 18:43:53,660 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 4604 to namenode at ubuntu01:50070
2015-08-25 18:43:53,660 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 75319
2015-08-25 19:43:54,083 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-08-25 19:43:54,083 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=4605&endTxId=4902&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-08-25 19:43:54,112 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 1285.71 KB/s
2015-08-25 19:43:54,113 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000004605-0000000000000004902_0000001440503034083 size 0 bytes.
2015-08-25 19:43:54,113 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-08-25 19:43:54,113 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004605-0000000000000004902 expecting start txid #4605
2015-08-25 19:43:54,113 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004605-0000000000000004902
2015-08-25 19:43:54,129 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004605-0000000000000004902 of size 37313 edits # 298 loaded in 0 seconds
2015-08-25 19:43:54,130 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004902 using no compression
2015-08-25 19:43:54,174 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004902 of size 76696 bytes saved in 0 seconds.
2015-08-25 19:43:54,206 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4604
2015-08-25 19:43:54,206 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004602, cpktTxId=0000000000000004602)
2015-08-25 19:43:54,220 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=4902&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-08-25 19:43:54,290 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.07s at 0.00 KB/s
2015-08-25 19:43:54,290 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 4902 to namenode at ubuntu01:50070
2015-08-25 19:43:54,290 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 76696
2015-08-25 19:55:00,179 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-08-25 19:55:00,184 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at ubuntu01/127.0.1.1
************************************************************/
2015-08-25 20:10:25,788 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-08-25 20:10:25,816 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-08-25 20:10:26,174 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-08-25 20:10:26,313 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-08-25 20:10:26,383 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-08-25 20:10:26,383 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-08-25 20:10:26,611 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/liyaohui/hadoop/tmp/dfs/namesecondary/in_use.lock acquired by nodename 3062@ubuntu01
2015-08-25 20:10:26,688 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2015-08-25 20:10:26,688 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2015-08-25 20:10:26,690 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-08-25 20:10:26,693 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-08-25 20:10:26,693 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-08-25 20:10:26,694 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2015-08-25 20:10:26,694 INFO org.apache.hadoop.util.GSet: capacity      = 2^22 = 4194304 entries
2015-08-25 20:10:26,717 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-08-25 20:10:26,718 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-08-25 20:10:26,718 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-08-25 20:10:26,718 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-08-25 20:10:26,718 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-08-25 20:10:26,718 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-08-25 20:10:26,718 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-08-25 20:10:26,718 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-08-25 20:10:26,719 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = liyaohui (auth:SIMPLE)
2015-08-25 20:10:26,719 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-08-25 20:10:26,719 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-08-25 20:10:26,719 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-08-25 20:10:26,721 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-08-25 20:10:26,904 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-08-25 20:10:26,904 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-08-25 20:10:26,905 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2015-08-25 20:10:26,905 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-08-25 20:10:26,978 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-08-25 20:10:26,982 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-08-25 20:10:26,982 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-08-25 20:10:26,982 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-08-25 20:10:27,041 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-08-25 20:10:27,092 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-08-25 20:10:27,094 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-08-25 20:10:27,094 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-08-25 20:10:27,094 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-08-25 20:10:27,103 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50090
2015-08-25 20:10:27,103 INFO org.mortbay.log: jetty-6.1.26
2015-08-25 20:10:27,388 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50090
2015-08-25 20:10:27,388 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-08-25 20:10:27,388 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Secondary Web-server up at: 0.0.0.0:50090
2015-08-25 20:10:27,388 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-08-25 20:10:27,388 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-08-25 20:11:27,648 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-08-25 20:11:27,651 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getimage=1&txid=4902&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-08-25 20:11:27,849 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.20s at 373.74 KB/s
2015-08-25 20:11:27,849 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000004902 size 76696 bytes.
2015-08-25 20:11:27,877 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=4903&endTxId=4968&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-08-25 20:11:27,933 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.06s at 18285.71 KB/s
2015-08-25 20:11:27,933 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000004903-0000000000000004968_0000001440504687876 size 0 bytes.
2015-08-25 20:11:27,934 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=4969&endTxId=4971&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-08-25 20:11:27,964 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-08-25 20:11:27,964 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000004969-0000000000000004971_0000001440504687934 size 0 bytes.
2015-08-25 20:11:27,978 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004902 using no compression
2015-08-25 20:11:27,978 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 689
2015-08-25 20:11:28,019 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2015-08-25 20:11:28,020 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004902 of size 76696 bytes loaded in 0 seconds.
2015-08-25 20:11:28,020 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 4902 from /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004902
2015-08-25 20:11:28,020 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 3 entries 45 lookups
2015-08-25 20:11:28,025 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2015-08-25 20:11:28,029 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004903-0000000000000004968 expecting start txid #4903
2015-08-25 20:11:28,029 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004903-0000000000000004968
2015-08-25 20:11:28,065 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004903-0000000000000004968 of size 1048576 edits # 66 loaded in 0 seconds
2015-08-25 20:11:28,065 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004969-0000000000000004971 expecting start txid #4969
2015-08-25 20:11:28,065 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004969-0000000000000004971
2015-08-25 20:11:28,065 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000004969-0000000000000004971 of size 108 edits # 3 loaded in 0 seconds
2015-08-25 20:11:28,072 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004971 using no compression
2015-08-25 20:11:28,117 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000004971 of size 77152 bytes saved in 0 seconds.
2015-08-25 20:11:28,151 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4902
2015-08-25 20:11:28,151 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004604, cpktTxId=0000000000000004604)
2015-08-25 20:11:28,174 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=4971&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-08-25 20:11:28,360 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.19s at 0.00 KB/s
2015-08-25 20:11:28,361 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 4971 to namenode at ubuntu01:50070
2015-08-25 20:11:28,361 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 77152
2015-08-25 20:14:58,746 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-08-25 20:14:58,748 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at ubuntu01/127.0.1.1
************************************************************/
2015-09-01 20:58:33,782 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-09-01 20:58:33,804 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-09-01 20:58:34,167 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-01 20:58:34,310 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-09-01 20:58:34,379 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-09-01 20:58:34,379 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-09-01 20:58:34,607 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/liyaohui/hadoop/tmp/dfs/namesecondary/in_use.lock acquired by nodename 3082@ubuntu01
2015-09-01 20:58:34,690 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2015-09-01 20:58:34,690 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2015-09-01 20:58:34,693 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-09-01 20:58:34,696 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-09-01 20:58:34,696 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-09-01 20:58:34,697 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2015-09-01 20:58:34,697 INFO org.apache.hadoop.util.GSet: capacity      = 2^22 = 4194304 entries
2015-09-01 20:58:34,722 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-09-01 20:58:34,722 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-09-01 20:58:34,722 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-09-01 20:58:34,722 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-09-01 20:58:34,722 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-09-01 20:58:34,722 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-09-01 20:58:34,722 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-09-01 20:58:34,722 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-09-01 20:58:34,723 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = liyaohui (auth:SIMPLE)
2015-09-01 20:58:34,723 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-09-01 20:58:34,723 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-09-01 20:58:34,723 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-09-01 20:58:34,725 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-09-01 20:58:34,909 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-09-01 20:58:34,909 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-09-01 20:58:34,909 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2015-09-01 20:58:34,909 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-09-01 20:58:34,984 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-09-01 20:58:34,989 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-09-01 20:58:34,989 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-09-01 20:58:34,989 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-09-01 20:58:35,025 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-09-01 20:58:35,075 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-09-01 20:58:35,077 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-09-01 20:58:35,077 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-09-01 20:58:35,077 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-09-01 20:58:35,087 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50090
2015-09-01 20:58:35,087 INFO org.mortbay.log: jetty-6.1.26
2015-09-01 20:58:35,397 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50090
2015-09-01 20:58:35,397 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-09-01 20:58:35,397 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Secondary Web-server up at: 0.0.0.0:50090
2015-09-01 20:58:35,397 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-09-01 20:58:35,397 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-09-01 20:59:35,692 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-09-01 20:59:35,695 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getimage=1&txid=5074&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-01 20:59:35,888 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.19s at 388.60 KB/s
2015-09-01 20:59:35,888 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000005074 size 77710 bytes.
2015-09-01 20:59:35,919 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=5075&endTxId=5076&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-01 20:59:35,950 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-09-01 20:59:35,950 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000005075-0000000000000005076_0000001441112375919 size 0 bytes.
2015-09-01 20:59:35,964 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000005074 using no compression
2015-09-01 20:59:35,964 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 696
2015-09-01 20:59:36,001 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2015-09-01 20:59:36,001 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000005074 of size 77710 bytes loaded in 0 seconds.
2015-09-01 20:59:36,001 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 5074 from /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000005074
2015-09-01 20:59:36,001 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 3 entries 45 lookups
2015-09-01 20:59:36,007 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-09-01 20:59:36,010 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005075-0000000000000005076 expecting start txid #5075
2015-09-01 20:59:36,011 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005075-0000000000000005076
2015-09-01 20:59:36,025 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005075-0000000000000005076 of size 30 edits # 2 loaded in 0 seconds
2015-09-01 20:59:36,032 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000005076 using no compression
2015-09-01 20:59:36,083 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000005076 of size 77710 bytes saved in 0 seconds.
2015-09-01 20:59:36,116 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5074
2015-09-01 20:59:36,116 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004971, cpktTxId=0000000000000004971)
2015-09-01 20:59:36,117 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000004902, cpktTxId=0000000000000004902)
2015-09-01 20:59:36,142 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=5076&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-01 20:59:36,313 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.17s at 0.00 KB/s
2015-09-01 20:59:36,313 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 5076 to namenode at ubuntu01:50070
2015-09-01 20:59:36,313 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 77710
2015-09-01 21:59:36,764 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-09-01 21:59:36,764 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=5077&endTxId=5079&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-01 21:59:36,793 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-09-01 21:59:36,793 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000005077-0000000000000005079_0000001441115976764 size 0 bytes.
2015-09-01 21:59:36,793 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-09-01 21:59:36,793 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005077-0000000000000005079 expecting start txid #5077
2015-09-01 21:59:36,794 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005077-0000000000000005079
2015-09-01 21:59:36,796 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005077-0000000000000005079 of size 80 edits # 3 loaded in 0 seconds
2015-09-01 21:59:36,798 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000005079 using no compression
2015-09-01 21:59:36,844 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000005079 of size 77710 bytes saved in 0 seconds.
2015-09-01 21:59:36,866 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5076
2015-09-01 21:59:36,866 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000005074, cpktTxId=0000000000000005074)
2015-09-01 21:59:36,875 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=5079&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-01 21:59:36,964 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.09s at 0.00 KB/s
2015-09-01 21:59:36,964 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 5079 to namenode at ubuntu01:50070
2015-09-01 21:59:36,964 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 77710
2015-09-01 22:30:14,239 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-09-01 22:30:14,241 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at ubuntu01/127.0.1.1
************************************************************/
2015-09-01 22:33:04,221 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-09-01 22:33:04,230 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-09-01 22:33:04,581 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-01 22:33:04,727 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-09-01 22:33:04,790 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-09-01 22:33:04,790 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-09-01 22:33:04,992 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/liyaohui/hadoop/tmp/dfs/namesecondary/in_use.lock acquired by nodename 7033@ubuntu01
2015-09-01 22:33:05,053 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2015-09-01 22:33:05,053 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2015-09-01 22:33:05,056 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-09-01 22:33:05,058 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-09-01 22:33:05,058 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-09-01 22:33:05,059 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2015-09-01 22:33:05,059 INFO org.apache.hadoop.util.GSet: capacity      = 2^22 = 4194304 entries
2015-09-01 22:33:05,085 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-09-01 22:33:05,085 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-09-01 22:33:05,085 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-09-01 22:33:05,085 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-09-01 22:33:05,085 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-09-01 22:33:05,085 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-09-01 22:33:05,085 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-09-01 22:33:05,085 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-09-01 22:33:05,086 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = liyaohui (auth:SIMPLE)
2015-09-01 22:33:05,086 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-09-01 22:33:05,086 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = false
2015-09-01 22:33:05,086 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-09-01 22:33:05,088 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-09-01 22:33:05,264 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-09-01 22:33:05,264 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-09-01 22:33:05,264 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2015-09-01 22:33:05,264 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-09-01 22:33:05,333 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-09-01 22:33:05,337 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-09-01 22:33:05,337 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-09-01 22:33:05,337 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-09-01 22:33:05,370 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-09-01 22:33:05,420 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-09-01 22:33:05,422 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-09-01 22:33:05,422 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-09-01 22:33:05,422 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-09-01 22:33:05,435 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50090
2015-09-01 22:33:05,436 INFO org.mortbay.log: jetty-6.1.26
2015-09-01 22:33:05,818 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50090
2015-09-01 22:33:05,818 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-09-01 22:33:05,818 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Secondary Web-server up at: 0.0.0.0:50090
2015-09-01 22:33:05,818 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-09-01 22:33:05,818 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-09-01 22:34:06,089 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-09-01 22:34:06,092 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getimage=1&txid=5079&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-01 22:34:06,246 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.15s at 490.20 KB/s
2015-09-01 22:34:06,246 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000005079 size 77710 bytes.
2015-09-01 22:34:06,277 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=5080&endTxId=5080&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-01 22:34:06,328 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 20078.43 KB/s
2015-09-01 22:34:06,328 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000005080-0000000000000005080_0000001441118046277 size 0 bytes.
2015-09-01 22:34:06,329 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=5081&endTxId=5082&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-01 22:34:06,360 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-09-01 22:34:06,360 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000005081-0000000000000005082_0000001441118046329 size 0 bytes.
2015-09-01 22:34:06,374 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000005079 using no compression
2015-09-01 22:34:06,375 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 696
2015-09-01 22:34:06,411 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2015-09-01 22:34:06,412 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000005079 of size 77710 bytes loaded in 0 seconds.
2015-09-01 22:34:06,412 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 5079 from /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000005079
2015-09-01 22:34:06,412 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 3 entries 45 lookups
2015-09-01 22:34:06,418 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2015-09-01 22:34:06,422 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005080-0000000000000005080 expecting start txid #5080
2015-09-01 22:34:06,422 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005080-0000000000000005080
2015-09-01 22:34:06,440 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005080-0000000000000005080 of size 1048576 edits # 1 loaded in 0 seconds
2015-09-01 22:34:06,440 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005081-0000000000000005082 expecting start txid #5081
2015-09-01 22:34:06,440 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005081-0000000000000005082
2015-09-01 22:34:06,440 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005081-0000000000000005082 of size 30 edits # 2 loaded in 0 seconds
2015-09-01 22:34:06,447 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000005082 using no compression
2015-09-01 22:34:06,492 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000005082 of size 77710 bytes saved in 0 seconds.
2015-09-01 22:34:06,526 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5079
2015-09-01 22:34:06,526 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000005076, cpktTxId=0000000000000005076)
2015-09-01 22:34:06,545 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=5082&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-01 22:34:06,726 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.18s at 0.00 KB/s
2015-09-01 22:34:06,726 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 5082 to namenode at ubuntu01:50070
2015-09-01 22:34:06,726 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 77710
2015-09-01 22:41:21,508 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-09-01 22:41:21,509 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at ubuntu01/127.0.1.1
************************************************************/
2015-09-02 09:16:39,018 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-09-02 09:16:39,049 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-09-02 09:16:39,375 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-02 09:16:39,519 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-09-02 09:16:39,587 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-09-02 09:16:39,587 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2015-09-02 09:16:39,820 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/liyaohui/hadoop/tmp/dfs/namesecondary/in_use.lock acquired by nodename 2939@ubuntu01
2015-09-02 09:16:39,901 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2015-09-02 09:16:39,901 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2015-09-02 09:16:39,904 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-09-02 09:16:39,907 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-09-02 09:16:39,907 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-09-02 09:16:39,908 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2015-09-02 09:16:39,908 INFO org.apache.hadoop.util.GSet: capacity      = 2^22 = 4194304 entries
2015-09-02 09:16:39,936 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-09-02 09:16:39,937 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-09-02 09:16:39,937 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-09-02 09:16:39,937 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-09-02 09:16:39,937 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-09-02 09:16:39,937 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-09-02 09:16:39,937 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-09-02 09:16:39,937 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-09-02 09:16:39,938 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = liyaohui (auth:SIMPLE)
2015-09-02 09:16:39,938 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-09-02 09:16:39,938 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = false
2015-09-02 09:16:39,938 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-09-02 09:16:39,940 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-09-02 09:16:40,130 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-09-02 09:16:40,130 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-09-02 09:16:40,130 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2015-09-02 09:16:40,130 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-09-02 09:16:40,204 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-09-02 09:16:40,208 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-09-02 09:16:40,208 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-09-02 09:16:40,208 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-09-02 09:16:40,245 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-09-02 09:16:40,295 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-09-02 09:16:40,297 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2015-09-02 09:16:40,297 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-09-02 09:16:40,297 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-09-02 09:16:40,307 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50090
2015-09-02 09:16:40,307 INFO org.mortbay.log: jetty-6.1.26
2015-09-02 09:16:40,585 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50090
2015-09-02 09:16:40,585 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2015-09-02 09:16:40,585 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Secondary Web-server up at: 0.0.0.0:50090
2015-09-02 09:16:40,586 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2015-09-02 09:16:40,586 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2015-09-02 09:17:40,974 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2015-09-02 09:17:40,978 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getimage=1&txid=5088&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-02 09:17:41,271 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.29s at 256.85 KB/s
2015-09-02 09:17:41,271 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000005088 size 77806 bytes.
2015-09-02 09:17:41,313 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=5089&endTxId=5090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-02 09:17:41,374 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.06s at 0.00 KB/s
2015-09-02 09:17:41,374 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000005089-0000000000000005090_0000001441156661313 size 0 bytes.
2015-09-02 09:17:41,389 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000005088 using no compression
2015-09-02 09:17:41,389 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 697
2015-09-02 09:17:41,430 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2015-09-02 09:17:41,430 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000005088 of size 77806 bytes loaded in 0 seconds.
2015-09-02 09:17:41,431 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 5088 from /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000005088
2015-09-02 09:17:41,431 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 3 entries 45 lookups
2015-09-02 09:17:41,436 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-09-02 09:17:41,440 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005089-0000000000000005090 expecting start txid #5089
2015-09-02 09:17:41,440 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005089-0000000000000005090
2015-09-02 09:17:41,455 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005089-0000000000000005090 of size 30 edits # 2 loaded in 0 seconds
2015-09-02 09:17:41,461 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000005090 using no compression
2015-09-02 09:17:41,568 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000005090 of size 77806 bytes saved in 0 seconds.
2015-09-02 09:17:41,652 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5088
2015-09-02 09:17:41,652 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000005079, cpktTxId=0000000000000005079)
2015-09-02 09:17:41,652 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000005082, cpktTxId=0000000000000005082)
2015-09-02 09:17:41,691 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=5090&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-02 09:17:41,963 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.27s at 0.00 KB/s
2015-09-02 09:17:41,963 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 5090 to namenode at ubuntu01:50070
2015-09-02 09:17:41,963 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 77806
2015-09-02 10:17:42,303 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-09-02 10:17:42,303 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=5091&endTxId=5092&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-02 10:17:42,332 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-09-02 10:17:42,332 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000005091-0000000000000005092_0000001441160262303 size 0 bytes.
2015-09-02 10:17:42,332 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-09-02 10:17:42,332 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005091-0000000000000005092 expecting start txid #5091
2015-09-02 10:17:42,332 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005091-0000000000000005092
2015-09-02 10:17:42,332 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005091-0000000000000005092 of size 30 edits # 2 loaded in 0 seconds
2015-09-02 10:17:42,334 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000005092 using no compression
2015-09-02 10:17:42,393 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000005092 of size 77806 bytes saved in 0 seconds.
2015-09-02 10:17:42,447 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5090
2015-09-02 10:17:42,447 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000005088, cpktTxId=0000000000000005088)
2015-09-02 10:17:42,465 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=5092&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-02 10:17:42,543 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.08s at 0.00 KB/s
2015-09-02 10:17:42,543 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 5092 to namenode at ubuntu01:50070
2015-09-02 10:17:42,543 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 77806
2015-09-02 11:17:42,901 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-09-02 11:17:42,902 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=5093&endTxId=5094&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-02 11:17:42,930 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-09-02 11:17:42,930 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000005093-0000000000000005094_0000001441163862902 size 0 bytes.
2015-09-02 11:17:42,931 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-09-02 11:17:42,931 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005093-0000000000000005094 expecting start txid #5093
2015-09-02 11:17:42,931 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005093-0000000000000005094
2015-09-02 11:17:42,931 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005093-0000000000000005094 of size 30 edits # 2 loaded in 0 seconds
2015-09-02 11:17:42,933 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000005094 using no compression
2015-09-02 11:17:42,973 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000005094 of size 77806 bytes saved in 0 seconds.
2015-09-02 11:17:42,994 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5092
2015-09-02 11:17:42,994 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000005090, cpktTxId=0000000000000005090)
2015-09-02 11:17:43,005 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=5094&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-02 11:17:43,080 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.08s at 0.00 KB/s
2015-09-02 11:17:43,080 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 5094 to namenode at ubuntu01:50070
2015-09-02 11:17:43,080 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 77806
2015-09-02 12:17:43,452 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-09-02 12:17:43,452 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=5095&endTxId=5096&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-02 12:17:43,482 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-09-02 12:17:43,482 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000005095-0000000000000005096_0000001441167463452 size 0 bytes.
2015-09-02 12:17:43,482 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-09-02 12:17:43,482 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005095-0000000000000005096 expecting start txid #5095
2015-09-02 12:17:43,482 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005095-0000000000000005096
2015-09-02 12:17:43,482 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005095-0000000000000005096 of size 30 edits # 2 loaded in 0 seconds
2015-09-02 12:17:43,483 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000005096 using no compression
2015-09-02 12:17:43,523 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000005096 of size 77806 bytes saved in 0 seconds.
2015-09-02 12:17:43,554 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5094
2015-09-02 12:17:43,554 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000005092, cpktTxId=0000000000000005092)
2015-09-02 12:17:43,565 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=5096&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-02 12:17:43,651 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.09s at 0.00 KB/s
2015-09-02 12:17:43,651 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 5096 to namenode at ubuntu01:50070
2015-09-02 12:17:43,651 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 77806
2015-09-02 13:17:44,005 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-09-02 13:17:44,005 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=5097&endTxId=5098&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-02 13:17:44,034 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-09-02 13:17:44,034 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000005097-0000000000000005098_0000001441171064005 size 0 bytes.
2015-09-02 13:17:44,034 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-09-02 13:17:44,034 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005097-0000000000000005098 expecting start txid #5097
2015-09-02 13:17:44,034 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005097-0000000000000005098
2015-09-02 13:17:44,034 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005097-0000000000000005098 of size 30 edits # 2 loaded in 0 seconds
2015-09-02 13:17:44,035 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000005098 using no compression
2015-09-02 13:17:44,065 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000005098 of size 77806 bytes saved in 0 seconds.
2015-09-02 13:17:44,086 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5096
2015-09-02 13:17:44,086 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000005094, cpktTxId=0000000000000005094)
2015-09-02 13:17:44,095 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=5098&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-02 13:17:44,161 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.07s at 0.00 KB/s
2015-09-02 13:17:44,161 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 5098 to namenode at ubuntu01:50070
2015-09-02 13:17:44,161 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 77806
2015-09-02 14:17:44,500 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-09-02 14:17:44,501 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=5099&endTxId=5100&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-02 14:17:44,531 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-09-02 14:17:44,531 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000005099-0000000000000005100_0000001441174664501 size 0 bytes.
2015-09-02 14:17:44,532 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-09-02 14:17:44,532 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005099-0000000000000005100 expecting start txid #5099
2015-09-02 14:17:44,532 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005099-0000000000000005100
2015-09-02 14:17:44,532 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005099-0000000000000005100 of size 30 edits # 2 loaded in 0 seconds
2015-09-02 14:17:44,533 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000005100 using no compression
2015-09-02 14:17:44,562 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000005100 of size 77806 bytes saved in 0 seconds.
2015-09-02 14:17:44,594 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5098
2015-09-02 14:17:44,594 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000005096, cpktTxId=0000000000000005096)
2015-09-02 14:17:44,604 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=5100&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-02 14:17:44,680 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.08s at 0.00 KB/s
2015-09-02 14:17:44,680 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 5100 to namenode at ubuntu01:50070
2015-09-02 14:17:44,680 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 77806
2015-09-02 15:17:44,975 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-09-02 15:17:44,975 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=5101&endTxId=5102&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-02 15:17:45,004 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 0.00 KB/s
2015-09-02 15:17:45,004 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000005101-0000000000000005102_0000001441178264975 size 0 bytes.
2015-09-02 15:17:45,005 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-09-02 15:17:45,005 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005101-0000000000000005102 expecting start txid #5101
2015-09-02 15:17:45,005 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005101-0000000000000005102
2015-09-02 15:17:45,005 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005101-0000000000000005102 of size 30 edits # 2 loaded in 0 seconds
2015-09-02 15:17:45,006 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000005102 using no compression
2015-09-02 15:17:45,035 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000005102 of size 77806 bytes saved in 0 seconds.
2015-09-02 15:17:45,057 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5100
2015-09-02 15:17:45,057 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000005098, cpktTxId=0000000000000005098)
2015-09-02 15:17:45,073 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=5102&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-02 15:17:45,153 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.08s at 0.00 KB/s
2015-09-02 15:17:45,153 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 5102 to namenode at ubuntu01:50070
2015-09-02 15:17:45,153 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 77806
2015-09-02 16:17:45,479 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2015-09-02 16:17:45,479 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?getedit=1&startTxId=5103&endTxId=5141&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-02 16:17:45,509 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 100.00 KB/s
2015-09-02 16:17:45,509 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000005103-0000000000000005141_0000001441181865479 size 0 bytes.
2015-09-02 16:17:45,509 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2015-09-02 16:17:45,510 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005103-0000000000000005141 expecting start txid #5103
2015-09-02 16:17:45,510 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005103-0000000000000005141
2015-09-02 16:17:45,525 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/edits_0000000000000005103-0000000000000005141 of size 3220 edits # 39 loaded in 0 seconds
2015-09-02 16:17:45,526 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000005141 using no compression
2015-09-02 16:17:45,550 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage.ckpt_0000000000000005141 of size 13109 bytes saved in 0 seconds.
2015-09-02 16:17:45,572 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5102
2015-09-02 16:17:45,572 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/namesecondary/current/fsimage_0000000000000005100, cpktTxId=0000000000000005100)
2015-09-02 16:17:45,582 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://ubuntu01:50070/getimage?putimage=1&txid=5141&port=50090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-02 16:17:45,657 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.08s at 0.00 KB/s
2015-09-02 16:17:45,657 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 5141 to namenode at ubuntu01:50070
2015-09-02 16:17:45,657 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 13109
2015-09-02 16:59:24,226 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2015-09-02 16:59:24,236 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at ubuntu01/127.0.1.1
************************************************************/
