2015-07-05 06:31:10,585 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-07-05 06:31:10,605 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2015-07-05 06:31:11,260 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-07-05 06:31:11,580 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2015-07-05 06:31:11,581 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2015-07-05 06:31:11,581 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2015-07-05 06:31:11,582 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2015-07-05 06:31:11,582 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2015-07-05 06:31:11,582 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2015-07-05 06:31:11,604 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2015-07-05 06:31:11,604 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2015-07-05 06:31:11,653 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-07-05 06:31:11,714 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-07-05 06:31:11,714 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2015-07-05 06:31:11,735 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2015-07-05 06:31:11,736 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2015-07-05 06:31:11,767 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2015-07-05 06:31:11,804 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2015-07-05 06:31:11,804 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2015-07-05 06:31:11,858 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@1d27ba
2015-07-05 06:31:11,858 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2015-07-05 06:31:11,858 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2015-07-05 06:31:11,858 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2015-07-05 06:31:11,861 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.9 G). Thrashing might happen.
2015-07-05 06:31:11,866 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2015-07-05 06:31:11,920 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 56905
2015-07-05 06:31:11,938 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2015-07-05 06:31:11,938 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2015-07-05 06:31:11,939 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-07-05 06:31:11,939 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 56905: starting
2015-07-05 06:31:11,946 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : ubuntu01:56905
2015-07-05 06:31:11,946 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at ubuntu01/127.0.1.1:56905
2015-07-05 06:31:11,955 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2015-07-05 06:31:11,956 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2015-07-05 06:31:11,956 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-07-05 06:31:11,956 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2015-07-05 06:31:11,957 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2015-07-05 06:31:11,977 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2015-07-05 06:31:11,990 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2015-07-05 06:31:11,992 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2015-07-05 06:31:12,026 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-07-05 06:31:12,077 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-07-05 06:31:12,078 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2015-07-05 06:31:12,078 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-07-05 06:31:12,079 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-07-05 06:31:12,082 INFO org.apache.hadoop.http.HttpServer: adding path spec: /node/*
2015-07-05 06:31:12,082 INFO org.apache.hadoop.http.HttpServer: adding path spec: /ws/*
2015-07-05 06:31:12,084 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 8042
2015-07-05 06:31:12,084 INFO org.mortbay.log: jetty-6.1.26
2015-07-05 06:31:12,110 INFO org.mortbay.log: Extract jar:file:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2015-07-05 06:31:12,460 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:8042
2015-07-05 06:31:12,460 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app /node started at 8042
2015-07-05 06:31:12,756 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2015-07-05 06:31:12,789 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8031
2015-07-05 06:31:12,979 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 496931737
2015-07-05 06:31:12,982 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for nm-tokens, got key with id :-1069924524
2015-07-05 06:31:12,983 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as ubuntu01:56905 with total resource of <memory:8192, vCores:8>
2015-07-05 06:31:12,983 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2015-07-05 06:31:46,383 ERROR org.apache.hadoop.yarn.server.nodemanager.NodeManager: RECEIVED SIGNAL 15: SIGTERM
2015-07-05 06:31:46,388 INFO org.mortbay.log: Stopped SelectChannelConnector@0.0.0.0:8042
2015-07-05 06:31:46,389 INFO org.apache.hadoop.ipc.Server: Stopping server on 56905
2015-07-05 06:31:46,390 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 56905
2015-07-05 06:31:46,390 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2015-07-05 06:31:46,391 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.
2015-07-05 06:31:46,399 INFO org.apache.hadoop.ipc.Server: Stopping server on 8040
2015-07-05 06:31:46,399 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8040
2015-07-05 06:31:46,399 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2015-07-05 06:31:46,400 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Public cache exiting
2015-07-05 06:31:46,400 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NodeManager metrics system...
2015-07-05 06:31:46,400 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system stopped.
2015-07-05 06:31:46,400 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system shutdown complete.
2015-07-05 06:31:46,401 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at ubuntu01/127.0.1.1
************************************************************/
2015-07-15 10:59:54,416 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-07-15 10:59:54,438 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2015-07-15 10:59:55,172 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-07-15 10:59:55,591 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2015-07-15 10:59:55,592 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2015-07-15 10:59:55,593 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2015-07-15 10:59:55,593 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2015-07-15 10:59:55,593 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2015-07-15 10:59:55,594 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2015-07-15 10:59:55,615 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2015-07-15 10:59:55,615 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2015-07-15 10:59:55,664 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-07-15 10:59:55,726 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-07-15 10:59:55,726 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2015-07-15 10:59:55,741 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2015-07-15 10:59:55,741 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2015-07-15 10:59:55,763 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1436929195743
2015-07-15 10:59:55,780 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2015-07-15 10:59:55,823 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2015-07-15 10:59:55,823 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2015-07-15 10:59:55,873 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@a7bfbc
2015-07-15 10:59:55,873 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2015-07-15 10:59:55,874 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2015-07-15 10:59:55,874 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2015-07-15 10:59:55,877 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.9 G). Thrashing might happen.
2015-07-15 10:59:55,881 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2015-07-15 10:59:55,932 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50429
2015-07-15 10:59:55,950 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2015-07-15 10:59:55,950 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2015-07-15 10:59:55,950 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-07-15 10:59:55,950 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50429: starting
2015-07-15 10:59:55,958 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : ubuntu01:50429
2015-07-15 10:59:55,958 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at ubuntu01/127.0.1.1:50429
2015-07-15 10:59:55,966 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2015-07-15 10:59:55,967 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2015-07-15 10:59:55,971 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-07-15 10:59:55,971 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2015-07-15 10:59:55,971 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2015-07-15 10:59:56,006 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2015-07-15 10:59:56,019 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2015-07-15 10:59:56,021 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2015-07-15 10:59:56,052 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-07-15 10:59:56,103 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-07-15 10:59:56,104 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2015-07-15 10:59:56,105 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-07-15 10:59:56,105 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-07-15 10:59:56,108 INFO org.apache.hadoop.http.HttpServer: adding path spec: /node/*
2015-07-15 10:59:56,108 INFO org.apache.hadoop.http.HttpServer: adding path spec: /ws/*
2015-07-15 10:59:56,110 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 8042
2015-07-15 10:59:56,110 INFO org.mortbay.log: jetty-6.1.26
2015-07-15 10:59:56,136 INFO org.mortbay.log: Extract jar:file:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2015-07-15 10:59:56,493 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:8042
2015-07-15 10:59:56,493 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app /node started at 8042
2015-07-15 10:59:56,792 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2015-07-15 10:59:56,825 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8031
2015-07-15 10:59:57,022 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id -2020815200
2015-07-15 10:59:57,025 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for nm-tokens, got key with id :-1182964968
2015-07-15 10:59:57,025 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as ubuntu01:50429 with total resource of <memory:8192, vCores:8>
2015-07-15 10:59:57,025 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2015-07-15 14:22:48,896 ERROR org.apache.hadoop.yarn.server.nodemanager.NodeManager: RECEIVED SIGNAL 15: SIGTERM
2015-07-15 14:22:48,901 INFO org.mortbay.log: Stopped SelectChannelConnector@0.0.0.0:8042
2015-07-15 14:22:49,002 INFO org.apache.hadoop.ipc.Server: Stopping server on 50429
2015-07-15 14:22:49,003 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 50429
2015-07-15 14:22:49,003 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2015-07-15 14:22:49,003 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.
2015-07-15 14:22:49,011 INFO org.apache.hadoop.ipc.Server: Stopping server on 8040
2015-07-15 14:22:49,012 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2015-07-15 14:22:49,012 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8040
2015-07-15 14:22:49,012 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Public cache exiting
2015-07-15 14:22:49,012 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NodeManager metrics system...
2015-07-15 14:22:49,013 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system stopped.
2015-07-15 14:22:49,013 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system shutdown complete.
2015-07-15 14:22:49,013 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at ubuntu01/127.0.1.1
************************************************************/
2015-07-15 14:28:04,272 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-07-15 14:28:04,290 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2015-07-15 14:28:05,028 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-07-15 14:28:05,310 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2015-07-15 14:28:05,311 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2015-07-15 14:28:05,311 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2015-07-15 14:28:05,312 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2015-07-15 14:28:05,312 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2015-07-15 14:28:05,312 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2015-07-15 14:28:05,333 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2015-07-15 14:28:05,333 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2015-07-15 14:28:05,383 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-07-15 14:28:05,443 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-07-15 14:28:05,444 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2015-07-15 14:28:05,459 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2015-07-15 14:28:05,459 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2015-07-15 14:28:05,483 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1436941685461
2015-07-15 14:28:05,485 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1436929195743
2015-07-15 14:28:05,507 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2015-07-15 14:28:05,524 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2015-07-15 14:28:05,524 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2015-07-15 14:28:05,581 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@a7bfbc
2015-07-15 14:28:05,581 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2015-07-15 14:28:05,581 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2015-07-15 14:28:05,581 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2015-07-15 14:28:05,584 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.9 G). Thrashing might happen.
2015-07-15 14:28:05,589 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2015-07-15 14:28:05,638 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 44193
2015-07-15 14:28:05,656 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2015-07-15 14:28:05,656 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2015-07-15 14:28:05,656 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-07-15 14:28:05,657 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 44193: starting
2015-07-15 14:28:05,663 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : ubuntu01:44193
2015-07-15 14:28:05,663 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at ubuntu01/127.0.1.1:44193
2015-07-15 14:28:05,670 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2015-07-15 14:28:05,671 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2015-07-15 14:28:05,672 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-07-15 14:28:05,672 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2015-07-15 14:28:05,672 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2015-07-15 14:28:05,684 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2015-07-15 14:28:05,696 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2015-07-15 14:28:05,698 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2015-07-15 14:28:05,729 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-07-15 14:28:05,780 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-07-15 14:28:05,782 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2015-07-15 14:28:05,782 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-07-15 14:28:05,782 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-07-15 14:28:05,785 INFO org.apache.hadoop.http.HttpServer: adding path spec: /node/*
2015-07-15 14:28:05,785 INFO org.apache.hadoop.http.HttpServer: adding path spec: /ws/*
2015-07-15 14:28:05,787 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 8042
2015-07-15 14:28:05,787 INFO org.mortbay.log: jetty-6.1.26
2015-07-15 14:28:05,814 INFO org.mortbay.log: Extract jar:file:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2015-07-15 14:28:06,164 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:8042
2015-07-15 14:28:06,164 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app /node started at 8042
2015-07-15 14:28:06,461 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2015-07-15 14:28:06,494 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8031
2015-07-15 14:28:06,683 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 1568191789
2015-07-15 14:28:06,686 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for nm-tokens, got key with id :-1013090366
2015-07-15 14:28:06,687 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as ubuntu01:44193 with total resource of <memory:8192, vCores:8>
2015-07-15 14:28:06,687 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2015-07-15 16:10:22,959 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0001_000001 (auth:SIMPLE)
2015-07-15 16:10:23,106 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0001_01_000001 by user liyaohui
2015-07-15 16:10:23,132 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Creating a new application reference for app application_1436941682764_0001
2015-07-15 16:10:23,135 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0001 transitioned from NEW to INITING
2015-07-15 16:10:23,138 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0001 transitioned from INITING to RUNNING
2015-07-15 16:10:23,138 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0001_01_000001 to application application_1436941682764_0001
2015-07-15 16:10:23,157 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0001	CONTAINERID=container_1436941682764_0001_01_000001
2015-07-15 16:10:23,163 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0001_01_000001 transitioned from NEW to LOCALIZING
2015-07-15 16:10:23,163 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0001
2015-07-15 16:10:23,184 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0001/job.splitmetainfo transitioned from INIT to DOWNLOADING
2015-07-15 16:10:23,184 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0001/job.jar transitioned from INIT to DOWNLOADING
2015-07-15 16:10:23,184 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0001/job.split transitioned from INIT to DOWNLOADING
2015-07-15 16:10:23,184 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0001/job.xml transitioned from INIT to DOWNLOADING
2015-07-15 16:10:23,184 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1436941682764_0001_01_000001
2015-07-15 16:10:23,458 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1436941682764_0001_01_000001.tokens. Credentials list: 
2015-07-15 16:10:23,483 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user liyaohui
2015-07-15 16:10:23,541 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1436941682764_0001_01_000001.tokens to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0001/container_1436941682764_0001_01_000001.tokens
2015-07-15 16:10:23,541 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: CWD set to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0001 = file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0001
2015-07-15 16:10:23,778 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:10:24,213 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0001/job.splitmetainfo transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:10:24,787 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:10:25,452 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0001/job.jar transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:10:25,474 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0001/job.split transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:10:25,497 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0001/job.xml transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:10:25,498 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0001_01_000001 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:10:25,565 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0001_01_000001 transitioned from LOCALIZED to RUNNING
2015-07-15 16:10:25,590 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0001/container_1436941682764_0001_01_000001/default_container_executor.sh]
2015-07-15 16:10:25,790 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:10:26,792 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:10:26,853 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0001_01_000001
2015-07-15 16:10:26,887 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 12997 for container-id container_1436941682764_0001_01_000001: 60.0 MB of 2 GB physical memory used; 1.3 GB of 4.2 GB virtual memory used
2015-07-15 16:10:27,793 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:10:28,795 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:10:29,797 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:10:29,922 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 12997 for container-id container_1436941682764_0001_01_000001: 161.5 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:10:30,799 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:10:31,801 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:10:31,896 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0001_000001 (auth:SIMPLE)
2015-07-15 16:10:31,911 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0001_01_000002 by user liyaohui
2015-07-15 16:10:31,912 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0001_01_000002 to application application_1436941682764_0001
2015-07-15 16:10:31,912 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0001_01_000002 transitioned from NEW to LOCALIZING
2015-07-15 16:10:31,912 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0001
2015-07-15 16:10:31,912 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1436941682764_0001
2015-07-15 16:10:31,912 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-07-15 16:10:31,912 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0001	CONTAINERID=container_1436941682764_0001_01_000002
2015-07-15 16:10:31,915 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1436941682764_0001
2015-07-15 16:10:31,916 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0001_01_000002 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:10:31,951 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0001_01_000002 transitioned from LOCALIZED to RUNNING
2015-07-15 16:10:31,976 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0001/container_1436941682764_0001_01_000002/default_container_executor.sh]
2015-07-15 16:10:32,803 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:10:32,804 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:10:32,927 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0001_01_000002
2015-07-15 16:10:32,946 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 12997 for container-id container_1436941682764_0001_01_000001: 179.9 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:10:32,971 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 13123 for container-id container_1436941682764_0001_01_000002: 67.8 MB of 1 GB physical memory used; 523.8 MB of 2.1 GB virtual memory used
2015-07-15 16:10:33,805 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:10:33,806 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:10:34,478 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0001_01_000002
2015-07-15 16:10:34,479 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0001_01_000002 transitioned from RUNNING to KILLING
2015-07-15 16:10:34,479 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0001_01_000002
2015-07-15 16:10:34,480 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0001	CONTAINERID=container_1436941682764_0001_01_000002
2015-07-15 16:10:34,480 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:10:34,481 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-07-15 16:10:34,506 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1436941682764_0001_01_000002 is : 143
2015-07-15 16:10:34,553 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0001_01_000002 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-07-15 16:10:34,554 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0001/container_1436941682764_0001_01_000002
2015-07-15 16:10:34,555 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0001	CONTAINERID=container_1436941682764_0001_01_000002
2015-07-15 16:10:34,564 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0001_01_000002 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-07-15 16:10:34,564 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0001_01_000002 from application application_1436941682764_0001
2015-07-15 16:10:34,564 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0001
2015-07-15 16:10:35,488 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:10:35,488 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-07-15 16:10:35,489 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0001_01_000002
2015-07-15 16:10:35,971 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0001_01_000002
2015-07-15 16:10:35,987 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 12997 for container-id container_1436941682764_0001_01_000001: 185.3 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:10:36,490 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:10:36,783 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0001_01_000003 by user liyaohui
2015-07-15 16:10:36,783 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0001	CONTAINERID=container_1436941682764_0001_01_000003
2015-07-15 16:10:36,784 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0001_01_000003 to application application_1436941682764_0001
2015-07-15 16:10:36,784 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0001_01_000003 transitioned from NEW to LOCALIZING
2015-07-15 16:10:36,784 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0001
2015-07-15 16:10:36,784 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1436941682764_0001
2015-07-15 16:10:36,784 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-07-15 16:10:36,785 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1436941682764_0001
2015-07-15 16:10:36,785 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0001_01_000003 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:10:36,817 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0001_01_000003 transitioned from LOCALIZED to RUNNING
2015-07-15 16:10:36,840 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0001/container_1436941682764_0001_01_000003/default_container_executor.sh]
2015-07-15 16:10:37,492 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:10:37,493 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:10:38,494 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:10:38,495 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:10:38,987 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0001_01_000003
2015-07-15 16:10:39,008 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 12997 for container-id container_1436941682764_0001_01_000001: 186.3 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:10:39,025 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 13209 for container-id container_1436941682764_0001_01_000003: 110.9 MB of 1 GB physical memory used; 540.7 MB of 2.1 GB virtual memory used
2015-07-15 16:10:39,497 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:10:39,498 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:10:39,563 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0001_01_000003
2015-07-15 16:10:39,564 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0001	CONTAINERID=container_1436941682764_0001_01_000003
2015-07-15 16:10:39,564 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0001_01_000003 transitioned from RUNNING to KILLING
2015-07-15 16:10:39,564 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0001_01_000003
2015-07-15 16:10:39,564 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:10:39,565 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-07-15 16:10:39,570 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1436941682764_0001_01_000003 is : 143
2015-07-15 16:10:39,598 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0001_01_000003 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-07-15 16:10:39,598 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0001/container_1436941682764_0001_01_000003
2015-07-15 16:10:39,611 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0001	CONTAINERID=container_1436941682764_0001_01_000003
2015-07-15 16:10:39,611 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0001_01_000003 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-07-15 16:10:39,611 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0001_01_000003 from application application_1436941682764_0001
2015-07-15 16:10:39,611 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0001
2015-07-15 16:10:40,567 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:10:40,567 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-07-15 16:10:40,568 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0001_01_000003
2015-07-15 16:10:41,569 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:10:42,025 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0001_01_000003
2015-07-15 16:10:42,043 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 12997 for container-id container_1436941682764_0001_01_000001: 200.1 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:10:42,571 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:10:43,572 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:10:44,574 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:10:44,996 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container container_1436941682764_0001_01_000001 succeeded 
2015-07-15 16:10:44,997 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0001_01_000001 transitioned from RUNNING to EXITED_WITH_SUCCESS
2015-07-15 16:10:44,997 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0001_01_000001
2015-07-15 16:10:45,009 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0001/container_1436941682764_0001_01_000001
2015-07-15 16:10:45,011 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Succeeded	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0001	CONTAINERID=container_1436941682764_0001_01_000001
2015-07-15 16:10:45,011 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0001_01_000001 transitioned from EXITED_WITH_SUCCESS to DONE
2015-07-15 16:10:45,011 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0001_01_000001 from application application_1436941682764_0001
2015-07-15 16:10:45,011 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0001
2015-07-15 16:10:45,044 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0001_01_000001
2015-07-15 16:10:45,576 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_COMPLETE diagnostics: "" exit_status: 0
2015-07-15 16:10:45,576 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0001_01_000001
2015-07-15 16:10:45,592 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0001_000001 (auth:SIMPLE)
2015-07-15 16:10:45,602 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0001_01_000001
2015-07-15 16:10:46,583 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0001 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP
2015-07-15 16:10:46,583 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0001
2015-07-15 16:10:46,583 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_STOP for appId application_1436941682764_0001
2015-07-15 16:10:46,584 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0001 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED
2015-07-15 16:10:46,584 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler: Scheduling Log Deletion for application: application_1436941682764_0001, with delay of 10800 seconds
2015-07-15 16:48:47,448 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0004_000001 (auth:SIMPLE)
2015-07-15 16:48:47,453 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0004_01_000001 by user liyaohui
2015-07-15 16:48:47,453 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Creating a new application reference for app application_1436941682764_0004
2015-07-15 16:48:47,453 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0004	CONTAINERID=container_1436941682764_0004_01_000001
2015-07-15 16:48:47,453 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0004 transitioned from NEW to INITING
2015-07-15 16:48:47,459 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0004_01_000001 to application application_1436941682764_0004
2015-07-15 16:48:47,459 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0004 transitioned from INITING to RUNNING
2015-07-15 16:48:47,460 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0004_01_000001 transitioned from NEW to LOCALIZING
2015-07-15 16:48:47,460 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0004
2015-07-15 16:48:47,460 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0004/job.splitmetainfo transitioned from INIT to DOWNLOADING
2015-07-15 16:48:47,460 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0004/job.jar transitioned from INIT to DOWNLOADING
2015-07-15 16:48:47,460 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0004/job.split transitioned from INIT to DOWNLOADING
2015-07-15 16:48:47,460 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0004/job.xml transitioned from INIT to DOWNLOADING
2015-07-15 16:48:47,460 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1436941682764_0004_01_000001
2015-07-15 16:48:47,468 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1436941682764_0004_01_000001.tokens. Credentials list: 
2015-07-15 16:48:47,471 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user liyaohui
2015-07-15 16:48:47,482 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1436941682764_0004_01_000001.tokens to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0004/container_1436941682764_0004_01_000001.tokens
2015-07-15 16:48:47,482 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: CWD set to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0004 = file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0004
2015-07-15 16:48:47,569 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0004/job.splitmetainfo transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:48:47,853 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0004/job.jar transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:48:47,879 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0004/job.split transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:48:47,902 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0004/job.xml transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:48:47,902 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0004_01_000001 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:48:47,931 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0004_01_000001 transitioned from LOCALIZED to RUNNING
2015-07-15 16:48:47,954 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0004/container_1436941682764_0004_01_000001/default_container_executor.sh]
2015-07-15 16:48:48,099 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0004_01_000001
2015-07-15 16:48:48,117 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 15081 for container-id container_1436941682764_0004_01_000001: 26.4 MB of 2 GB physical memory used; 1.3 GB of 4.2 GB virtual memory used
2015-07-15 16:48:48,442 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:48:49,444 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:48:50,445 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:48:51,138 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 15081 for container-id container_1436941682764_0004_01_000001: 153.4 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:48:51,446 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:48:52,448 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:48:53,449 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:48:53,498 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0004_000001 (auth:SIMPLE)
2015-07-15 16:48:53,503 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0004_01_000002 by user liyaohui
2015-07-15 16:48:53,503 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0004	CONTAINERID=container_1436941682764_0004_01_000002
2015-07-15 16:48:53,503 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0004_01_000002 to application application_1436941682764_0004
2015-07-15 16:48:53,503 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0004_01_000002 transitioned from NEW to LOCALIZING
2015-07-15 16:48:53,503 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0004
2015-07-15 16:48:53,503 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1436941682764_0004
2015-07-15 16:48:53,504 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-07-15 16:48:53,504 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1436941682764_0004
2015-07-15 16:48:53,504 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0004_01_000002 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:48:53,538 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0004_01_000002 transitioned from LOCALIZED to RUNNING
2015-07-15 16:48:53,569 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0004/container_1436941682764_0004_01_000002/default_container_executor.sh]
2015-07-15 16:48:54,139 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0004_01_000002
2015-07-15 16:48:54,157 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 15206 for container-id container_1436941682764_0004_01_000002: 51.3 MB of 1 GB physical memory used; 513.7 MB of 2.1 GB virtual memory used
2015-07-15 16:48:54,175 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 15081 for container-id container_1436941682764_0004_01_000001: 215.1 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:48:54,450 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:48:54,450 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:48:55,451 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:48:55,451 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:48:56,078 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0004_01_000002
2015-07-15 16:48:56,078 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0004	CONTAINERID=container_1436941682764_0004_01_000002
2015-07-15 16:48:56,078 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0004_01_000002 transitioned from RUNNING to KILLING
2015-07-15 16:48:56,078 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0004_01_000002
2015-07-15 16:48:56,079 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:48:56,079 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-07-15 16:48:56,083 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1436941682764_0004_01_000002 is : 143
2015-07-15 16:48:56,100 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0004_01_000002 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-07-15 16:48:56,100 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0004/container_1436941682764_0004_01_000002
2015-07-15 16:48:56,100 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0004	CONTAINERID=container_1436941682764_0004_01_000002
2015-07-15 16:48:56,100 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0004_01_000002 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-07-15 16:48:56,100 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0004_01_000002 from application application_1436941682764_0004
2015-07-15 16:48:56,100 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0004
2015-07-15 16:48:57,081 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:48:57,081 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-07-15 16:48:57,082 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0004_01_000002
2015-07-15 16:48:57,175 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0004_01_000002
2015-07-15 16:48:57,192 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 15081 for container-id container_1436941682764_0004_01_000001: 216.2 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:48:58,083 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:48:59,084 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:00,085 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:00,207 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 15081 for container-id container_1436941682764_0004_01_000001: 217.9 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:49:01,086 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:02,087 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:02,587 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container container_1436941682764_0004_01_000001 succeeded 
2015-07-15 16:49:02,587 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0004_01_000001 transitioned from RUNNING to EXITED_WITH_SUCCESS
2015-07-15 16:49:02,587 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0004_01_000001
2015-07-15 16:49:02,601 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0004/container_1436941682764_0004_01_000001
2015-07-15 16:49:02,601 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Succeeded	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0004	CONTAINERID=container_1436941682764_0004_01_000001
2015-07-15 16:49:02,601 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0004_01_000001 transitioned from EXITED_WITH_SUCCESS to DONE
2015-07-15 16:49:02,601 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0004_01_000001 from application application_1436941682764_0004
2015-07-15 16:49:02,602 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0004
2015-07-15 16:49:03,092 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_COMPLETE diagnostics: "" exit_status: 0
2015-07-15 16:49:03,092 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0004_01_000001
2015-07-15 16:49:03,103 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0004_000001 (auth:SIMPLE)
2015-07-15 16:49:03,106 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0004_01_000001
2015-07-15 16:49:03,207 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0004_01_000001
2015-07-15 16:49:04,093 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0004 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP
2015-07-15 16:49:04,094 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0004
2015-07-15 16:49:04,095 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_STOP for appId application_1436941682764_0004
2015-07-15 16:49:04,096 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0004 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED
2015-07-15 16:49:04,096 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler: Scheduling Log Deletion for application: application_1436941682764_0004, with delay of 10800 seconds
2015-07-15 16:49:04,100 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0005_000001 (auth:SIMPLE)
2015-07-15 16:49:04,106 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0005_01_000001 by user liyaohui
2015-07-15 16:49:04,107 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Creating a new application reference for app application_1436941682764_0005
2015-07-15 16:49:04,107 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0005	CONTAINERID=container_1436941682764_0005_01_000001
2015-07-15 16:49:04,107 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0005 transitioned from NEW to INITING
2015-07-15 16:49:04,107 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0005_01_000001 to application application_1436941682764_0005
2015-07-15 16:49:04,107 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0005 transitioned from INITING to RUNNING
2015-07-15 16:49:04,107 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0005_01_000001 transitioned from NEW to LOCALIZING
2015-07-15 16:49:04,107 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0005
2015-07-15 16:49:04,108 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0005/job.splitmetainfo transitioned from INIT to DOWNLOADING
2015-07-15 16:49:04,108 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0005/job.jar transitioned from INIT to DOWNLOADING
2015-07-15 16:49:04,108 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0005/job.split transitioned from INIT to DOWNLOADING
2015-07-15 16:49:04,108 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0005/job.xml transitioned from INIT to DOWNLOADING
2015-07-15 16:49:04,108 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1436941682764_0005_01_000001
2015-07-15 16:49:04,120 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1436941682764_0005_01_000001.tokens. Credentials list: 
2015-07-15 16:49:04,123 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user liyaohui
2015-07-15 16:49:04,136 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1436941682764_0005_01_000001.tokens to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0005/container_1436941682764_0005_01_000001.tokens
2015-07-15 16:49:04,136 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: CWD set to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0005 = file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0005
2015-07-15 16:49:04,224 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0005/job.splitmetainfo transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:49:04,475 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0005/job.jar transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:49:04,500 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0005/job.split transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:49:04,527 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0005/job.xml transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:49:04,527 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0005_01_000001 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:49:04,549 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0005_01_000001 transitioned from LOCALIZED to RUNNING
2015-07-15 16:49:04,573 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0005/container_1436941682764_0005_01_000001/default_container_executor.sh]
2015-07-15 16:49:05,094 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:06,095 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:06,208 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0005_01_000001
2015-07-15 16:49:06,227 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 15467 for container-id container_1436941682764_0005_01_000001: 95.4 MB of 2 GB physical memory used; 1.3 GB of 4.2 GB virtual memory used
2015-07-15 16:49:07,096 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:08,098 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:09,099 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:09,245 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 15467 for container-id container_1436941682764_0005_01_000001: 219.4 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:49:10,101 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:10,162 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0005_000001 (auth:SIMPLE)
2015-07-15 16:49:10,166 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0005_01_000002 by user liyaohui
2015-07-15 16:49:10,166 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0005	CONTAINERID=container_1436941682764_0005_01_000002
2015-07-15 16:49:10,166 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0005_01_000002 to application application_1436941682764_0005
2015-07-15 16:49:10,167 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0005_01_000002 transitioned from NEW to LOCALIZING
2015-07-15 16:49:10,167 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0005
2015-07-15 16:49:10,167 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1436941682764_0005
2015-07-15 16:49:10,167 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-07-15 16:49:10,167 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1436941682764_0005
2015-07-15 16:49:10,167 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0005_01_000002 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:49:10,192 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0005_01_000002 transitioned from LOCALIZED to RUNNING
2015-07-15 16:49:10,212 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0005/container_1436941682764_0005_01_000002/default_container_executor.sh]
2015-07-15 16:49:11,102 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:11,102 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:12,103 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:12,103 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:12,245 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0005_01_000002
2015-07-15 16:49:12,262 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 15590 for container-id container_1436941682764_0005_01_000002: 101.1 MB of 1 GB physical memory used; 530.8 MB of 2.1 GB virtual memory used
2015-07-15 16:49:12,295 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 15467 for container-id container_1436941682764_0005_01_000001: 219.8 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:49:13,003 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0005_01_000002
2015-07-15 16:49:13,003 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0005	CONTAINERID=container_1436941682764_0005_01_000002
2015-07-15 16:49:13,003 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0005_01_000002 transitioned from RUNNING to KILLING
2015-07-15 16:49:13,003 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0005_01_000002
2015-07-15 16:49:13,003 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:13,004 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-07-15 16:49:13,026 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1436941682764_0005_01_000002 is : 143
2015-07-15 16:49:13,041 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0005_01_000002 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-07-15 16:49:13,042 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0005/container_1436941682764_0005_01_000002
2015-07-15 16:49:13,042 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0005	CONTAINERID=container_1436941682764_0005_01_000002
2015-07-15 16:49:13,042 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0005_01_000002 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-07-15 16:49:13,042 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0005_01_000002 from application application_1436941682764_0005
2015-07-15 16:49:13,042 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0005
2015-07-15 16:49:14,005 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:14,005 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-07-15 16:49:14,006 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0005_01_000002
2015-07-15 16:49:15,008 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:15,078 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0005_01_000003 by user liyaohui
2015-07-15 16:49:15,079 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0005	CONTAINERID=container_1436941682764_0005_01_000003
2015-07-15 16:49:15,079 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0005_01_000003 to application application_1436941682764_0005
2015-07-15 16:49:15,079 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0005_01_000003 transitioned from NEW to LOCALIZING
2015-07-15 16:49:15,079 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0005
2015-07-15 16:49:15,079 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1436941682764_0005
2015-07-15 16:49:15,079 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-07-15 16:49:15,079 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1436941682764_0005
2015-07-15 16:49:15,079 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0005_01_000003 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:49:15,111 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0005_01_000003 transitioned from LOCALIZED to RUNNING
2015-07-15 16:49:15,135 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0005/container_1436941682764_0005_01_000003/default_container_executor.sh]
2015-07-15 16:49:15,296 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0005_01_000003
2015-07-15 16:49:15,296 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0005_01_000002
2015-07-15 16:49:15,312 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 15675 for container-id container_1436941682764_0005_01_000003: 13 MB of 1 GB physical memory used; 488.9 MB of 2.1 GB virtual memory used
2015-07-15 16:49:15,326 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 15467 for container-id container_1436941682764_0005_01_000001: 219.7 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:49:16,009 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:16,009 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:17,012 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:17,012 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:18,014 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:18,014 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:18,341 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 15675 for container-id container_1436941682764_0005_01_000003: 134.0 MB of 1 GB physical memory used; 537.4 MB of 2.1 GB virtual memory used
2015-07-15 16:49:18,356 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 15467 for container-id container_1436941682764_0005_01_000001: 219.7 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:49:18,939 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0005_01_000003
2015-07-15 16:49:18,939 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0005	CONTAINERID=container_1436941682764_0005_01_000003
2015-07-15 16:49:18,939 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0005_01_000003 transitioned from RUNNING to KILLING
2015-07-15 16:49:18,939 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0005_01_000003
2015-07-15 16:49:18,939 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:18,939 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-07-15 16:49:18,955 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1436941682764_0005_01_000003 is : 143
2015-07-15 16:49:18,958 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0005_01_000003 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-07-15 16:49:18,958 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0005/container_1436941682764_0005_01_000003
2015-07-15 16:49:18,959 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0005	CONTAINERID=container_1436941682764_0005_01_000003
2015-07-15 16:49:18,959 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0005_01_000003 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-07-15 16:49:18,959 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0005_01_000003 from application application_1436941682764_0005
2015-07-15 16:49:18,959 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0005
2015-07-15 16:49:19,940 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:19,941 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-07-15 16:49:19,941 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0005_01_000003
2015-07-15 16:49:20,942 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:21,356 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0005_01_000003
2015-07-15 16:49:21,371 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 15467 for container-id container_1436941682764_0005_01_000001: 222.2 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:49:21,943 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:22,943 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:23,944 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:24,385 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 15467 for container-id container_1436941682764_0005_01_000001: 222.2 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:49:24,946 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:25,403 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container container_1436941682764_0005_01_000001 succeeded 
2015-07-15 16:49:25,404 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0005_01_000001 transitioned from RUNNING to EXITED_WITH_SUCCESS
2015-07-15 16:49:25,404 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0005_01_000001
2015-07-15 16:49:25,416 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0005/container_1436941682764_0005_01_000001
2015-07-15 16:49:25,416 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Succeeded	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0005	CONTAINERID=container_1436941682764_0005_01_000001
2015-07-15 16:49:25,416 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0005_01_000001 transitioned from EXITED_WITH_SUCCESS to DONE
2015-07-15 16:49:25,416 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0005_01_000001 from application application_1436941682764_0005
2015-07-15 16:49:25,416 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0005
2015-07-15 16:49:25,946 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_COMPLETE diagnostics: "" exit_status: 0
2015-07-15 16:49:25,947 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0005_01_000001
2015-07-15 16:49:25,952 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0005_000001 (auth:SIMPLE)
2015-07-15 16:49:25,957 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0005_01_000001
2015-07-15 16:49:26,948 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0005 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP
2015-07-15 16:49:26,948 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0005
2015-07-15 16:49:26,949 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_STOP for appId application_1436941682764_0005
2015-07-15 16:49:26,949 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0005 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED
2015-07-15 16:49:26,949 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler: Scheduling Log Deletion for application: application_1436941682764_0005, with delay of 10800 seconds
2015-07-15 16:49:26,956 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0006_000001 (auth:SIMPLE)
2015-07-15 16:49:26,960 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0006_01_000001 by user liyaohui
2015-07-15 16:49:26,961 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Creating a new application reference for app application_1436941682764_0006
2015-07-15 16:49:26,961 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0006	CONTAINERID=container_1436941682764_0006_01_000001
2015-07-15 16:49:26,961 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0006 transitioned from NEW to INITING
2015-07-15 16:49:26,961 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0006_01_000001 to application application_1436941682764_0006
2015-07-15 16:49:26,961 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0006 transitioned from INITING to RUNNING
2015-07-15 16:49:26,961 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0006_01_000001 transitioned from NEW to LOCALIZING
2015-07-15 16:49:26,961 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0006
2015-07-15 16:49:26,961 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0006/job.splitmetainfo transitioned from INIT to DOWNLOADING
2015-07-15 16:49:26,961 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0006/job.jar transitioned from INIT to DOWNLOADING
2015-07-15 16:49:26,961 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0006/job.split transitioned from INIT to DOWNLOADING
2015-07-15 16:49:26,961 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0006/job.xml transitioned from INIT to DOWNLOADING
2015-07-15 16:49:26,961 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1436941682764_0006_01_000001
2015-07-15 16:49:26,967 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1436941682764_0006_01_000001.tokens. Credentials list: 
2015-07-15 16:49:26,969 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user liyaohui
2015-07-15 16:49:26,983 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1436941682764_0006_01_000001.tokens to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0006/container_1436941682764_0006_01_000001.tokens
2015-07-15 16:49:26,983 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: CWD set to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0006 = file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0006
2015-07-15 16:49:27,086 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0006/job.splitmetainfo transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:49:27,338 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0006/job.jar transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:49:27,463 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0005_01_000001
2015-07-15 16:49:27,484 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0006/job.split transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:49:27,512 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0006/job.xml transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:49:27,512 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0006_01_000001 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:49:27,532 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0006_01_000001 transitioned from LOCALIZED to RUNNING
2015-07-15 16:49:27,557 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0006/container_1436941682764_0006_01_000001/default_container_executor.sh]
2015-07-15 16:49:27,948 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:28,949 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:29,951 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:30,463 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0006_01_000001
2015-07-15 16:49:30,478 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 15909 for container-id container_1436941682764_0006_01_000001: 147.8 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:49:30,952 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:31,953 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:32,954 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:33,150 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0006_000001 (auth:SIMPLE)
2015-07-15 16:49:33,154 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0006_01_000002 by user liyaohui
2015-07-15 16:49:33,154 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0006	CONTAINERID=container_1436941682764_0006_01_000002
2015-07-15 16:49:33,154 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0006_01_000002 to application application_1436941682764_0006
2015-07-15 16:49:33,155 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0006_01_000002 transitioned from NEW to LOCALIZING
2015-07-15 16:49:33,155 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0006
2015-07-15 16:49:33,155 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1436941682764_0006
2015-07-15 16:49:33,155 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-07-15 16:49:33,155 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1436941682764_0006
2015-07-15 16:49:33,155 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0006_01_000002 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:49:33,176 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0006_01_000002 transitioned from LOCALIZED to RUNNING
2015-07-15 16:49:33,194 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0006/container_1436941682764_0006_01_000002/default_container_executor.sh]
2015-07-15 16:49:33,478 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0006_01_000002
2015-07-15 16:49:33,497 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 15909 for container-id container_1436941682764_0006_01_000001: 243.6 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:49:33,521 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 16032 for container-id container_1436941682764_0006_01_000002: 42.3 MB of 1 GB physical memory used; 511.8 MB of 2.1 GB virtual memory used
2015-07-15 16:49:33,955 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:33,955 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:34,956 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:34,956 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:35,958 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:35,958 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:36,040 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0006_01_000002
2015-07-15 16:49:36,041 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0006	CONTAINERID=container_1436941682764_0006_01_000002
2015-07-15 16:49:36,041 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0006_01_000002 transitioned from RUNNING to KILLING
2015-07-15 16:49:36,041 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0006_01_000002
2015-07-15 16:49:36,041 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:36,041 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-07-15 16:49:36,046 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1436941682764_0006_01_000002 is : 143
2015-07-15 16:49:36,062 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0006_01_000002 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-07-15 16:49:36,063 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0006/container_1436941682764_0006_01_000002
2015-07-15 16:49:36,064 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0006	CONTAINERID=container_1436941682764_0006_01_000002
2015-07-15 16:49:36,064 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0006_01_000002 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-07-15 16:49:36,064 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0006_01_000002 from application application_1436941682764_0006
2015-07-15 16:49:36,064 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0006
2015-07-15 16:49:36,521 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0006_01_000002
2015-07-15 16:49:36,535 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 15909 for container-id container_1436941682764_0006_01_000001: 243.9 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:49:37,042 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:37,042 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-07-15 16:49:37,042 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0006_01_000002
2015-07-15 16:49:38,044 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:39,044 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:39,070 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0006_01_000003 by user liyaohui
2015-07-15 16:49:39,071 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0006	CONTAINERID=container_1436941682764_0006_01_000003
2015-07-15 16:49:39,071 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0006_01_000003 to application application_1436941682764_0006
2015-07-15 16:49:39,071 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0006_01_000003 transitioned from NEW to LOCALIZING
2015-07-15 16:49:39,071 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0006
2015-07-15 16:49:39,071 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1436941682764_0006
2015-07-15 16:49:39,071 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-07-15 16:49:39,072 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1436941682764_0006
2015-07-15 16:49:39,072 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0006_01_000003 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:49:39,093 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0006_01_000003 transitioned from LOCALIZED to RUNNING
2015-07-15 16:49:39,112 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0006/container_1436941682764_0006_01_000003/default_container_executor.sh]
2015-07-15 16:49:39,535 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0006_01_000003
2015-07-15 16:49:39,549 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 15909 for container-id container_1436941682764_0006_01_000001: 244.0 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:49:39,564 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 16117 for container-id container_1436941682764_0006_01_000003: 57.3 MB of 1 GB physical memory used; 513.2 MB of 2.1 GB virtual memory used
2015-07-15 16:49:40,045 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:40,046 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:41,047 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:41,047 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:42,048 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:42,048 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:42,580 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 15909 for container-id container_1436941682764_0006_01_000001: 244.0 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:49:42,595 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 16117 for container-id container_1436941682764_0006_01_000003: 140.3 MB of 1 GB physical memory used; 537.3 MB of 2.1 GB virtual memory used
2015-07-15 16:49:42,775 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0006_01_000003
2015-07-15 16:49:42,775 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0006_01_000003 transitioned from RUNNING to KILLING
2015-07-15 16:49:42,775 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0006	CONTAINERID=container_1436941682764_0006_01_000003
2015-07-15 16:49:42,775 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0006_01_000003
2015-07-15 16:49:42,775 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:42,776 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-07-15 16:49:42,780 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1436941682764_0006_01_000003 is : 143
2015-07-15 16:49:42,792 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0006_01_000003 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-07-15 16:49:42,793 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0006/container_1436941682764_0006_01_000003
2015-07-15 16:49:42,794 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0006	CONTAINERID=container_1436941682764_0006_01_000003
2015-07-15 16:49:42,794 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0006_01_000003 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-07-15 16:49:42,794 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0006_01_000003 from application application_1436941682764_0006
2015-07-15 16:49:42,794 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0006
2015-07-15 16:49:43,778 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:43,778 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-07-15 16:49:43,779 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0006_01_000003
2015-07-15 16:49:44,779 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:45,595 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0006_01_000003
2015-07-15 16:49:45,609 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 15909 for container-id container_1436941682764_0006_01_000001: 245.5 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:49:45,781 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:46,782 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:47,783 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:48,623 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 15909 for container-id container_1436941682764_0006_01_000001: 245.5 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:49:48,783 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:49,221 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container container_1436941682764_0006_01_000001 succeeded 
2015-07-15 16:49:49,222 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0006_01_000001 transitioned from RUNNING to EXITED_WITH_SUCCESS
2015-07-15 16:49:49,222 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0006_01_000001
2015-07-15 16:49:49,233 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0006/container_1436941682764_0006_01_000001
2015-07-15 16:49:49,233 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Succeeded	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0006	CONTAINERID=container_1436941682764_0006_01_000001
2015-07-15 16:49:49,233 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0006_01_000001 transitioned from EXITED_WITH_SUCCESS to DONE
2015-07-15 16:49:49,233 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0006_01_000001 from application application_1436941682764_0006
2015-07-15 16:49:49,233 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0006
2015-07-15 16:49:49,784 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_COMPLETE diagnostics: "" exit_status: 0
2015-07-15 16:49:49,784 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0006_01_000001
2015-07-15 16:49:49,789 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0006_000001 (auth:SIMPLE)
2015-07-15 16:49:49,793 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0006_01_000001
2015-07-15 16:49:50,786 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0006 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP
2015-07-15 16:49:50,786 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0006
2015-07-15 16:49:50,786 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_STOP for appId application_1436941682764_0006
2015-07-15 16:49:50,786 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0006 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED
2015-07-15 16:49:50,786 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler: Scheduling Log Deletion for application: application_1436941682764_0006, with delay of 10800 seconds
2015-07-15 16:49:50,791 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0007_000001 (auth:SIMPLE)
2015-07-15 16:49:50,801 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0007_01_000001 by user liyaohui
2015-07-15 16:49:50,801 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Creating a new application reference for app application_1436941682764_0007
2015-07-15 16:49:50,801 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0007	CONTAINERID=container_1436941682764_0007_01_000001
2015-07-15 16:49:50,801 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0007 transitioned from NEW to INITING
2015-07-15 16:49:50,801 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0007_01_000001 to application application_1436941682764_0007
2015-07-15 16:49:50,801 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0007 transitioned from INITING to RUNNING
2015-07-15 16:49:50,801 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0007_01_000001 transitioned from NEW to LOCALIZING
2015-07-15 16:49:50,801 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0007
2015-07-15 16:49:50,802 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0007/job.splitmetainfo transitioned from INIT to DOWNLOADING
2015-07-15 16:49:50,802 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0007/job.jar transitioned from INIT to DOWNLOADING
2015-07-15 16:49:50,802 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0007/job.split transitioned from INIT to DOWNLOADING
2015-07-15 16:49:50,802 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0007/job.xml transitioned from INIT to DOWNLOADING
2015-07-15 16:49:50,802 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1436941682764_0007_01_000001
2015-07-15 16:49:50,808 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1436941682764_0007_01_000001.tokens. Credentials list: 
2015-07-15 16:49:50,810 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user liyaohui
2015-07-15 16:49:50,820 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1436941682764_0007_01_000001.tokens to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0007/container_1436941682764_0007_01_000001.tokens
2015-07-15 16:49:50,820 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: CWD set to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0007 = file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0007
2015-07-15 16:49:50,896 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0007/job.splitmetainfo transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:49:51,145 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0007/job.jar transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:49:51,167 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0007/job.split transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:49:51,188 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0007/job.xml transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:49:51,188 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0007_01_000001 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:49:51,208 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0007_01_000001 transitioned from LOCALIZED to RUNNING
2015-07-15 16:49:51,227 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0007/container_1436941682764_0007_01_000001/default_container_executor.sh]
2015-07-15 16:49:51,623 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0007_01_000001
2015-07-15 16:49:51,623 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0006_01_000001
2015-07-15 16:49:51,638 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 16351 for container-id container_1436941682764_0007_01_000001: 54.2 MB of 2 GB physical memory used; 1.3 GB of 4.2 GB virtual memory used
2015-07-15 16:49:51,786 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:52,787 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:53,788 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:54,656 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 16351 for container-id container_1436941682764_0007_01_000001: 212.1 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:49:54,789 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:55,791 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:56,762 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0007_000001 (auth:SIMPLE)
2015-07-15 16:49:56,765 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0007_01_000002 by user liyaohui
2015-07-15 16:49:56,765 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0007	CONTAINERID=container_1436941682764_0007_01_000002
2015-07-15 16:49:56,765 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0007_01_000002 to application application_1436941682764_0007
2015-07-15 16:49:56,766 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0007_01_000002 transitioned from NEW to LOCALIZING
2015-07-15 16:49:56,766 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0007
2015-07-15 16:49:56,766 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1436941682764_0007
2015-07-15 16:49:56,766 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-07-15 16:49:56,766 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1436941682764_0007
2015-07-15 16:49:56,767 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0007_01_000002 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:49:56,787 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0007_01_000002 transitioned from LOCALIZED to RUNNING
2015-07-15 16:49:56,793 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:56,793 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:56,806 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0007/container_1436941682764_0007_01_000002/default_container_executor.sh]
2015-07-15 16:49:57,656 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0007_01_000002
2015-07-15 16:49:57,670 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 16351 for container-id container_1436941682764_0007_01_000001: 253.7 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:49:57,684 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 16474 for container-id container_1436941682764_0007_01_000002: 64.1 MB of 1 GB physical memory used; 515.4 MB of 2.1 GB virtual memory used
2015-07-15 16:49:57,794 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:57,794 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:58,796 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:58,796 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:59,495 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0007_01_000002
2015-07-15 16:49:59,495 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0007	CONTAINERID=container_1436941682764_0007_01_000002
2015-07-15 16:49:59,495 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0007_01_000002 transitioned from RUNNING to KILLING
2015-07-15 16:49:59,495 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0007_01_000002
2015-07-15 16:49:59,495 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:49:59,495 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-07-15 16:49:59,499 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1436941682764_0007_01_000002 is : 143
2015-07-15 16:49:59,513 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0007_01_000002 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-07-15 16:49:59,513 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0007	CONTAINERID=container_1436941682764_0007_01_000002
2015-07-15 16:49:59,513 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0007_01_000002 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-07-15 16:49:59,513 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0007_01_000002 from application application_1436941682764_0007
2015-07-15 16:49:59,513 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0007
2015-07-15 16:49:59,513 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0007/container_1436941682764_0007_01_000002
2015-07-15 16:50:00,496 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:00,496 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-07-15 16:50:00,496 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0007_01_000002
2015-07-15 16:50:00,685 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0007_01_000002
2015-07-15 16:50:00,700 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 16351 for container-id container_1436941682764_0007_01_000001: 253.8 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:50:01,498 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:01,679 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0007_01_000003 by user liyaohui
2015-07-15 16:50:01,679 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0007	CONTAINERID=container_1436941682764_0007_01_000003
2015-07-15 16:50:01,679 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0007_01_000003 to application application_1436941682764_0007
2015-07-15 16:50:01,680 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0007_01_000003 transitioned from NEW to LOCALIZING
2015-07-15 16:50:01,681 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0007
2015-07-15 16:50:01,681 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1436941682764_0007
2015-07-15 16:50:01,681 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-07-15 16:50:01,681 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1436941682764_0007
2015-07-15 16:50:01,681 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0007_01_000003 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:50:01,722 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0007_01_000003 transitioned from LOCALIZED to RUNNING
2015-07-15 16:50:01,741 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0007/container_1436941682764_0007_01_000003/default_container_executor.sh]
2015-07-15 16:50:02,499 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:02,499 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:03,500 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:03,500 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:03,700 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0007_01_000003
2015-07-15 16:50:03,715 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 16561 for container-id container_1436941682764_0007_01_000003: 101.9 MB of 1 GB physical memory used; 528.9 MB of 2.1 GB virtual memory used
2015-07-15 16:50:03,729 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 16351 for container-id container_1436941682764_0007_01_000001: 253.6 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:50:04,380 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0007_01_000003
2015-07-15 16:50:04,380 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0007	CONTAINERID=container_1436941682764_0007_01_000003
2015-07-15 16:50:04,380 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0007_01_000003 transitioned from RUNNING to KILLING
2015-07-15 16:50:04,380 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0007_01_000003
2015-07-15 16:50:04,381 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:04,381 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-07-15 16:50:04,386 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1436941682764_0007_01_000003 is : 143
2015-07-15 16:50:04,397 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0007_01_000003 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-07-15 16:50:04,398 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0007/container_1436941682764_0007_01_000003
2015-07-15 16:50:04,398 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0007	CONTAINERID=container_1436941682764_0007_01_000003
2015-07-15 16:50:04,398 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0007_01_000003 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-07-15 16:50:04,398 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0007_01_000003 from application application_1436941682764_0007
2015-07-15 16:50:04,398 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0007
2015-07-15 16:50:05,382 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:05,382 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-07-15 16:50:05,382 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0007_01_000003
2015-07-15 16:50:06,383 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:06,729 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0007_01_000003
2015-07-15 16:50:06,743 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 16351 for container-id container_1436941682764_0007_01_000001: 255.3 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:50:07,384 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:08,385 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:09,386 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:09,756 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 16351 for container-id container_1436941682764_0007_01_000001: 255.3 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:50:10,387 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:10,821 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container container_1436941682764_0007_01_000001 succeeded 
2015-07-15 16:50:10,821 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0007_01_000001 transitioned from RUNNING to EXITED_WITH_SUCCESS
2015-07-15 16:50:10,821 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0007_01_000001
2015-07-15 16:50:10,841 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0007/container_1436941682764_0007_01_000001
2015-07-15 16:50:10,841 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Succeeded	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0007	CONTAINERID=container_1436941682764_0007_01_000001
2015-07-15 16:50:10,841 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0007_01_000001 transitioned from EXITED_WITH_SUCCESS to DONE
2015-07-15 16:50:10,841 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0007_01_000001 from application application_1436941682764_0007
2015-07-15 16:50:10,842 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0007
2015-07-15 16:50:11,388 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_COMPLETE diagnostics: "" exit_status: 0
2015-07-15 16:50:11,388 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0007_01_000001
2015-07-15 16:50:11,398 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0007_000001 (auth:SIMPLE)
2015-07-15 16:50:11,400 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0007_01_000001
2015-07-15 16:50:12,389 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0007 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP
2015-07-15 16:50:12,389 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0007
2015-07-15 16:50:12,392 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_STOP for appId application_1436941682764_0007
2015-07-15 16:50:12,392 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0007 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED
2015-07-15 16:50:12,392 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler: Scheduling Log Deletion for application: application_1436941682764_0007, with delay of 10800 seconds
2015-07-15 16:50:12,395 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0008_000001 (auth:SIMPLE)
2015-07-15 16:50:12,404 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0008_01_000001 by user liyaohui
2015-07-15 16:50:12,404 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Creating a new application reference for app application_1436941682764_0008
2015-07-15 16:50:12,404 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0008	CONTAINERID=container_1436941682764_0008_01_000001
2015-07-15 16:50:12,404 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0008 transitioned from NEW to INITING
2015-07-15 16:50:12,404 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0008_01_000001 to application application_1436941682764_0008
2015-07-15 16:50:12,404 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0008 transitioned from INITING to RUNNING
2015-07-15 16:50:12,405 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0008_01_000001 transitioned from NEW to LOCALIZING
2015-07-15 16:50:12,405 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0008
2015-07-15 16:50:12,405 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0008/job.splitmetainfo transitioned from INIT to DOWNLOADING
2015-07-15 16:50:12,405 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0008/job.jar transitioned from INIT to DOWNLOADING
2015-07-15 16:50:12,405 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0008/job.split transitioned from INIT to DOWNLOADING
2015-07-15 16:50:12,405 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0008/job.xml transitioned from INIT to DOWNLOADING
2015-07-15 16:50:12,405 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1436941682764_0008_01_000001
2015-07-15 16:50:12,410 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1436941682764_0008_01_000001.tokens. Credentials list: 
2015-07-15 16:50:12,411 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user liyaohui
2015-07-15 16:50:12,421 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1436941682764_0008_01_000001.tokens to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0008/container_1436941682764_0008_01_000001.tokens
2015-07-15 16:50:12,421 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: CWD set to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0008 = file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0008
2015-07-15 16:50:12,507 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0008/job.splitmetainfo transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:50:12,757 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0007_01_000001
2015-07-15 16:50:12,762 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0008/job.jar transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:50:12,786 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0008/job.split transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:50:12,806 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0008/job.xml transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:50:12,807 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0008_01_000001 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:50:12,827 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0008_01_000001 transitioned from LOCALIZED to RUNNING
2015-07-15 16:50:12,847 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0008/container_1436941682764_0008_01_000001/default_container_executor.sh]
2015-07-15 16:50:13,389 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:14,390 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:15,391 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:15,757 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0008_01_000001
2015-07-15 16:50:15,770 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 16793 for container-id container_1436941682764_0008_01_000001: 158.2 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:50:16,393 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:17,394 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:18,365 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0008_000001 (auth:SIMPLE)
2015-07-15 16:50:18,369 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0008_01_000002 by user liyaohui
2015-07-15 16:50:18,369 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0008	CONTAINERID=container_1436941682764_0008_01_000002
2015-07-15 16:50:18,369 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0008_01_000002 to application application_1436941682764_0008
2015-07-15 16:50:18,370 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0008_01_000002 transitioned from NEW to LOCALIZING
2015-07-15 16:50:18,370 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0008
2015-07-15 16:50:18,370 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1436941682764_0008
2015-07-15 16:50:18,370 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-07-15 16:50:18,370 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1436941682764_0008
2015-07-15 16:50:18,370 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0008_01_000002 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:50:18,391 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0008_01_000002 transitioned from LOCALIZED to RUNNING
2015-07-15 16:50:18,395 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:18,395 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:18,413 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0008/container_1436941682764_0008_01_000002/default_container_executor.sh]
2015-07-15 16:50:18,771 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0008_01_000002
2015-07-15 16:50:18,785 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 16916 for container-id container_1436941682764_0008_01_000002: 49.3 MB of 1 GB physical memory used; 512.0 MB of 2.1 GB virtual memory used
2015-07-15 16:50:18,798 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 16793 for container-id container_1436941682764_0008_01_000001: 255.3 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:50:19,396 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:19,396 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:20,398 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:20,398 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:21,082 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0008_01_000002
2015-07-15 16:50:21,082 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0008	CONTAINERID=container_1436941682764_0008_01_000002
2015-07-15 16:50:21,083 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0008_01_000002 transitioned from RUNNING to KILLING
2015-07-15 16:50:21,083 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0008_01_000002
2015-07-15 16:50:21,083 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:21,083 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-07-15 16:50:21,087 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1436941682764_0008_01_000002 is : 143
2015-07-15 16:50:21,105 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0008_01_000002 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-07-15 16:50:21,106 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0008/container_1436941682764_0008_01_000002
2015-07-15 16:50:21,107 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0008	CONTAINERID=container_1436941682764_0008_01_000002
2015-07-15 16:50:21,107 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0008_01_000002 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-07-15 16:50:21,107 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0008_01_000002 from application application_1436941682764_0008
2015-07-15 16:50:21,107 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0008
2015-07-15 16:50:21,799 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0008_01_000002
2015-07-15 16:50:21,812 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 16793 for container-id container_1436941682764_0008_01_000001: 255.5 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:50:22,084 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:22,084 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-07-15 16:50:22,084 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0008_01_000002
2015-07-15 16:50:23,085 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:23,281 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0008_01_000003 by user liyaohui
2015-07-15 16:50:23,281 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0008	CONTAINERID=container_1436941682764_0008_01_000003
2015-07-15 16:50:23,281 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0008_01_000003 to application application_1436941682764_0008
2015-07-15 16:50:23,282 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0008_01_000003 transitioned from NEW to LOCALIZING
2015-07-15 16:50:23,282 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0008
2015-07-15 16:50:23,282 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1436941682764_0008
2015-07-15 16:50:23,282 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-07-15 16:50:23,282 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1436941682764_0008
2015-07-15 16:50:23,282 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0008_01_000003 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:50:23,304 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0008_01_000003 transitioned from LOCALIZED to RUNNING
2015-07-15 16:50:23,324 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0008/container_1436941682764_0008_01_000003/default_container_executor.sh]
2015-07-15 16:50:24,086 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:24,086 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:24,812 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0008_01_000003
2015-07-15 16:50:24,826 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 16793 for container-id container_1436941682764_0008_01_000001: 255.7 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:50:24,840 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 17001 for container-id container_1436941682764_0008_01_000003: 90.5 MB of 1 GB physical memory used; 525.7 MB of 2.1 GB virtual memory used
2015-07-15 16:50:25,088 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:25,088 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:25,945 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0008_01_000003
2015-07-15 16:50:25,945 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0008	CONTAINERID=container_1436941682764_0008_01_000003
2015-07-15 16:50:25,945 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:25,945 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:25,945 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0008_01_000003 transitioned from RUNNING to KILLING
2015-07-15 16:50:25,945 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0008_01_000003
2015-07-15 16:50:25,956 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1436941682764_0008_01_000003 is : 143
2015-07-15 16:50:25,969 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0008_01_000003 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-07-15 16:50:25,970 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0008/container_1436941682764_0008_01_000003
2015-07-15 16:50:25,971 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0008	CONTAINERID=container_1436941682764_0008_01_000003
2015-07-15 16:50:25,971 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0008_01_000003 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-07-15 16:50:25,971 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0008_01_000003 from application application_1436941682764_0008
2015-07-15 16:50:25,971 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0008
2015-07-15 16:50:26,946 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:26,947 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-07-15 16:50:26,947 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0008_01_000003
2015-07-15 16:50:27,840 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0008_01_000003
2015-07-15 16:50:27,854 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 16793 for container-id container_1436941682764_0008_01_000001: 257.5 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:50:27,948 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:28,949 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:29,950 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:30,867 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 16793 for container-id container_1436941682764_0008_01_000001: 257.5 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:50:30,951 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:31,952 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:32,265 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container container_1436941682764_0008_01_000001 succeeded 
2015-07-15 16:50:32,265 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0008_01_000001 transitioned from RUNNING to EXITED_WITH_SUCCESS
2015-07-15 16:50:32,265 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0008_01_000001
2015-07-15 16:50:32,276 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0008/container_1436941682764_0008_01_000001
2015-07-15 16:50:32,277 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Succeeded	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0008	CONTAINERID=container_1436941682764_0008_01_000001
2015-07-15 16:50:32,277 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0008_01_000001 transitioned from EXITED_WITH_SUCCESS to DONE
2015-07-15 16:50:32,277 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0008_01_000001 from application application_1436941682764_0008
2015-07-15 16:50:32,277 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0008
2015-07-15 16:50:32,952 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 8 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_COMPLETE diagnostics: "" exit_status: 0
2015-07-15 16:50:32,953 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0008_01_000001
2015-07-15 16:50:32,956 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0008_000001 (auth:SIMPLE)
2015-07-15 16:50:32,959 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0008_01_000001
2015-07-15 16:50:33,867 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0008_01_000001
2015-07-15 16:50:33,954 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0008 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP
2015-07-15 16:50:33,954 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_STOP for appId application_1436941682764_0008
2015-07-15 16:50:33,954 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0008 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED
2015-07-15 16:50:33,954 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler: Scheduling Log Deletion for application: application_1436941682764_0008, with delay of 10800 seconds
2015-07-15 16:50:33,955 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0008
2015-07-15 16:50:33,960 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0009_000001 (auth:SIMPLE)
2015-07-15 16:50:33,966 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0009_01_000001 by user liyaohui
2015-07-15 16:50:33,967 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Creating a new application reference for app application_1436941682764_0009
2015-07-15 16:50:33,967 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0009	CONTAINERID=container_1436941682764_0009_01_000001
2015-07-15 16:50:33,967 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0009 transitioned from NEW to INITING
2015-07-15 16:50:33,967 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0009_01_000001 to application application_1436941682764_0009
2015-07-15 16:50:33,967 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0009 transitioned from INITING to RUNNING
2015-07-15 16:50:33,967 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0009_01_000001 transitioned from NEW to LOCALIZING
2015-07-15 16:50:33,967 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0009
2015-07-15 16:50:33,967 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0009/job.splitmetainfo transitioned from INIT to DOWNLOADING
2015-07-15 16:50:33,967 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0009/job.jar transitioned from INIT to DOWNLOADING
2015-07-15 16:50:33,968 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0009/job.split transitioned from INIT to DOWNLOADING
2015-07-15 16:50:33,968 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0009/job.xml transitioned from INIT to DOWNLOADING
2015-07-15 16:50:33,968 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1436941682764_0009_01_000001
2015-07-15 16:50:33,972 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1436941682764_0009_01_000001.tokens. Credentials list: 
2015-07-15 16:50:33,974 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user liyaohui
2015-07-15 16:50:33,984 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1436941682764_0009_01_000001.tokens to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0009/container_1436941682764_0009_01_000001.tokens
2015-07-15 16:50:33,984 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: CWD set to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0009 = file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0009
2015-07-15 16:50:34,065 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0009/job.splitmetainfo transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:50:34,336 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0009/job.jar transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:50:34,355 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0009/job.split transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:50:34,375 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0009/job.xml transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:50:34,375 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0009_01_000001 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:50:34,397 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0009_01_000001 transitioned from LOCALIZED to RUNNING
2015-07-15 16:50:34,416 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0009/container_1436941682764_0009_01_000001/default_container_executor.sh]
2015-07-15 16:50:34,954 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:35,955 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:36,868 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0009_01_000001
2015-07-15 16:50:36,882 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 17231 for container-id container_1436941682764_0009_01_000001: 154.4 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:50:36,956 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:37,957 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:38,959 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:39,896 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 17231 for container-id container_1436941682764_0009_01_000001: 253.8 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:50:39,920 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0009_000001 (auth:SIMPLE)
2015-07-15 16:50:39,924 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0009_01_000002 by user liyaohui
2015-07-15 16:50:39,924 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0009	CONTAINERID=container_1436941682764_0009_01_000002
2015-07-15 16:50:39,924 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0009_01_000002 to application application_1436941682764_0009
2015-07-15 16:50:39,924 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0009_01_000002 transitioned from NEW to LOCALIZING
2015-07-15 16:50:39,924 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0009
2015-07-15 16:50:39,924 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1436941682764_0009
2015-07-15 16:50:39,924 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-07-15 16:50:39,925 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1436941682764_0009
2015-07-15 16:50:39,925 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0009_01_000002 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:50:39,945 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0009_01_000002 transitioned from LOCALIZED to RUNNING
2015-07-15 16:50:39,960 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:39,960 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:39,965 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0009/container_1436941682764_0009_01_000002/default_container_executor.sh]
2015-07-15 16:50:40,960 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:40,961 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:41,962 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:41,962 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:42,644 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0009_01_000002
2015-07-15 16:50:42,644 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0009	CONTAINERID=container_1436941682764_0009_01_000002
2015-07-15 16:50:42,644 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0009_01_000002 transitioned from RUNNING to KILLING
2015-07-15 16:50:42,644 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0009_01_000002
2015-07-15 16:50:42,644 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:42,644 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-07-15 16:50:42,648 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1436941682764_0009_01_000002 is : 143
2015-07-15 16:50:42,660 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0009_01_000002 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-07-15 16:50:42,660 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0009/container_1436941682764_0009_01_000002
2015-07-15 16:50:42,661 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0009	CONTAINERID=container_1436941682764_0009_01_000002
2015-07-15 16:50:42,661 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0009_01_000002 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-07-15 16:50:42,661 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0009_01_000002 from application application_1436941682764_0009
2015-07-15 16:50:42,661 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0009
2015-07-15 16:50:42,896 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0009_01_000002
2015-07-15 16:50:42,896 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0009_01_000002
2015-07-15 16:50:42,910 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 17231 for container-id container_1436941682764_0009_01_000001: 254.3 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:50:43,645 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:43,645 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-07-15 16:50:43,645 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0009_01_000002
2015-07-15 16:50:44,646 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:44,833 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0009_01_000003 by user liyaohui
2015-07-15 16:50:44,833 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0009	CONTAINERID=container_1436941682764_0009_01_000003
2015-07-15 16:50:44,833 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0009_01_000003 to application application_1436941682764_0009
2015-07-15 16:50:44,834 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0009_01_000003 transitioned from NEW to LOCALIZING
2015-07-15 16:50:44,834 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0009
2015-07-15 16:50:44,834 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1436941682764_0009
2015-07-15 16:50:44,834 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-07-15 16:50:44,834 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1436941682764_0009
2015-07-15 16:50:44,834 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0009_01_000003 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:50:44,855 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0009_01_000003 transitioned from LOCALIZED to RUNNING
2015-07-15 16:50:44,874 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0009/container_1436941682764_0009_01_000003/default_container_executor.sh]
2015-07-15 16:50:45,647 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:45,648 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:45,910 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0009_01_000003
2015-07-15 16:50:45,924 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 17231 for container-id container_1436941682764_0009_01_000001: 254.4 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:50:45,938 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 17439 for container-id container_1436941682764_0009_01_000003: 70.4 MB of 1 GB physical memory used; 519.2 MB of 2.1 GB virtual memory used
2015-07-15 16:50:46,649 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:46,649 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:47,502 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0009_01_000003
2015-07-15 16:50:47,502 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0009	CONTAINERID=container_1436941682764_0009_01_000003
2015-07-15 16:50:47,502 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0009_01_000003 transitioned from RUNNING to KILLING
2015-07-15 16:50:47,502 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0009_01_000003
2015-07-15 16:50:47,503 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:47,503 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-07-15 16:50:47,510 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1436941682764_0009_01_000003 is : 143
2015-07-15 16:50:47,523 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0009_01_000003 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-07-15 16:50:47,523 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0009	CONTAINERID=container_1436941682764_0009_01_000003
2015-07-15 16:50:47,523 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0009_01_000003 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-07-15 16:50:47,523 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0009_01_000003 from application application_1436941682764_0009
2015-07-15 16:50:47,523 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0009
2015-07-15 16:50:47,523 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0009/container_1436941682764_0009_01_000003
2015-07-15 16:50:48,504 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:48,504 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-07-15 16:50:48,505 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0009_01_000003
2015-07-15 16:50:48,938 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0009_01_000003
2015-07-15 16:50:48,952 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 17231 for container-id container_1436941682764_0009_01_000001: 256.1 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:50:49,505 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:50,506 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:51,507 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:51,966 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 17231 for container-id container_1436941682764_0009_01_000001: 256.1 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:50:52,508 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:53,509 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:53,940 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container container_1436941682764_0009_01_000001 succeeded 
2015-07-15 16:50:53,941 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0009_01_000001 transitioned from RUNNING to EXITED_WITH_SUCCESS
2015-07-15 16:50:53,941 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0009_01_000001
2015-07-15 16:50:53,952 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0009/container_1436941682764_0009_01_000001
2015-07-15 16:50:53,952 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Succeeded	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0009	CONTAINERID=container_1436941682764_0009_01_000001
2015-07-15 16:50:53,952 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0009_01_000001 transitioned from EXITED_WITH_SUCCESS to DONE
2015-07-15 16:50:53,953 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0009_01_000001 from application application_1436941682764_0009
2015-07-15 16:50:53,953 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0009
2015-07-15 16:50:54,510 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 9 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_COMPLETE diagnostics: "" exit_status: 0
2015-07-15 16:50:54,510 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0009_01_000001
2015-07-15 16:50:54,515 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0009_000001 (auth:SIMPLE)
2015-07-15 16:50:54,518 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0009_01_000001
2015-07-15 16:50:54,966 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0009_01_000001
2015-07-15 16:50:55,511 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0009 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP
2015-07-15 16:50:55,511 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0009
2015-07-15 16:50:55,516 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_STOP for appId application_1436941682764_0009
2015-07-15 16:50:55,516 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0009 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED
2015-07-15 16:50:55,516 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler: Scheduling Log Deletion for application: application_1436941682764_0009, with delay of 10800 seconds
2015-07-15 16:50:55,517 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0010_000001 (auth:SIMPLE)
2015-07-15 16:50:55,522 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0010_01_000001 by user liyaohui
2015-07-15 16:50:55,522 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Creating a new application reference for app application_1436941682764_0010
2015-07-15 16:50:55,522 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0010	CONTAINERID=container_1436941682764_0010_01_000001
2015-07-15 16:50:55,522 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0010 transitioned from NEW to INITING
2015-07-15 16:50:55,523 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0010_01_000001 to application application_1436941682764_0010
2015-07-15 16:50:55,523 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0010 transitioned from INITING to RUNNING
2015-07-15 16:50:55,523 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0010_01_000001 transitioned from NEW to LOCALIZING
2015-07-15 16:50:55,523 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0010
2015-07-15 16:50:55,524 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0010/job.splitmetainfo transitioned from INIT to DOWNLOADING
2015-07-15 16:50:55,524 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0010/job.jar transitioned from INIT to DOWNLOADING
2015-07-15 16:50:55,524 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0010/job.split transitioned from INIT to DOWNLOADING
2015-07-15 16:50:55,524 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0010/job.xml transitioned from INIT to DOWNLOADING
2015-07-15 16:50:55,524 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1436941682764_0010_01_000001
2015-07-15 16:50:55,529 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1436941682764_0010_01_000001.tokens. Credentials list: 
2015-07-15 16:50:55,531 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user liyaohui
2015-07-15 16:50:55,542 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1436941682764_0010_01_000001.tokens to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0010/container_1436941682764_0010_01_000001.tokens
2015-07-15 16:50:55,542 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: CWD set to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0010 = file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0010
2015-07-15 16:50:55,623 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0010/job.splitmetainfo transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:50:55,882 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0010/job.jar transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:50:55,904 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0010/job.split transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:50:55,936 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0010/job.xml transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:50:55,936 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0010_01_000001 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:50:55,957 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0010_01_000001 transitioned from LOCALIZED to RUNNING
2015-07-15 16:50:55,978 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0010/container_1436941682764_0010_01_000001/default_container_executor.sh]
2015-07-15 16:50:56,511 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:57,512 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:57,966 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0010_01_000001
2015-07-15 16:50:57,981 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 17669 for container-id container_1436941682764_0010_01_000001: 106.4 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:50:58,514 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:50:59,515 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:00,516 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:00,995 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 17669 for container-id container_1436941682764_0010_01_000001: 255.1 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:51:01,502 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0010_000001 (auth:SIMPLE)
2015-07-15 16:51:01,506 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0010_01_000002 by user liyaohui
2015-07-15 16:51:01,506 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0010	CONTAINERID=container_1436941682764_0010_01_000002
2015-07-15 16:51:01,506 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0010_01_000002 to application application_1436941682764_0010
2015-07-15 16:51:01,506 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0010_01_000002 transitioned from NEW to LOCALIZING
2015-07-15 16:51:01,506 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0010
2015-07-15 16:51:01,506 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1436941682764_0010
2015-07-15 16:51:01,506 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-07-15 16:51:01,506 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1436941682764_0010
2015-07-15 16:51:01,507 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0010_01_000002 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:51:01,517 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:01,517 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:01,529 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0010_01_000002 transitioned from LOCALIZED to RUNNING
2015-07-15 16:51:01,548 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0010/container_1436941682764_0010_01_000002/default_container_executor.sh]
2015-07-15 16:51:02,520 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:02,520 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:03,522 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:03,522 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:03,995 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0010_01_000002
2015-07-15 16:51:04,018 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 17669 for container-id container_1436941682764_0010_01_000001: 254.9 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:51:04,035 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 17794 for container-id container_1436941682764_0010_01_000002: 236.0 MB of 1 GB physical memory used; 534.3 MB of 2.1 GB virtual memory used
2015-07-15 16:51:04,335 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0010_01_000002
2015-07-15 16:51:04,335 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0010	CONTAINERID=container_1436941682764_0010_01_000002
2015-07-15 16:51:04,335 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0010_01_000002 transitioned from RUNNING to KILLING
2015-07-15 16:51:04,335 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0010_01_000002
2015-07-15 16:51:04,336 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:04,336 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-07-15 16:51:04,340 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1436941682764_0010_01_000002 is : 143
2015-07-15 16:51:04,352 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0010_01_000002 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-07-15 16:51:04,353 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0010/container_1436941682764_0010_01_000002
2015-07-15 16:51:04,353 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0010	CONTAINERID=container_1436941682764_0010_01_000002
2015-07-15 16:51:04,353 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0010_01_000002 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-07-15 16:51:04,353 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0010_01_000002 from application application_1436941682764_0010
2015-07-15 16:51:04,353 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0010
2015-07-15 16:51:05,337 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:05,337 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-07-15 16:51:05,337 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0010_01_000002
2015-07-15 16:51:06,338 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:06,418 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0010_01_000003 by user liyaohui
2015-07-15 16:51:06,418 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0010	CONTAINERID=container_1436941682764_0010_01_000003
2015-07-15 16:51:06,418 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0010_01_000003 to application application_1436941682764_0010
2015-07-15 16:51:06,418 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0010_01_000003 transitioned from NEW to LOCALIZING
2015-07-15 16:51:06,418 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0010
2015-07-15 16:51:06,418 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1436941682764_0010
2015-07-15 16:51:06,418 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-07-15 16:51:06,419 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1436941682764_0010
2015-07-15 16:51:06,419 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0010_01_000003 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:51:06,446 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0010_01_000003 transitioned from LOCALIZED to RUNNING
2015-07-15 16:51:06,476 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0010/container_1436941682764_0010_01_000003/default_container_executor.sh]
2015-07-15 16:51:07,035 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0010_01_000003
2015-07-15 16:51:07,035 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0010_01_000002
2015-07-15 16:51:07,049 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 17669 for container-id container_1436941682764_0010_01_000001: 255.4 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:51:07,063 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 17879 for container-id container_1436941682764_0010_01_000003: 55.7 MB of 1 GB physical memory used; 514.0 MB of 2.1 GB virtual memory used
2015-07-15 16:51:07,339 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:07,339 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:08,340 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:08,340 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:09,103 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0010_01_000003
2015-07-15 16:51:09,103 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0010	CONTAINERID=container_1436941682764_0010_01_000003
2015-07-15 16:51:09,103 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0010_01_000003 transitioned from RUNNING to KILLING
2015-07-15 16:51:09,103 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0010_01_000003
2015-07-15 16:51:09,104 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:09,104 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-07-15 16:51:09,109 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1436941682764_0010_01_000003 is : 143
2015-07-15 16:51:09,123 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0010_01_000003 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-07-15 16:51:09,123 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0010/container_1436941682764_0010_01_000003
2015-07-15 16:51:09,124 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0010	CONTAINERID=container_1436941682764_0010_01_000003
2015-07-15 16:51:09,124 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0010_01_000003 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-07-15 16:51:09,124 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0010_01_000003 from application application_1436941682764_0010
2015-07-15 16:51:09,124 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0010
2015-07-15 16:51:10,064 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0010_01_000003
2015-07-15 16:51:10,077 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 17669 for container-id container_1436941682764_0010_01_000001: 256.1 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:51:10,106 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:10,106 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-07-15 16:51:10,106 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0010_01_000003
2015-07-15 16:51:11,107 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:12,108 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:13,090 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 17669 for container-id container_1436941682764_0010_01_000001: 256.9 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:51:13,109 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:14,110 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:15,110 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:15,866 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container container_1436941682764_0010_01_000001 succeeded 
2015-07-15 16:51:15,867 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0010_01_000001 transitioned from RUNNING to EXITED_WITH_SUCCESS
2015-07-15 16:51:15,867 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0010_01_000001
2015-07-15 16:51:15,878 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0010/container_1436941682764_0010_01_000001
2015-07-15 16:51:15,878 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Succeeded	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0010	CONTAINERID=container_1436941682764_0010_01_000001
2015-07-15 16:51:15,878 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0010_01_000001 transitioned from EXITED_WITH_SUCCESS to DONE
2015-07-15 16:51:15,878 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0010_01_000001 from application application_1436941682764_0010
2015-07-15 16:51:15,878 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0010
2015-07-15 16:51:16,091 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0010_01_000001
2015-07-15 16:51:16,111 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 10 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_COMPLETE diagnostics: "" exit_status: 0
2015-07-15 16:51:16,111 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0010_01_000001
2015-07-15 16:51:16,118 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0010_000001 (auth:SIMPLE)
2015-07-15 16:51:16,122 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0010_01_000001
2015-07-15 16:51:17,113 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0010 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP
2015-07-15 16:51:17,114 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0010
2015-07-15 16:51:17,114 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_STOP for appId application_1436941682764_0010
2015-07-15 16:51:17,114 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0010 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED
2015-07-15 16:51:17,114 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler: Scheduling Log Deletion for application: application_1436941682764_0010, with delay of 10800 seconds
2015-07-15 16:51:17,118 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0011_000001 (auth:SIMPLE)
2015-07-15 16:51:17,123 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0011_01_000001 by user liyaohui
2015-07-15 16:51:17,123 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Creating a new application reference for app application_1436941682764_0011
2015-07-15 16:51:17,123 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0011	CONTAINERID=container_1436941682764_0011_01_000001
2015-07-15 16:51:17,124 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0011 transitioned from NEW to INITING
2015-07-15 16:51:17,124 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0011_01_000001 to application application_1436941682764_0011
2015-07-15 16:51:17,124 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0011 transitioned from INITING to RUNNING
2015-07-15 16:51:17,124 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0011_01_000001 transitioned from NEW to LOCALIZING
2015-07-15 16:51:17,124 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0011
2015-07-15 16:51:17,124 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0011/job.splitmetainfo transitioned from INIT to DOWNLOADING
2015-07-15 16:51:17,124 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0011/job.jar transitioned from INIT to DOWNLOADING
2015-07-15 16:51:17,124 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0011/job.split transitioned from INIT to DOWNLOADING
2015-07-15 16:51:17,124 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0011/job.xml transitioned from INIT to DOWNLOADING
2015-07-15 16:51:17,124 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1436941682764_0011_01_000001
2015-07-15 16:51:17,129 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1436941682764_0011_01_000001.tokens. Credentials list: 
2015-07-15 16:51:17,131 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user liyaohui
2015-07-15 16:51:17,144 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1436941682764_0011_01_000001.tokens to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0011/container_1436941682764_0011_01_000001.tokens
2015-07-15 16:51:17,144 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: CWD set to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0011 = file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0011
2015-07-15 16:51:17,225 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0011/job.splitmetainfo transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:51:17,474 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0011/job.jar transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:51:17,495 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0011/job.split transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:51:17,515 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0011/job.xml transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:51:17,515 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0011_01_000001 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:51:17,534 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0011_01_000001 transitioned from LOCALIZED to RUNNING
2015-07-15 16:51:17,554 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0011/container_1436941682764_0011_01_000001/default_container_executor.sh]
2015-07-15 16:51:18,113 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:19,091 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0011_01_000001
2015-07-15 16:51:19,106 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 18110 for container-id container_1436941682764_0011_01_000001: 90.5 MB of 2 GB physical memory used; 1.3 GB of 4.2 GB virtual memory used
2015-07-15 16:51:19,116 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:20,117 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:21,118 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:22,119 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:22,120 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 18110 for container-id container_1436941682764_0011_01_000001: 256.0 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:51:23,077 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0011_000001 (auth:SIMPLE)
2015-07-15 16:51:23,080 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0011_01_000002 by user liyaohui
2015-07-15 16:51:23,080 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0011	CONTAINERID=container_1436941682764_0011_01_000002
2015-07-15 16:51:23,080 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0011_01_000002 to application application_1436941682764_0011
2015-07-15 16:51:23,080 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0011_01_000002 transitioned from NEW to LOCALIZING
2015-07-15 16:51:23,080 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0011
2015-07-15 16:51:23,080 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1436941682764_0011
2015-07-15 16:51:23,080 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-07-15 16:51:23,080 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1436941682764_0011
2015-07-15 16:51:23,080 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0011_01_000002 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:51:23,107 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0011_01_000002 transitioned from LOCALIZED to RUNNING
2015-07-15 16:51:23,120 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:23,120 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:23,129 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0011/container_1436941682764_0011_01_000002/default_container_executor.sh]
2015-07-15 16:51:24,121 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:24,122 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:25,120 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0011_01_000002
2015-07-15 16:51:25,122 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:25,123 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:25,134 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 18110 for container-id container_1436941682764_0011_01_000001: 255.7 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:51:25,148 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 18233 for container-id container_1436941682764_0011_01_000002: 104.0 MB of 1 GB physical memory used; 531.7 MB of 2.1 GB virtual memory used
2015-07-15 16:51:25,801 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0011_01_000002
2015-07-15 16:51:25,801 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0011	CONTAINERID=container_1436941682764_0011_01_000002
2015-07-15 16:51:25,802 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0011_01_000002 transitioned from RUNNING to KILLING
2015-07-15 16:51:25,802 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0011_01_000002
2015-07-15 16:51:25,802 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:25,802 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-07-15 16:51:25,806 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1436941682764_0011_01_000002 is : 143
2015-07-15 16:51:25,818 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0011_01_000002 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-07-15 16:51:25,818 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0011/container_1436941682764_0011_01_000002
2015-07-15 16:51:25,819 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0011	CONTAINERID=container_1436941682764_0011_01_000002
2015-07-15 16:51:25,819 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0011_01_000002 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-07-15 16:51:25,819 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0011_01_000002 from application application_1436941682764_0011
2015-07-15 16:51:25,819 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0011
2015-07-15 16:51:26,803 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:26,803 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-07-15 16:51:26,803 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0011_01_000002
2015-07-15 16:51:27,804 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:27,992 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0011_01_000003 by user liyaohui
2015-07-15 16:51:27,993 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0011	CONTAINERID=container_1436941682764_0011_01_000003
2015-07-15 16:51:27,993 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0011_01_000003 to application application_1436941682764_0011
2015-07-15 16:51:27,993 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0011_01_000003 transitioned from NEW to LOCALIZING
2015-07-15 16:51:27,993 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0011
2015-07-15 16:51:27,993 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1436941682764_0011
2015-07-15 16:51:27,994 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-07-15 16:51:27,994 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1436941682764_0011
2015-07-15 16:51:27,994 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0011_01_000003 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:51:28,014 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0011_01_000003 transitioned from LOCALIZED to RUNNING
2015-07-15 16:51:28,033 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0011/container_1436941682764_0011_01_000003/default_container_executor.sh]
2015-07-15 16:51:28,148 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0011_01_000003
2015-07-15 16:51:28,148 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0011_01_000002
2015-07-15 16:51:28,162 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 18110 for container-id container_1436941682764_0011_01_000001: 256.5 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:51:28,176 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 18318 for container-id container_1436941682764_0011_01_000003: 21.7 MB of 1 GB physical memory used; 500.8 MB of 2.1 GB virtual memory used
2015-07-15 16:51:28,805 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:28,805 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:29,807 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:29,807 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:30,648 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0011_01_000003
2015-07-15 16:51:30,648 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0011	CONTAINERID=container_1436941682764_0011_01_000003
2015-07-15 16:51:30,648 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0011_01_000003 transitioned from RUNNING to KILLING
2015-07-15 16:51:30,648 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0011_01_000003
2015-07-15 16:51:30,649 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:30,649 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-07-15 16:51:30,659 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1436941682764_0011_01_000003 is : 143
2015-07-15 16:51:30,667 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0011_01_000003 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-07-15 16:51:30,667 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0011/container_1436941682764_0011_01_000003
2015-07-15 16:51:30,668 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0011	CONTAINERID=container_1436941682764_0011_01_000003
2015-07-15 16:51:30,668 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0011_01_000003 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-07-15 16:51:30,668 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0011_01_000003 from application application_1436941682764_0011
2015-07-15 16:51:30,668 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0011
2015-07-15 16:51:31,176 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0011_01_000003
2015-07-15 16:51:31,189 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 18110 for container-id container_1436941682764_0011_01_000001: 257.1 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:51:31,649 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:31,650 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-07-15 16:51:31,650 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0011_01_000003
2015-07-15 16:51:32,651 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:33,652 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:34,202 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 18110 for container-id container_1436941682764_0011_01_000001: 257.9 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:51:34,652 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:35,653 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:36,654 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:37,107 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container container_1436941682764_0011_01_000001 succeeded 
2015-07-15 16:51:37,107 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0011_01_000001 transitioned from RUNNING to EXITED_WITH_SUCCESS
2015-07-15 16:51:37,107 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0011_01_000001
2015-07-15 16:51:37,119 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0011/container_1436941682764_0011_01_000001
2015-07-15 16:51:37,119 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Succeeded	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0011	CONTAINERID=container_1436941682764_0011_01_000001
2015-07-15 16:51:37,119 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0011_01_000001 transitioned from EXITED_WITH_SUCCESS to DONE
2015-07-15 16:51:37,119 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0011_01_000001 from application application_1436941682764_0011
2015-07-15 16:51:37,119 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0011
2015-07-15 16:51:37,202 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0011_01_000001
2015-07-15 16:51:37,654 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 11 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_COMPLETE diagnostics: "" exit_status: 0
2015-07-15 16:51:37,655 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0011_01_000001
2015-07-15 16:51:37,661 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0011_000001 (auth:SIMPLE)
2015-07-15 16:51:37,663 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0011_01_000001
2015-07-15 16:51:38,656 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0011 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP
2015-07-15 16:51:38,656 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0011
2015-07-15 16:51:38,656 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_STOP for appId application_1436941682764_0011
2015-07-15 16:51:38,656 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0011 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED
2015-07-15 16:51:38,657 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler: Scheduling Log Deletion for application: application_1436941682764_0011, with delay of 10800 seconds
2015-07-15 16:51:38,661 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0012_000001 (auth:SIMPLE)
2015-07-15 16:51:38,669 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0012_01_000001 by user liyaohui
2015-07-15 16:51:38,669 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Creating a new application reference for app application_1436941682764_0012
2015-07-15 16:51:38,669 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0012	CONTAINERID=container_1436941682764_0012_01_000001
2015-07-15 16:51:38,671 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0012 transitioned from NEW to INITING
2015-07-15 16:51:38,671 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0012_01_000001 to application application_1436941682764_0012
2015-07-15 16:51:38,671 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0012 transitioned from INITING to RUNNING
2015-07-15 16:51:38,672 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0012_01_000001 transitioned from NEW to LOCALIZING
2015-07-15 16:51:38,672 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0012
2015-07-15 16:51:38,672 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0012/job.splitmetainfo transitioned from INIT to DOWNLOADING
2015-07-15 16:51:38,672 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0012/job.jar transitioned from INIT to DOWNLOADING
2015-07-15 16:51:38,672 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0012/job.split transitioned from INIT to DOWNLOADING
2015-07-15 16:51:38,672 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0012/job.xml transitioned from INIT to DOWNLOADING
2015-07-15 16:51:38,672 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1436941682764_0012_01_000001
2015-07-15 16:51:38,676 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1436941682764_0012_01_000001.tokens. Credentials list: 
2015-07-15 16:51:38,678 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user liyaohui
2015-07-15 16:51:38,688 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1436941682764_0012_01_000001.tokens to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0012/container_1436941682764_0012_01_000001.tokens
2015-07-15 16:51:38,688 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: CWD set to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0012 = file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0012
2015-07-15 16:51:38,771 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0012/job.splitmetainfo transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:51:39,023 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0012/job.jar transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:51:39,042 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0012/job.split transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:51:39,065 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0012/job.xml transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:51:39,065 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0012_01_000001 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:51:39,084 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0012_01_000001 transitioned from LOCALIZED to RUNNING
2015-07-15 16:51:39,159 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0012/container_1436941682764_0012_01_000001/default_container_executor.sh]
2015-07-15 16:51:39,656 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:40,203 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0012_01_000001
2015-07-15 16:51:40,216 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 18549 for container-id container_1436941682764_0012_01_000001: 70.8 MB of 2 GB physical memory used; 1.3 GB of 4.2 GB virtual memory used
2015-07-15 16:51:40,657 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:41,658 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:42,659 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:43,230 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 18549 for container-id container_1436941682764_0012_01_000001: 254.0 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:51:43,660 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:44,661 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:44,668 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0012_000001 (auth:SIMPLE)
2015-07-15 16:51:44,672 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0012_01_000002 by user liyaohui
2015-07-15 16:51:44,672 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0012	CONTAINERID=container_1436941682764_0012_01_000002
2015-07-15 16:51:44,672 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0012_01_000002 to application application_1436941682764_0012
2015-07-15 16:51:44,672 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0012_01_000002 transitioned from NEW to LOCALIZING
2015-07-15 16:51:44,672 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0012
2015-07-15 16:51:44,672 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1436941682764_0012
2015-07-15 16:51:44,672 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-07-15 16:51:44,672 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1436941682764_0012
2015-07-15 16:51:44,672 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0012_01_000002 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:51:44,697 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0012_01_000002 transitioned from LOCALIZED to RUNNING
2015-07-15 16:51:44,717 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0012/container_1436941682764_0012_01_000002/default_container_executor.sh]
2015-07-15 16:51:45,662 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:45,662 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:46,230 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0012_01_000002
2015-07-15 16:51:46,245 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 18672 for container-id container_1436941682764_0012_01_000002: 90.5 MB of 1 GB physical memory used; 526.2 MB of 2.1 GB virtual memory used
2015-07-15 16:51:46,259 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 18549 for container-id container_1436941682764_0012_01_000001: 255 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:51:46,663 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:46,663 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:47,399 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0012_01_000002
2015-07-15 16:51:47,399 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0012	CONTAINERID=container_1436941682764_0012_01_000002
2015-07-15 16:51:47,399 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0012_01_000002 transitioned from RUNNING to KILLING
2015-07-15 16:51:47,399 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:47,399 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0012_01_000002
2015-07-15 16:51:47,399 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-07-15 16:51:47,419 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1436941682764_0012_01_000002 is : 143
2015-07-15 16:51:47,431 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0012_01_000002 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-07-15 16:51:47,431 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0012/container_1436941682764_0012_01_000002
2015-07-15 16:51:47,432 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0012	CONTAINERID=container_1436941682764_0012_01_000002
2015-07-15 16:51:47,432 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0012_01_000002 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-07-15 16:51:47,432 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0012_01_000002 from application application_1436941682764_0012
2015-07-15 16:51:47,432 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0012
2015-07-15 16:51:48,400 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:48,400 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-07-15 16:51:48,401 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0012_01_000002
2015-07-15 16:51:49,259 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0012_01_000002
2015-07-15 16:51:49,272 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 18549 for container-id container_1436941682764_0012_01_000001: 255.2 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:51:49,401 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:49,586 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0012_01_000003 by user liyaohui
2015-07-15 16:51:49,586 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0012	CONTAINERID=container_1436941682764_0012_01_000003
2015-07-15 16:51:49,586 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0012_01_000003 to application application_1436941682764_0012
2015-07-15 16:51:49,587 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0012_01_000003 transitioned from NEW to LOCALIZING
2015-07-15 16:51:49,587 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0012
2015-07-15 16:51:49,587 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1436941682764_0012
2015-07-15 16:51:49,587 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-07-15 16:51:49,587 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1436941682764_0012
2015-07-15 16:51:49,587 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0012_01_000003 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:51:49,606 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0012_01_000003 transitioned from LOCALIZED to RUNNING
2015-07-15 16:51:49,625 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0012/container_1436941682764_0012_01_000003/default_container_executor.sh]
2015-07-15 16:51:50,402 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:50,402 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:51,404 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:51,404 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:52,272 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0012_01_000003
2015-07-15 16:51:52,289 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 18757 for container-id container_1436941682764_0012_01_000003: 139.9 MB of 1 GB physical memory used; 537.5 MB of 2.1 GB virtual memory used
2015-07-15 16:51:52,304 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 18549 for container-id container_1436941682764_0012_01_000001: 255.3 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:51:52,333 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0012_01_000003
2015-07-15 16:51:52,333 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0012	CONTAINERID=container_1436941682764_0012_01_000003
2015-07-15 16:51:52,333 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:52,333 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0012_01_000003 transitioned from RUNNING to KILLING
2015-07-15 16:51:52,333 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0012_01_000003
2015-07-15 16:51:52,333 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-07-15 16:51:52,342 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1436941682764_0012_01_000003 is : 143
2015-07-15 16:51:52,359 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0012_01_000003 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-07-15 16:51:52,359 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0012	CONTAINERID=container_1436941682764_0012_01_000003
2015-07-15 16:51:52,359 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0012_01_000003 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-07-15 16:51:52,359 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0012_01_000003 from application application_1436941682764_0012
2015-07-15 16:51:52,359 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0012
2015-07-15 16:51:52,359 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0012/container_1436941682764_0012_01_000003
2015-07-15 16:51:53,334 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:53,334 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-07-15 16:51:53,334 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0012_01_000003
2015-07-15 16:51:54,335 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:55,304 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0012_01_000003
2015-07-15 16:51:55,317 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 18549 for container-id container_1436941682764_0012_01_000001: 256.8 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:51:55,336 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:56,337 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:57,338 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:58,331 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 18549 for container-id container_1436941682764_0012_01_000001: 256.8 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:51:58,338 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:51:58,792 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container container_1436941682764_0012_01_000001 succeeded 
2015-07-15 16:51:58,792 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0012_01_000001 transitioned from RUNNING to EXITED_WITH_SUCCESS
2015-07-15 16:51:58,792 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0012_01_000001
2015-07-15 16:51:58,803 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0012/container_1436941682764_0012_01_000001
2015-07-15 16:51:58,803 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Succeeded	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0012	CONTAINERID=container_1436941682764_0012_01_000001
2015-07-15 16:51:58,803 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0012_01_000001 transitioned from EXITED_WITH_SUCCESS to DONE
2015-07-15 16:51:58,803 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0012_01_000001 from application application_1436941682764_0012
2015-07-15 16:51:58,803 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0012
2015-07-15 16:51:59,339 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 12 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_COMPLETE diagnostics: "" exit_status: 0
2015-07-15 16:51:59,339 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0012_01_000001
2015-07-15 16:51:59,344 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0012_000001 (auth:SIMPLE)
2015-07-15 16:51:59,349 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0012_01_000001
2015-07-15 16:52:00,341 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0012 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP
2015-07-15 16:52:00,341 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0012
2015-07-15 16:52:00,341 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_STOP for appId application_1436941682764_0012
2015-07-15 16:52:00,341 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0012 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED
2015-07-15 16:52:00,341 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler: Scheduling Log Deletion for application: application_1436941682764_0012, with delay of 10800 seconds
2015-07-15 16:52:00,345 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0013_000001 (auth:SIMPLE)
2015-07-15 16:52:00,349 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0013_01_000001 by user liyaohui
2015-07-15 16:52:00,349 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Creating a new application reference for app application_1436941682764_0013
2015-07-15 16:52:00,349 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0013	CONTAINERID=container_1436941682764_0013_01_000001
2015-07-15 16:52:00,349 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0013 transitioned from NEW to INITING
2015-07-15 16:52:00,349 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0013_01_000001 to application application_1436941682764_0013
2015-07-15 16:52:00,349 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0013 transitioned from INITING to RUNNING
2015-07-15 16:52:00,349 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0013_01_000001 transitioned from NEW to LOCALIZING
2015-07-15 16:52:00,349 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0013
2015-07-15 16:52:00,350 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0013/job.splitmetainfo transitioned from INIT to DOWNLOADING
2015-07-15 16:52:00,350 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0013/job.jar transitioned from INIT to DOWNLOADING
2015-07-15 16:52:00,350 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0013/job.split transitioned from INIT to DOWNLOADING
2015-07-15 16:52:00,350 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0013/job.xml transitioned from INIT to DOWNLOADING
2015-07-15 16:52:00,350 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1436941682764_0013_01_000001
2015-07-15 16:52:00,354 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1436941682764_0013_01_000001.tokens. Credentials list: 
2015-07-15 16:52:00,356 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user liyaohui
2015-07-15 16:52:00,365 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1436941682764_0013_01_000001.tokens to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0013/container_1436941682764_0013_01_000001.tokens
2015-07-15 16:52:00,365 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: CWD set to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0013 = file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0013
2015-07-15 16:52:00,440 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0013/job.splitmetainfo transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:52:00,689 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0013/job.jar transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:52:00,707 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0013/job.split transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:52:00,727 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0013/job.xml transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:52:00,727 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0013_01_000001 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:52:00,746 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0013_01_000001 transitioned from LOCALIZED to RUNNING
2015-07-15 16:52:00,765 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0013/container_1436941682764_0013_01_000001/default_container_executor.sh]
2015-07-15 16:52:01,331 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0013_01_000001
2015-07-15 16:52:01,331 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0012_01_000001
2015-07-15 16:52:01,341 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:01,348 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 18988 for container-id container_1436941682764_0013_01_000001: 56.7 MB of 2 GB physical memory used; 1.3 GB of 4.2 GB virtual memory used
2015-07-15 16:52:02,342 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:03,343 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:04,344 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:04,361 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 18988 for container-id container_1436941682764_0013_01_000001: 247.2 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:52:05,345 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:06,255 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0013_000001 (auth:SIMPLE)
2015-07-15 16:52:06,261 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0013_01_000002 by user liyaohui
2015-07-15 16:52:06,261 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0013	CONTAINERID=container_1436941682764_0013_01_000002
2015-07-15 16:52:06,261 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0013_01_000002 to application application_1436941682764_0013
2015-07-15 16:52:06,261 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0013_01_000002 transitioned from NEW to LOCALIZING
2015-07-15 16:52:06,261 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0013
2015-07-15 16:52:06,261 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1436941682764_0013
2015-07-15 16:52:06,261 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-07-15 16:52:06,261 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1436941682764_0013
2015-07-15 16:52:06,261 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0013_01_000002 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:52:06,284 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0013_01_000002 transitioned from LOCALIZED to RUNNING
2015-07-15 16:52:06,303 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0013/container_1436941682764_0013_01_000002/default_container_executor.sh]
2015-07-15 16:52:06,346 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:06,346 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:07,347 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:07,347 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:07,362 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0013_01_000002
2015-07-15 16:52:07,376 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 19113 for container-id container_1436941682764_0013_01_000002: 69.9 MB of 1 GB physical memory used; 519.1 MB of 2.1 GB virtual memory used
2015-07-15 16:52:07,390 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 18988 for container-id container_1436941682764_0013_01_000001: 257.2 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:52:08,348 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:08,348 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:08,986 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0013_01_000002
2015-07-15 16:52:08,986 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0013	CONTAINERID=container_1436941682764_0013_01_000002
2015-07-15 16:52:08,986 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0013_01_000002 transitioned from RUNNING to KILLING
2015-07-15 16:52:08,986 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0013_01_000002
2015-07-15 16:52:08,986 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:08,986 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-07-15 16:52:08,997 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1436941682764_0013_01_000002 is : 143
2015-07-15 16:52:09,012 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0013_01_000002 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-07-15 16:52:09,013 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0013/container_1436941682764_0013_01_000002
2015-07-15 16:52:09,013 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0013	CONTAINERID=container_1436941682764_0013_01_000002
2015-07-15 16:52:09,013 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0013_01_000002 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-07-15 16:52:09,013 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0013_01_000002 from application application_1436941682764_0013
2015-07-15 16:52:09,013 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0013
2015-07-15 16:52:09,988 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:09,988 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-07-15 16:52:09,988 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0013_01_000002
2015-07-15 16:52:10,390 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0013_01_000002
2015-07-15 16:52:10,403 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 18988 for container-id container_1436941682764_0013_01_000001: 257.7 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:52:10,989 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:11,172 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0013_01_000003 by user liyaohui
2015-07-15 16:52:11,172 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0013	CONTAINERID=container_1436941682764_0013_01_000003
2015-07-15 16:52:11,172 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0013_01_000003 to application application_1436941682764_0013
2015-07-15 16:52:11,172 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0013_01_000003 transitioned from NEW to LOCALIZING
2015-07-15 16:52:11,172 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0013
2015-07-15 16:52:11,172 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1436941682764_0013
2015-07-15 16:52:11,172 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-07-15 16:52:11,172 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1436941682764_0013
2015-07-15 16:52:11,173 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0013_01_000003 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:52:11,192 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0013_01_000003 transitioned from LOCALIZED to RUNNING
2015-07-15 16:52:11,212 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0013/container_1436941682764_0013_01_000003/default_container_executor.sh]
2015-07-15 16:52:11,990 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:11,990 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:12,991 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:12,991 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:13,403 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0013_01_000003
2015-07-15 16:52:13,429 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 19198 for container-id container_1436941682764_0013_01_000003: 119.7 MB of 1 GB physical memory used; 534.3 MB of 2.1 GB virtual memory used
2015-07-15 16:52:13,443 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 18988 for container-id container_1436941682764_0013_01_000001: 257.8 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:52:13,839 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0013_01_000003
2015-07-15 16:52:13,840 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0013	CONTAINERID=container_1436941682764_0013_01_000003
2015-07-15 16:52:13,840 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0013_01_000003 transitioned from RUNNING to KILLING
2015-07-15 16:52:13,840 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0013_01_000003
2015-07-15 16:52:13,840 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:13,840 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-07-15 16:52:13,845 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1436941682764_0013_01_000003 is : 143
2015-07-15 16:52:13,856 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0013_01_000003 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-07-15 16:52:13,856 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0013/container_1436941682764_0013_01_000003
2015-07-15 16:52:13,857 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0013	CONTAINERID=container_1436941682764_0013_01_000003
2015-07-15 16:52:13,857 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0013_01_000003 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-07-15 16:52:13,857 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0013_01_000003 from application application_1436941682764_0013
2015-07-15 16:52:13,857 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0013
2015-07-15 16:52:14,843 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:14,844 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-07-15 16:52:14,844 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0013_01_000003
2015-07-15 16:52:15,848 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:16,443 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0013_01_000003
2015-07-15 16:52:16,457 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 18988 for container-id container_1436941682764_0013_01_000001: 259.3 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:52:16,849 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:17,849 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:18,850 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:19,470 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 18988 for container-id container_1436941682764_0013_01_000001: 259.3 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:52:19,851 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:20,292 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container container_1436941682764_0013_01_000001 succeeded 
2015-07-15 16:52:20,292 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0013_01_000001 transitioned from RUNNING to EXITED_WITH_SUCCESS
2015-07-15 16:52:20,292 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0013_01_000001
2015-07-15 16:52:20,305 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0013/container_1436941682764_0013_01_000001
2015-07-15 16:52:20,305 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Succeeded	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0013	CONTAINERID=container_1436941682764_0013_01_000001
2015-07-15 16:52:20,305 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0013_01_000001 transitioned from EXITED_WITH_SUCCESS to DONE
2015-07-15 16:52:20,305 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0013_01_000001 from application application_1436941682764_0013
2015-07-15 16:52:20,305 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0013
2015-07-15 16:52:20,852 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 13 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_COMPLETE diagnostics: "" exit_status: 0
2015-07-15 16:52:20,852 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0013_01_000001
2015-07-15 16:52:20,857 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0013_000001 (auth:SIMPLE)
2015-07-15 16:52:20,860 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0013_01_000001
2015-07-15 16:52:21,853 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0013 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP
2015-07-15 16:52:21,854 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_STOP for appId application_1436941682764_0013
2015-07-15 16:52:21,854 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0013
2015-07-15 16:52:21,854 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0013 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED
2015-07-15 16:52:21,854 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler: Scheduling Log Deletion for application: application_1436941682764_0013, with delay of 10800 seconds
2015-07-15 16:52:21,862 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0014_000001 (auth:SIMPLE)
2015-07-15 16:52:21,866 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0014_01_000001 by user liyaohui
2015-07-15 16:52:21,866 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Creating a new application reference for app application_1436941682764_0014
2015-07-15 16:52:21,866 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0014	CONTAINERID=container_1436941682764_0014_01_000001
2015-07-15 16:52:21,866 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0014 transitioned from NEW to INITING
2015-07-15 16:52:21,866 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0014_01_000001 to application application_1436941682764_0014
2015-07-15 16:52:21,867 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0014 transitioned from INITING to RUNNING
2015-07-15 16:52:21,867 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0014_01_000001 transitioned from NEW to LOCALIZING
2015-07-15 16:52:21,867 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0014
2015-07-15 16:52:21,867 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0014/job.splitmetainfo transitioned from INIT to DOWNLOADING
2015-07-15 16:52:21,867 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0014/job.jar transitioned from INIT to DOWNLOADING
2015-07-15 16:52:21,867 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0014/job.split transitioned from INIT to DOWNLOADING
2015-07-15 16:52:21,867 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0014/job.xml transitioned from INIT to DOWNLOADING
2015-07-15 16:52:21,867 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1436941682764_0014_01_000001
2015-07-15 16:52:21,872 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1436941682764_0014_01_000001.tokens. Credentials list: 
2015-07-15 16:52:21,874 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user liyaohui
2015-07-15 16:52:21,884 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1436941682764_0014_01_000001.tokens to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0014/container_1436941682764_0014_01_000001.tokens
2015-07-15 16:52:21,884 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: CWD set to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0014 = file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0014
2015-07-15 16:52:21,959 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0014/job.splitmetainfo transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:52:22,203 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0014/job.jar transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:52:22,222 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0014/job.split transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:52:22,243 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0014/job.xml transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:52:22,244 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0014_01_000001 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:52:22,263 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0014_01_000001 transitioned from LOCALIZED to RUNNING
2015-07-15 16:52:22,282 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0014/container_1436941682764_0014_01_000001/default_container_executor.sh]
2015-07-15 16:52:22,470 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0014_01_000001
2015-07-15 16:52:22,471 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0013_01_000001
2015-07-15 16:52:22,484 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 19429 for container-id container_1436941682764_0014_01_000001: 30.3 MB of 2 GB physical memory used; 1.3 GB of 4.2 GB virtual memory used
2015-07-15 16:52:22,853 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:23,854 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:24,855 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:25,498 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 19429 for container-id container_1436941682764_0014_01_000001: 165.9 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:52:25,856 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:26,863 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:27,822 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0014_000001 (auth:SIMPLE)
2015-07-15 16:52:27,827 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0014_01_000002 by user liyaohui
2015-07-15 16:52:27,827 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0014	CONTAINERID=container_1436941682764_0014_01_000002
2015-07-15 16:52:27,827 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0014_01_000002 to application application_1436941682764_0014
2015-07-15 16:52:27,828 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0014_01_000002 transitioned from NEW to LOCALIZING
2015-07-15 16:52:27,828 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0014
2015-07-15 16:52:27,828 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1436941682764_0014
2015-07-15 16:52:27,828 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-07-15 16:52:27,828 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1436941682764_0014
2015-07-15 16:52:27,828 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0014_01_000002 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:52:27,850 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0014_01_000002 transitioned from LOCALIZED to RUNNING
2015-07-15 16:52:27,864 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:27,864 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:27,869 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0014/container_1436941682764_0014_01_000002/default_container_executor.sh]
2015-07-15 16:52:28,498 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0014_01_000002
2015-07-15 16:52:28,513 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 19552 for container-id container_1436941682764_0014_01_000002: 60.2 MB of 1 GB physical memory used; 513.2 MB of 2.1 GB virtual memory used
2015-07-15 16:52:28,527 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 19429 for container-id container_1436941682764_0014_01_000001: 254.9 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:52:28,866 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:28,866 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:29,867 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:29,867 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:30,588 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0014_01_000002
2015-07-15 16:52:30,588 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0014	CONTAINERID=container_1436941682764_0014_01_000002
2015-07-15 16:52:30,588 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0014_01_000002 transitioned from RUNNING to KILLING
2015-07-15 16:52:30,588 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0014_01_000002
2015-07-15 16:52:30,589 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:30,589 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-07-15 16:52:30,593 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1436941682764_0014_01_000002 is : 143
2015-07-15 16:52:30,606 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0014_01_000002 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-07-15 16:52:30,607 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0014/container_1436941682764_0014_01_000002
2015-07-15 16:52:30,608 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0014	CONTAINERID=container_1436941682764_0014_01_000002
2015-07-15 16:52:30,608 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0014_01_000002 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-07-15 16:52:30,608 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0014_01_000002 from application application_1436941682764_0014
2015-07-15 16:52:30,608 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0014
2015-07-15 16:52:31,527 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0014_01_000002
2015-07-15 16:52:31,540 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 19429 for container-id container_1436941682764_0014_01_000001: 255.1 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:52:31,590 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:31,590 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-07-15 16:52:31,590 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0014_01_000002
2015-07-15 16:52:32,591 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:32,746 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0014_01_000003 by user liyaohui
2015-07-15 16:52:32,746 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0014	CONTAINERID=container_1436941682764_0014_01_000003
2015-07-15 16:52:32,746 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0014_01_000003 to application application_1436941682764_0014
2015-07-15 16:52:32,747 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0014_01_000003 transitioned from NEW to LOCALIZING
2015-07-15 16:52:32,747 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0014
2015-07-15 16:52:32,747 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1436941682764_0014
2015-07-15 16:52:32,747 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-07-15 16:52:32,747 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1436941682764_0014
2015-07-15 16:52:32,747 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0014_01_000003 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:52:32,766 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0014_01_000003 transitioned from LOCALIZED to RUNNING
2015-07-15 16:52:32,784 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0014/container_1436941682764_0014_01_000003/default_container_executor.sh]
2015-07-15 16:52:33,591 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:33,592 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:34,541 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0014_01_000003
2015-07-15 16:52:34,556 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 19637 for container-id container_1436941682764_0014_01_000003: 96.3 MB of 1 GB physical memory used; 526.6 MB of 2.1 GB virtual memory used
2015-07-15 16:52:34,569 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 19429 for container-id container_1436941682764_0014_01_000001: 255.3 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:52:34,593 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:34,593 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:35,511 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0014_01_000003
2015-07-15 16:52:35,511 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0014	CONTAINERID=container_1436941682764_0014_01_000003
2015-07-15 16:52:35,512 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0014_01_000003 transitioned from RUNNING to KILLING
2015-07-15 16:52:35,512 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0014_01_000003
2015-07-15 16:52:35,512 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:35,512 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-07-15 16:52:35,517 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1436941682764_0014_01_000003 is : 143
2015-07-15 16:52:35,542 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0014_01_000003 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-07-15 16:52:35,542 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0014/container_1436941682764_0014_01_000003
2015-07-15 16:52:35,542 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0014	CONTAINERID=container_1436941682764_0014_01_000003
2015-07-15 16:52:35,542 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0014_01_000003 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-07-15 16:52:35,542 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0014_01_000003 from application application_1436941682764_0014
2015-07-15 16:52:35,542 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0014
2015-07-15 16:52:36,513 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:36,513 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 3 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-07-15 16:52:36,513 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0014_01_000003
2015-07-15 16:52:37,516 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:37,570 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0014_01_000003
2015-07-15 16:52:37,583 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 19429 for container-id container_1436941682764_0014_01_000001: 256.5 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:52:38,517 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:39,518 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:40,519 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:40,596 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 19429 for container-id container_1436941682764_0014_01_000001: 256.8 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:52:41,520 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:41,938 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container container_1436941682764_0014_01_000001 succeeded 
2015-07-15 16:52:41,938 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0014_01_000001 transitioned from RUNNING to EXITED_WITH_SUCCESS
2015-07-15 16:52:41,938 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0014_01_000001
2015-07-15 16:52:41,949 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0014/container_1436941682764_0014_01_000001
2015-07-15 16:52:41,949 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Succeeded	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0014	CONTAINERID=container_1436941682764_0014_01_000001
2015-07-15 16:52:41,950 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0014_01_000001 transitioned from EXITED_WITH_SUCCESS to DONE
2015-07-15 16:52:41,950 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0014_01_000001 from application application_1436941682764_0014
2015-07-15 16:52:41,950 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0014
2015-07-15 16:52:42,520 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 14 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_COMPLETE diagnostics: "" exit_status: 0
2015-07-15 16:52:42,521 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0014_01_000001
2015-07-15 16:52:42,525 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0014_000001 (auth:SIMPLE)
2015-07-15 16:52:42,527 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0014_01_000001
2015-07-15 16:52:43,522 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0014 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP
2015-07-15 16:52:43,522 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0014
2015-07-15 16:52:43,522 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_STOP for appId application_1436941682764_0014
2015-07-15 16:52:43,522 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0014 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED
2015-07-15 16:52:43,522 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler: Scheduling Log Deletion for application: application_1436941682764_0014, with delay of 10800 seconds
2015-07-15 16:52:43,527 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0015_000001 (auth:SIMPLE)
2015-07-15 16:52:43,531 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0015_01_000001 by user liyaohui
2015-07-15 16:52:43,531 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Creating a new application reference for app application_1436941682764_0015
2015-07-15 16:52:43,531 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0015	CONTAINERID=container_1436941682764_0015_01_000001
2015-07-15 16:52:43,531 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0015 transitioned from NEW to INITING
2015-07-15 16:52:43,531 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0015_01_000001 to application application_1436941682764_0015
2015-07-15 16:52:43,531 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0015 transitioned from INITING to RUNNING
2015-07-15 16:52:43,531 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0015_01_000001 transitioned from NEW to LOCALIZING
2015-07-15 16:52:43,531 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0015
2015-07-15 16:52:43,531 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0015/job.splitmetainfo transitioned from INIT to DOWNLOADING
2015-07-15 16:52:43,531 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0015/job.jar transitioned from INIT to DOWNLOADING
2015-07-15 16:52:43,532 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0015/job.split transitioned from INIT to DOWNLOADING
2015-07-15 16:52:43,532 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0015/job.xml transitioned from INIT to DOWNLOADING
2015-07-15 16:52:43,532 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1436941682764_0015_01_000001
2015-07-15 16:52:43,536 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1436941682764_0015_01_000001.tokens. Credentials list: 
2015-07-15 16:52:43,538 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user liyaohui
2015-07-15 16:52:43,548 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1436941682764_0015_01_000001.tokens to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0015/container_1436941682764_0015_01_000001.tokens
2015-07-15 16:52:43,548 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: CWD set to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0015 = file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0015
2015-07-15 16:52:43,596 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0014_01_000001
2015-07-15 16:52:43,623 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0015/job.splitmetainfo transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:52:43,874 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0015/job.jar transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:52:43,894 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0015/job.split transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:52:43,912 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0015/job.xml transitioned from DOWNLOADING to LOCALIZED
2015-07-15 16:52:43,912 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0015_01_000001 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:52:43,931 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0015_01_000001 transitioned from LOCALIZED to RUNNING
2015-07-15 16:52:43,950 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0015/container_1436941682764_0015_01_000001/default_container_executor.sh]
2015-07-15 16:52:44,522 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 15 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:45,523 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 15 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:46,524 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 15 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:46,596 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0015_01_000001
2015-07-15 16:52:46,611 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 19872 for container-id container_1436941682764_0015_01_000001: 156.6 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:52:47,525 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 15 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:48,526 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 15 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:49,476 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0015_000001 (auth:SIMPLE)
2015-07-15 16:52:49,479 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1436941682764_0015_01_000002 by user liyaohui
2015-07-15 16:52:49,480 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0015	CONTAINERID=container_1436941682764_0015_01_000002
2015-07-15 16:52:49,480 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1436941682764_0015_01_000002 to application application_1436941682764_0015
2015-07-15 16:52:49,480 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0015_01_000002 transitioned from NEW to LOCALIZING
2015-07-15 16:52:49,480 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1436941682764_0015
2015-07-15 16:52:49,480 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1436941682764_0015
2015-07-15 16:52:49,480 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-07-15 16:52:49,480 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1436941682764_0015
2015-07-15 16:52:49,480 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0015_01_000002 transitioned from LOCALIZING to LOCALIZED
2015-07-15 16:52:49,500 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0015_01_000002 transitioned from LOCALIZED to RUNNING
2015-07-15 16:52:49,519 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0015/container_1436941682764_0015_01_000002/default_container_executor.sh]
2015-07-15 16:52:49,527 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 15 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:49,527 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 15 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:49,611 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1436941682764_0015_01_000002
2015-07-15 16:52:49,625 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 19872 for container-id container_1436941682764_0015_01_000001: 255.7 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:52:49,639 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 19995 for container-id container_1436941682764_0015_01_000002: 20.0 MB of 1 GB physical memory used; 495.7 MB of 2.1 GB virtual memory used
2015-07-15 16:52:50,528 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 15 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:50,528 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 15 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:51,529 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 15 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:51,530 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 15 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:52,080 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0015_01_000002
2015-07-15 16:52:52,080 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1436941682764_0015	CONTAINERID=container_1436941682764_0015_01_000002
2015-07-15 16:52:52,080 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 15 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:52,080 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0015_01_000002 transitioned from RUNNING to KILLING
2015-07-15 16:52:52,080 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0015_01_000002
2015-07-15 16:52:52,080 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 15 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-07-15 16:52:52,085 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1436941682764_0015_01_000002 is : 143
2015-07-15 16:52:52,097 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0015_01_000002 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-07-15 16:52:52,098 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0015/container_1436941682764_0015_01_000002
2015-07-15 16:52:52,098 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0015	CONTAINERID=container_1436941682764_0015_01_000002
2015-07-15 16:52:52,098 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0015_01_000002 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-07-15 16:52:52,098 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0015_01_000002 from application application_1436941682764_0015
2015-07-15 16:52:52,098 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0015
2015-07-15 16:52:52,639 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0015_01_000002
2015-07-15 16:52:52,651 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 19872 for container-id container_1436941682764_0015_01_000001: 256.6 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:52:53,082 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 15 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:53,082 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 15 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 2 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-07-15 16:52:53,082 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0015_01_000002
2015-07-15 16:52:54,083 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 15 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:55,084 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 15 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:55,664 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 19872 for container-id container_1436941682764_0015_01_000001: 257.6 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-07-15 16:52:56,085 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 15 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:57,086 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 15 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:58,087 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 15 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-07-15 16:52:58,612 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container container_1436941682764_0015_01_000001 succeeded 
2015-07-15 16:52:58,612 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0015_01_000001 transitioned from RUNNING to EXITED_WITH_SUCCESS
2015-07-15 16:52:58,612 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1436941682764_0015_01_000001
2015-07-15 16:52:58,623 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0015/container_1436941682764_0015_01_000001
2015-07-15 16:52:58,623 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Succeeded	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1436941682764_0015	CONTAINERID=container_1436941682764_0015_01_000001
2015-07-15 16:52:58,623 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1436941682764_0015_01_000001 transitioned from EXITED_WITH_SUCCESS to DONE
2015-07-15 16:52:58,623 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1436941682764_0015_01_000001 from application application_1436941682764_0015
2015-07-15 16:52:58,623 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1436941682764_0015
2015-07-15 16:52:58,665 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1436941682764_0015_01_000001
2015-07-15 16:52:59,088 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 15 cluster_timestamp: 1436941682764 } attemptId: 1 } id: 1 } state: C_COMPLETE diagnostics: "" exit_status: 0
2015-07-15 16:52:59,088 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1436941682764_0015_01_000001
2015-07-15 16:52:59,092 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1436941682764_0015_000001 (auth:SIMPLE)
2015-07-15 16:52:59,095 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1436941682764_0015_01_000001
2015-07-15 16:53:00,089 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0015 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP
2015-07-15 16:53:00,089 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1436941682764_0015
2015-07-15 16:53:00,090 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_STOP for appId application_1436941682764_0015
2015-07-15 16:53:00,090 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1436941682764_0015 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED
2015-07-15 16:53:00,090 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler: Scheduling Log Deletion for application: application_1436941682764_0015, with delay of 10800 seconds
2015-07-15 19:10:46,586 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting path : /home/liyaohui/hadoop/logs/userlogs/application_1436941682764_0001
2015-07-15 19:49:04,096 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting path : /home/liyaohui/hadoop/logs/userlogs/application_1436941682764_0004
2015-07-15 19:49:26,949 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting path : /home/liyaohui/hadoop/logs/userlogs/application_1436941682764_0005
2015-07-15 19:49:50,787 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting path : /home/liyaohui/hadoop/logs/userlogs/application_1436941682764_0006
2015-07-15 19:50:12,392 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting path : /home/liyaohui/hadoop/logs/userlogs/application_1436941682764_0007
2015-07-15 19:50:33,954 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting path : /home/liyaohui/hadoop/logs/userlogs/application_1436941682764_0008
2015-07-15 19:50:55,516 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting path : /home/liyaohui/hadoop/logs/userlogs/application_1436941682764_0009
2015-07-15 19:51:17,114 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting path : /home/liyaohui/hadoop/logs/userlogs/application_1436941682764_0010
2015-07-15 19:51:38,657 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting path : /home/liyaohui/hadoop/logs/userlogs/application_1436941682764_0011
2015-07-15 19:52:00,341 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting path : /home/liyaohui/hadoop/logs/userlogs/application_1436941682764_0012
2015-07-15 19:52:21,854 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting path : /home/liyaohui/hadoop/logs/userlogs/application_1436941682764_0013
2015-07-15 19:52:43,523 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting path : /home/liyaohui/hadoop/logs/userlogs/application_1436941682764_0014
2015-07-15 19:53:00,091 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting path : /home/liyaohui/hadoop/logs/userlogs/application_1436941682764_0015
2015-07-15 22:31:41,975 ERROR org.apache.hadoop.yarn.server.nodemanager.NodeManager: RECEIVED SIGNAL 15: SIGTERM
2015-07-15 22:31:42,158 INFO org.mortbay.log: Stopped SelectChannelConnector@0.0.0.0:8042
2015-07-15 22:31:42,259 INFO org.apache.hadoop.ipc.Server: Stopping server on 44193
2015-07-15 22:31:42,259 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 44193
2015-07-15 22:31:42,260 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2015-07-15 22:31:42,260 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.
2015-07-15 22:31:42,348 INFO org.apache.hadoop.ipc.Server: Stopping server on 8040
2015-07-15 22:31:42,349 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8040
2015-07-15 22:31:42,349 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2015-07-15 22:31:42,349 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Public cache exiting
2015-07-15 22:31:42,349 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NodeManager metrics system...
2015-07-15 22:31:42,350 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system stopped.
2015-07-15 22:31:42,350 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system shutdown complete.
2015-07-15 22:31:42,350 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at ubuntu01/127.0.1.1
************************************************************/
2015-07-17 21:56:39,262 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-07-17 21:56:39,299 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2015-07-17 21:56:39,993 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-07-17 21:56:40,375 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2015-07-17 21:56:40,376 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2015-07-17 21:56:40,377 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2015-07-17 21:56:40,377 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2015-07-17 21:56:40,378 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2015-07-17 21:56:40,378 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2015-07-17 21:56:40,401 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2015-07-17 21:56:40,401 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2015-07-17 21:56:40,453 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-07-17 21:56:40,518 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-07-17 21:56:40,518 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2015-07-17 21:56:40,545 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2015-07-17 21:56:40,545 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2015-07-17 21:56:40,561 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1436941685461
2015-07-17 21:56:40,562 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1437141400547
2015-07-17 21:56:40,565 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1437141400547/liyaohui
2015-07-17 21:56:40,565 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1436929195743
2015-07-17 21:56:40,589 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2015-07-17 21:56:40,624 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2015-07-17 21:56:40,624 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2015-07-17 21:56:40,676 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@16b83cc
2015-07-17 21:56:40,676 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2015-07-17 21:56:40,676 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2015-07-17 21:56:40,676 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2015-07-17 21:56:40,679 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.9 G). Thrashing might happen.
2015-07-17 21:56:40,683 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2015-07-17 21:56:40,731 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 39845
2015-07-17 21:56:40,748 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2015-07-17 21:56:40,748 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2015-07-17 21:56:40,748 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-07-17 21:56:40,749 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 39845: starting
2015-07-17 21:56:40,756 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : ubuntu01:39845
2015-07-17 21:56:40,756 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at ubuntu01/127.0.1.1:39845
2015-07-17 21:56:40,774 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2015-07-17 21:56:40,775 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2015-07-17 21:56:40,775 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-07-17 21:56:40,775 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2015-07-17 21:56:40,776 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2015-07-17 21:56:40,797 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2015-07-17 21:56:40,810 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2015-07-17 21:56:40,812 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2015-07-17 21:56:40,841 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-07-17 21:56:40,889 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-07-17 21:56:40,890 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2015-07-17 21:56:40,890 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-07-17 21:56:40,890 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-07-17 21:56:40,893 INFO org.apache.hadoop.http.HttpServer: adding path spec: /node/*
2015-07-17 21:56:40,893 INFO org.apache.hadoop.http.HttpServer: adding path spec: /ws/*
2015-07-17 21:56:40,895 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 8042
2015-07-17 21:56:40,895 INFO org.mortbay.log: jetty-6.1.26
2015-07-17 21:56:40,922 INFO org.mortbay.log: Extract jar:file:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2015-07-17 21:56:41,257 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:8042
2015-07-17 21:56:41,257 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app /node started at 8042
2015-07-17 21:56:41,540 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2015-07-17 21:56:41,570 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8031
2015-07-17 21:56:41,744 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 647646739
2015-07-17 21:56:41,747 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for nm-tokens, got key with id :1710204624
2015-07-17 21:56:41,748 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as ubuntu01:39845 with total resource of <memory:8192, vCores:8>
2015-07-17 21:56:41,748 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2015-07-17 22:15:54,999 ERROR org.apache.hadoop.yarn.server.nodemanager.NodeManager: RECEIVED SIGNAL 15: SIGTERM
2015-07-17 22:15:55,018 INFO org.mortbay.log: Stopped SelectChannelConnector@0.0.0.0:8042
2015-07-17 22:15:55,021 INFO org.apache.hadoop.ipc.Server: Stopping server on 39845
2015-07-17 22:15:55,026 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 39845
2015-07-17 22:15:55,027 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2015-07-17 22:15:55,027 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.
2015-07-17 22:15:55,036 INFO org.apache.hadoop.ipc.Server: Stopping server on 8040
2015-07-17 22:15:55,037 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8040
2015-07-17 22:15:55,037 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2015-07-17 22:15:55,038 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Public cache exiting
2015-07-17 22:15:55,038 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NodeManager metrics system...
2015-07-17 22:15:55,039 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system stopped.
2015-07-17 22:15:55,039 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system shutdown complete.
2015-07-17 22:15:55,039 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at ubuntu01/127.0.1.1
************************************************************/
2015-07-27 15:31:03,534 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-07-27 15:31:03,572 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2015-07-27 15:31:04,210 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-07-27 15:31:04,586 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2015-07-27 15:31:04,587 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2015-07-27 15:31:04,587 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2015-07-27 15:31:04,587 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2015-07-27 15:31:04,588 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2015-07-27 15:31:04,588 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2015-07-27 15:31:04,616 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2015-07-27 15:31:04,616 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2015-07-27 15:31:04,665 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-07-27 15:31:04,727 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-07-27 15:31:04,727 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2015-07-27 15:31:04,753 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2015-07-27 15:31:04,753 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2015-07-27 15:31:04,782 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1437982264755
2015-07-27 15:31:04,783 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1436941685461
2015-07-27 15:31:04,787 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1436929195743
2015-07-27 15:31:04,812 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2015-07-27 15:31:04,854 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2015-07-27 15:31:04,854 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2015-07-27 15:31:04,908 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@a7bfbc
2015-07-27 15:31:04,908 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2015-07-27 15:31:04,908 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2015-07-27 15:31:04,908 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2015-07-27 15:31:04,911 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.9 G). Thrashing might happen.
2015-07-27 15:31:04,916 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2015-07-27 15:31:04,966 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 45751
2015-07-27 15:31:04,987 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2015-07-27 15:31:04,987 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2015-07-27 15:31:04,987 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-07-27 15:31:04,987 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 45751: starting
2015-07-27 15:31:04,994 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : ubuntu01:45751
2015-07-27 15:31:04,994 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at ubuntu01/127.0.1.1:45751
2015-07-27 15:31:05,013 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2015-07-27 15:31:05,014 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2015-07-27 15:31:05,014 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-07-27 15:31:05,014 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2015-07-27 15:31:05,015 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2015-07-27 15:31:05,037 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2015-07-27 15:31:05,050 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2015-07-27 15:31:05,052 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2015-07-27 15:31:05,083 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-07-27 15:31:05,134 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-07-27 15:31:05,135 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2015-07-27 15:31:05,135 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-07-27 15:31:05,136 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-07-27 15:31:05,138 INFO org.apache.hadoop.http.HttpServer: adding path spec: /node/*
2015-07-27 15:31:05,139 INFO org.apache.hadoop.http.HttpServer: adding path spec: /ws/*
2015-07-27 15:31:05,141 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 8042
2015-07-27 15:31:05,141 INFO org.mortbay.log: jetty-6.1.26
2015-07-27 15:31:05,167 INFO org.mortbay.log: Extract jar:file:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2015-07-27 15:31:05,532 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:8042
2015-07-27 15:31:05,532 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app /node started at 8042
2015-07-27 15:31:05,830 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2015-07-27 15:31:05,862 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8031
2015-07-27 15:31:06,050 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 1910310116
2015-07-27 15:31:06,054 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for nm-tokens, got key with id :-1680595524
2015-07-27 15:31:06,054 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as ubuntu01:45751 with total resource of <memory:8192, vCores:8>
2015-07-27 15:31:06,054 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2015-07-27 21:50:55,728 ERROR org.apache.hadoop.yarn.server.nodemanager.NodeManager: RECEIVED SIGNAL 15: SIGTERM
2015-07-27 21:50:55,843 INFO org.mortbay.log: Stopped SelectChannelConnector@0.0.0.0:8042
2015-07-27 21:50:55,844 INFO org.apache.hadoop.ipc.Server: Stopping server on 45751
2015-07-27 21:50:55,846 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.
2015-07-27 21:50:55,848 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2015-07-27 21:50:55,848 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 45751
2015-07-27 21:50:55,871 INFO org.apache.hadoop.ipc.Server: Stopping server on 8040
2015-07-27 21:50:55,871 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8040
2015-07-27 21:50:55,872 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2015-07-27 21:50:55,872 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Public cache exiting
2015-07-27 21:50:55,872 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NodeManager metrics system...
2015-07-27 21:50:55,873 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system stopped.
2015-07-27 21:50:55,873 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system shutdown complete.
2015-07-27 21:50:55,873 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at ubuntu01/127.0.1.1
************************************************************/
2015-08-25 16:42:57,010 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-08-25 16:42:57,040 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2015-08-25 16:42:57,708 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-08-25 16:42:58,048 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2015-08-25 16:42:58,049 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2015-08-25 16:42:58,050 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2015-08-25 16:42:58,050 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2015-08-25 16:42:58,050 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2015-08-25 16:42:58,051 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2015-08-25 16:42:58,071 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2015-08-25 16:42:58,071 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2015-08-25 16:42:58,117 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-08-25 16:42:58,180 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-08-25 16:42:58,180 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2015-08-25 16:42:58,204 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2015-08-25 16:42:58,204 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2015-08-25 16:42:58,247 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1437982264755
2015-08-25 16:42:58,260 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1436941685461
2015-08-25 16:42:58,272 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1436929195743
2015-08-25 16:42:58,274 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1440492178206
2015-08-25 16:42:58,317 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2015-08-25 16:42:58,365 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2015-08-25 16:42:58,365 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2015-08-25 16:42:58,419 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@12aa092
2015-08-25 16:42:58,419 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2015-08-25 16:42:58,419 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2015-08-25 16:42:58,419 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2015-08-25 16:42:58,423 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.9 G). Thrashing might happen.
2015-08-25 16:42:58,427 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2015-08-25 16:42:58,479 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 57636
2015-08-25 16:42:58,498 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2015-08-25 16:42:58,498 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2015-08-25 16:42:58,499 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-08-25 16:42:58,499 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 57636: starting
2015-08-25 16:42:58,506 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : ubuntu01:57636
2015-08-25 16:42:58,506 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at ubuntu01/127.0.1.1:57636
2015-08-25 16:42:58,523 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2015-08-25 16:42:58,524 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2015-08-25 16:42:58,524 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-08-25 16:42:58,524 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2015-08-25 16:42:58,525 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2015-08-25 16:42:58,547 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2015-08-25 16:42:58,561 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2015-08-25 16:42:58,563 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2015-08-25 16:42:58,595 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-08-25 16:42:58,648 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-08-25 16:42:58,649 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2015-08-25 16:42:58,650 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-08-25 16:42:58,650 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-08-25 16:42:58,653 INFO org.apache.hadoop.http.HttpServer: adding path spec: /node/*
2015-08-25 16:42:58,653 INFO org.apache.hadoop.http.HttpServer: adding path spec: /ws/*
2015-08-25 16:42:58,655 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 8042
2015-08-25 16:42:58,655 INFO org.mortbay.log: jetty-6.1.26
2015-08-25 16:42:58,682 INFO org.mortbay.log: Extract jar:file:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2015-08-25 16:42:59,040 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:8042
2015-08-25 16:42:59,040 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app /node started at 8042
2015-08-25 16:42:59,352 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2015-08-25 16:42:59,386 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8031
2015-08-25 16:42:59,583 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id -54889756
2015-08-25 16:42:59,586 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for nm-tokens, got key with id :-1273548321
2015-08-25 16:42:59,587 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as ubuntu01:57636 with total resource of <memory:8192, vCores:8>
2015-08-25 16:42:59,587 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2015-08-25 17:11:54,741 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1440492175555_0001_000001 (auth:SIMPLE)
2015-08-25 17:11:54,886 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0001_01_000001 by user liyaohui
2015-08-25 17:11:54,911 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Creating a new application reference for app application_1440492175555_0001
2015-08-25 17:11:54,914 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0001	CONTAINERID=container_1440492175555_0001_01_000001
2015-08-25 17:11:54,914 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440492175555_0001 transitioned from NEW to INITING
2015-08-25 17:11:54,915 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0001_01_000001 to application application_1440492175555_0001
2015-08-25 17:11:54,918 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440492175555_0001 transitioned from INITING to RUNNING
2015-08-25 17:11:54,926 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000001 transitioned from NEW to LOCALIZING
2015-08-25 17:11:54,927 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0001
2015-08-25 17:11:54,936 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0001/job.splitmetainfo transitioned from INIT to DOWNLOADING
2015-08-25 17:11:54,936 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0001/job.jar transitioned from INIT to DOWNLOADING
2015-08-25 17:11:54,936 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0001/job.split transitioned from INIT to DOWNLOADING
2015-08-25 17:11:54,936 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0001/job.xml transitioned from INIT to DOWNLOADING
2015-08-25 17:11:54,936 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1440492175555_0001_01_000001
2015-08-25 17:11:55,036 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1440492175555_0001_01_000001.tokens. Credentials list: 
2015-08-25 17:11:55,110 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user liyaohui
2015-08-25 17:11:55,174 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1440492175555_0001_01_000001.tokens to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0001/container_1440492175555_0001_01_000001.tokens
2015-08-25 17:11:55,175 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: CWD set to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0001 = file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0001
2015-08-25 17:11:55,524 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:11:55,813 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0001/job.splitmetainfo transitioned from DOWNLOADING to LOCALIZED
2015-08-25 17:11:56,184 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0001/job.jar transitioned from DOWNLOADING to LOCALIZED
2015-08-25 17:11:56,230 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0001/job.split transitioned from DOWNLOADING to LOCALIZED
2015-08-25 17:11:56,267 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0001/job.xml transitioned from DOWNLOADING to LOCALIZED
2015-08-25 17:11:56,269 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000001 transitioned from LOCALIZING to LOCALIZED
2015-08-25 17:11:56,309 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000001 transitioned from LOCALIZED to RUNNING
2015-08-25 17:11:56,342 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0001/container_1440492175555_0001_01_000001/default_container_executor.sh]
2015-08-25 17:11:56,534 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:11:57,537 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:11:58,538 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:11:58,609 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0001_01_000001
2015-08-25 17:11:58,637 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 4863 for container-id container_1440492175555_0001_01_000001: 108.9 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 17:11:59,541 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:00,543 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:01,545 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:01,657 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 4863 for container-id container_1440492175555_0001_01_000001: 253.7 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 17:12:02,058 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1440492175555_0001_000001 (auth:SIMPLE)
2015-08-25 17:12:02,062 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0001_01_000003 by user liyaohui
2015-08-25 17:12:02,062 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0001_01_000002 by user liyaohui
2015-08-25 17:12:02,063 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0001	CONTAINERID=container_1440492175555_0001_01_000002
2015-08-25 17:12:02,065 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0001_01_000002 to application application_1440492175555_0001
2015-08-25 17:12:02,067 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0001_01_000003 to application application_1440492175555_0001
2015-08-25 17:12:02,067 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000002 transitioned from NEW to LOCALIZING
2015-08-25 17:12:02,067 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000003 transitioned from NEW to LOCALIZING
2015-08-25 17:12:02,068 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0001
2015-08-25 17:12:02,068 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0001
2015-08-25 17:12:02,068 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 17:12:02,068 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0001	CONTAINERID=container_1440492175555_0001_01_000003
2015-08-25 17:12:02,072 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0001
2015-08-25 17:12:02,072 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0001
2015-08-25 17:12:02,072 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0001
2015-08-25 17:12:02,072 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 17:12:02,073 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0001
2015-08-25 17:12:02,073 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000002 transitioned from LOCALIZING to LOCALIZED
2015-08-25 17:12:02,073 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000003 transitioned from LOCALIZING to LOCALIZED
2015-08-25 17:12:02,101 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000002 transitioned from LOCALIZED to RUNNING
2015-08-25 17:12:02,119 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000003 transitioned from LOCALIZED to RUNNING
2015-08-25 17:12:02,140 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0001/container_1440492175555_0001_01_000002/default_container_executor.sh]
2015-08-25 17:12:02,151 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0001/container_1440492175555_0001_01_000003/default_container_executor.sh]
2015-08-25 17:12:02,546 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:02,547 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:02,547 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:03,552 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:03,552 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:03,552 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:04,554 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:04,554 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:04,560 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:04,658 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0001_01_000002
2015-08-25 17:12:04,658 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0001_01_000003
2015-08-25 17:12:04,684 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 5015 for container-id container_1440492175555_0001_01_000002: 102.2 MB of 1 GB physical memory used; 528.9 MB of 2.1 GB virtual memory used
2015-08-25 17:12:04,716 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 4863 for container-id container_1440492175555_0001_01_000001: 254.8 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 17:12:04,758 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 5026 for container-id container_1440492175555_0001_01_000003: 100.4 MB of 1 GB physical memory used; 526.7 MB of 2.1 GB virtual memory used
2015-08-25 17:12:05,190 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0001_01_000002
2015-08-25 17:12:05,191 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0001	CONTAINERID=container_1440492175555_0001_01_000002
2015-08-25 17:12:05,191 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000002 transitioned from RUNNING to KILLING
2015-08-25 17:12:05,191 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0001_01_000002
2015-08-25 17:12:05,192 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:05,192 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 17:12:05,192 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:05,197 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container container_1440492175555_0001_01_000002 succeeded 
2015-08-25 17:12:05,268 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000002 transitioned from KILLING to EXITED_WITH_SUCCESS
2015-08-25 17:12:05,269 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0001/container_1440492175555_0001_01_000002
2015-08-25 17:12:05,285 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Succeeded	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0001	CONTAINERID=container_1440492175555_0001_01_000002
2015-08-25 17:12:05,286 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000002 transitioned from EXITED_WITH_SUCCESS to DONE
2015-08-25 17:12:05,286 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0001_01_000002 from application application_1440492175555_0001
2015-08-25 17:12:05,291 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0001
2015-08-25 17:12:05,556 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0001_01_000003
2015-08-25 17:12:05,556 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0001	CONTAINERID=container_1440492175555_0001_01_000003
2015-08-25 17:12:05,557 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:05,557 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: 0
2015-08-25 17:12:05,557 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0001_01_000002
2015-08-25 17:12:05,559 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000003 transitioned from RUNNING to KILLING
2015-08-25 17:12:05,559 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0001_01_000003
2015-08-25 17:12:05,559 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 17:12:05,577 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440492175555_0001_01_000003 is : 143
2015-08-25 17:12:05,592 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000003 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 17:12:05,592 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0001/container_1440492175555_0001_01_000003
2015-08-25 17:12:05,594 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0001	CONTAINERID=container_1440492175555_0001_01_000003
2015-08-25 17:12:05,594 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000003 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 17:12:05,594 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0001_01_000003 from application application_1440492175555_0001
2015-08-25 17:12:05,594 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0001
2015-08-25 17:12:06,561 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:06,561 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 17:12:06,561 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0001_01_000003
2015-08-25 17:12:06,973 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0001_01_000004 by user liyaohui
2015-08-25 17:12:06,973 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0001	CONTAINERID=container_1440492175555_0001_01_000004
2015-08-25 17:12:06,974 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0001_01_000004 to application application_1440492175555_0001
2015-08-25 17:12:06,974 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000004 transitioned from NEW to LOCALIZING
2015-08-25 17:12:06,974 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0001
2015-08-25 17:12:06,974 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0001
2015-08-25 17:12:06,974 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 17:12:06,974 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0001
2015-08-25 17:12:06,975 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000004 transitioned from LOCALIZING to LOCALIZED
2015-08-25 17:12:07,007 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000004 transitioned from LOCALIZED to RUNNING
2015-08-25 17:12:07,026 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0001/container_1440492175555_0001_01_000004/default_container_executor.sh]
2015-08-25 17:12:07,563 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:07,563 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:07,759 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0001_01_000004
2015-08-25 17:12:07,759 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0001_01_000002
2015-08-25 17:12:07,759 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0001_01_000003
2015-08-25 17:12:07,775 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 5162 for container-id container_1440492175555_0001_01_000004: 61.7 MB of 1 GB physical memory used; 513.9 MB of 2.1 GB virtual memory used
2015-08-25 17:12:07,794 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 4863 for container-id container_1440492175555_0001_01_000001: 255.1 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 17:12:08,565 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:08,565 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:09,345 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0001_01_000004
2015-08-25 17:12:09,345 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0001	CONTAINERID=container_1440492175555_0001_01_000004
2015-08-25 17:12:09,345 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000004 transitioned from RUNNING to KILLING
2015-08-25 17:12:09,345 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0001_01_000004
2015-08-25 17:12:09,346 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:09,346 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 17:12:09,354 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440492175555_0001_01_000004 is : 143
2015-08-25 17:12:09,367 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000004 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 17:12:09,367 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0001/container_1440492175555_0001_01_000004
2015-08-25 17:12:09,367 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0001	CONTAINERID=container_1440492175555_0001_01_000004
2015-08-25 17:12:09,367 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000004 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 17:12:09,367 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0001_01_000004 from application application_1440492175555_0001
2015-08-25 17:12:09,367 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0001
2015-08-25 17:12:10,351 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:10,351 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 17:12:10,352 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0001_01_000004
2015-08-25 17:12:10,794 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0001_01_000004
2015-08-25 17:12:10,810 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 4863 for container-id container_1440492175555_0001_01_000001: 255.2 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 17:12:10,982 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0001_01_000005 by user liyaohui
2015-08-25 17:12:10,982 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0001	CONTAINERID=container_1440492175555_0001_01_000005
2015-08-25 17:12:10,982 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0001_01_000005 to application application_1440492175555_0001
2015-08-25 17:12:10,983 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000005 transitioned from NEW to LOCALIZING
2015-08-25 17:12:10,983 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0001
2015-08-25 17:12:10,983 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0001
2015-08-25 17:12:10,983 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 17:12:10,983 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0001
2015-08-25 17:12:10,983 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000005 transitioned from LOCALIZING to LOCALIZED
2015-08-25 17:12:11,012 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000005 transitioned from LOCALIZED to RUNNING
2015-08-25 17:12:11,033 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0001/container_1440492175555_0001_01_000005/default_container_executor.sh]
2015-08-25 17:12:11,353 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:11,353 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:12,357 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:12,357 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:13,283 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0001_01_000005
2015-08-25 17:12:13,283 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0001	CONTAINERID=container_1440492175555_0001_01_000005
2015-08-25 17:12:13,283 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:13,283 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000005 transitioned from RUNNING to KILLING
2015-08-25 17:12:13,283 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0001_01_000005
2015-08-25 17:12:13,284 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 17:12:13,290 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440492175555_0001_01_000005 is : 143
2015-08-25 17:12:13,304 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000005 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 17:12:13,304 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0001/container_1440492175555_0001_01_000005
2015-08-25 17:12:13,304 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0001	CONTAINERID=container_1440492175555_0001_01_000005
2015-08-25 17:12:13,304 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000005 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 17:12:13,304 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0001_01_000005 from application application_1440492175555_0001
2015-08-25 17:12:13,304 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0001
2015-08-25 17:12:13,810 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0001_01_000005
2015-08-25 17:12:13,810 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0001_01_000005
2015-08-25 17:12:13,826 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 4863 for container-id container_1440492175555_0001_01_000001: 255.2 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 17:12:14,285 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:14,285 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 17:12:14,285 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0001_01_000005
2015-08-25 17:12:15,287 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:15,998 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0001_01_000006 by user liyaohui
2015-08-25 17:12:15,998 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0001	CONTAINERID=container_1440492175555_0001_01_000006
2015-08-25 17:12:15,999 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0001_01_000006 to application application_1440492175555_0001
2015-08-25 17:12:15,999 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000006 transitioned from NEW to LOCALIZING
2015-08-25 17:12:15,999 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0001
2015-08-25 17:12:15,999 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0001
2015-08-25 17:12:15,999 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 17:12:15,999 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0001
2015-08-25 17:12:15,999 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000006 transitioned from LOCALIZING to LOCALIZED
2015-08-25 17:12:16,025 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000006 transitioned from LOCALIZED to RUNNING
2015-08-25 17:12:16,045 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0001/container_1440492175555_0001_01_000006/default_container_executor.sh]
2015-08-25 17:12:16,289 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:16,289 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 6 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:16,826 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0001_01_000006
2015-08-25 17:12:16,846 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 4863 for container-id container_1440492175555_0001_01_000001: 255.2 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 17:12:16,866 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 5334 for container-id container_1440492175555_0001_01_000006: 63.4 MB of 1 GB physical memory used; 514.9 MB of 2.1 GB virtual memory used
2015-08-25 17:12:17,290 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:17,291 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 6 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:18,293 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:18,293 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 6 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:18,407 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0001_01_000006
2015-08-25 17:12:18,407 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0001	CONTAINERID=container_1440492175555_0001_01_000006
2015-08-25 17:12:18,407 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:18,407 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000006 transitioned from RUNNING to KILLING
2015-08-25 17:12:18,407 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0001_01_000006
2015-08-25 17:12:18,407 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 6 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 17:12:18,413 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440492175555_0001_01_000006 is : 143
2015-08-25 17:12:18,429 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000006 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 17:12:18,429 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0001/container_1440492175555_0001_01_000006
2015-08-25 17:12:18,430 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0001	CONTAINERID=container_1440492175555_0001_01_000006
2015-08-25 17:12:18,430 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000006 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 17:12:18,430 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0001_01_000006 from application application_1440492175555_0001
2015-08-25 17:12:18,430 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0001
2015-08-25 17:12:19,411 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:19,411 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 6 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 17:12:19,411 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0001_01_000006
2015-08-25 17:12:19,867 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0001_01_000006
2015-08-25 17:12:19,895 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 4863 for container-id container_1440492175555_0001_01_000001: 257.2 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 17:12:20,412 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:21,414 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:22,416 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:22,911 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 4863 for container-id container_1440492175555_0001_01_000001: 257.2 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 17:12:23,417 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:12:23,698 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container container_1440492175555_0001_01_000001 succeeded 
2015-08-25 17:12:23,698 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000001 transitioned from RUNNING to EXITED_WITH_SUCCESS
2015-08-25 17:12:23,698 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0001_01_000001
2015-08-25 17:12:23,709 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0001/container_1440492175555_0001_01_000001
2015-08-25 17:12:23,709 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Succeeded	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0001	CONTAINERID=container_1440492175555_0001_01_000001
2015-08-25 17:12:23,709 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0001_01_000001 transitioned from EXITED_WITH_SUCCESS to DONE
2015-08-25 17:12:23,710 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0001_01_000001 from application application_1440492175555_0001
2015-08-25 17:12:23,710 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0001
2015-08-25 17:12:24,418 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_COMPLETE diagnostics: "" exit_status: 0
2015-08-25 17:12:24,419 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0001_01_000001
2015-08-25 17:12:24,439 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1440492175555_0001_000001 (auth:SIMPLE)
2015-08-25 17:12:24,443 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0001_01_000001
2015-08-25 17:12:25,424 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440492175555_0001 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP
2015-08-25 17:12:25,424 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0001
2015-08-25 17:12:25,424 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_STOP for appId application_1440492175555_0001
2015-08-25 17:12:25,425 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440492175555_0001 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED
2015-08-25 17:12:25,425 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler: Scheduling Log Deletion for application: application_1440492175555_0001, with delay of 10800 seconds
2015-08-25 17:12:25,911 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0001_01_000001
2015-08-25 17:17:12,755 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1440492175555_0002_000001 (auth:SIMPLE)
2015-08-25 17:17:12,766 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0002_01_000001 by user liyaohui
2015-08-25 17:17:12,766 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Creating a new application reference for app application_1440492175555_0002
2015-08-25 17:17:12,766 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0002	CONTAINERID=container_1440492175555_0002_01_000001
2015-08-25 17:17:12,766 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440492175555_0002 transitioned from NEW to INITING
2015-08-25 17:17:12,766 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0002_01_000001 to application application_1440492175555_0002
2015-08-25 17:17:12,766 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440492175555_0002 transitioned from INITING to RUNNING
2015-08-25 17:17:12,766 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000001 transitioned from NEW to LOCALIZING
2015-08-25 17:17:12,767 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0002
2015-08-25 17:17:12,767 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0002/job.splitmetainfo transitioned from INIT to DOWNLOADING
2015-08-25 17:17:12,767 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0002/job.jar transitioned from INIT to DOWNLOADING
2015-08-25 17:17:12,767 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0002/job.split transitioned from INIT to DOWNLOADING
2015-08-25 17:17:12,767 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0002/job.xml transitioned from INIT to DOWNLOADING
2015-08-25 17:17:12,767 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1440492175555_0002_01_000001
2015-08-25 17:17:12,771 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1440492175555_0002_01_000001.tokens. Credentials list: 
2015-08-25 17:17:12,773 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user liyaohui
2015-08-25 17:17:12,784 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1440492175555_0002_01_000001.tokens to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0002/container_1440492175555_0002_01_000001.tokens
2015-08-25 17:17:12,784 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: CWD set to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0002 = file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0002
2015-08-25 17:17:12,870 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0002/job.splitmetainfo transitioned from DOWNLOADING to LOCALIZED
2015-08-25 17:17:13,098 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0002/job.jar transitioned from DOWNLOADING to LOCALIZED
2015-08-25 17:17:13,118 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0002/job.split transitioned from DOWNLOADING to LOCALIZED
2015-08-25 17:17:13,138 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0002/job.xml transitioned from DOWNLOADING to LOCALIZED
2015-08-25 17:17:13,138 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000001 transitioned from LOCALIZING to LOCALIZED
2015-08-25 17:17:13,173 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000001 transitioned from LOCALIZED to RUNNING
2015-08-25 17:17:13,196 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0002/container_1440492175555_0002_01_000001/default_container_executor.sh]
2015-08-25 17:17:13,742 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:13,920 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0002_01_000001
2015-08-25 17:17:13,936 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 5907 for container-id container_1440492175555_0002_01_000001: 56.6 MB of 2 GB physical memory used; 1.3 GB of 4.2 GB virtual memory used
2015-08-25 17:17:14,745 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:15,746 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:16,748 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:16,979 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 5907 for container-id container_1440492175555_0002_01_000001: 248.2 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 17:17:17,750 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:18,751 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:18,870 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1440492175555_0002_000001 (auth:SIMPLE)
2015-08-25 17:17:18,879 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0002_01_000002 by user liyaohui
2015-08-25 17:17:18,879 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0002	CONTAINERID=container_1440492175555_0002_01_000002
2015-08-25 17:17:18,879 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0002_01_000002 to application application_1440492175555_0002
2015-08-25 17:17:18,880 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000002 transitioned from NEW to LOCALIZING
2015-08-25 17:17:18,880 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0002
2015-08-25 17:17:18,880 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0002
2015-08-25 17:17:18,880 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 17:17:18,880 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0002
2015-08-25 17:17:18,880 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000002 transitioned from LOCALIZING to LOCALIZED
2015-08-25 17:17:18,906 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000002 transitioned from LOCALIZED to RUNNING
2015-08-25 17:17:18,926 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0002/container_1440492175555_0002_01_000002/default_container_executor.sh]
2015-08-25 17:17:19,753 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:19,753 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:19,979 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0002_01_000002
2015-08-25 17:17:20,001 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6032 for container-id container_1440492175555_0002_01_000002: 75.3 MB of 1 GB physical memory used; 520.0 MB of 2.1 GB virtual memory used
2015-08-25 17:17:20,016 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 5907 for container-id container_1440492175555_0002_01_000001: 254.5 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 17:17:20,757 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:20,757 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:21,086 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0002_01_000002
2015-08-25 17:17:21,086 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0002	CONTAINERID=container_1440492175555_0002_01_000002
2015-08-25 17:17:21,087 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000002 transitioned from RUNNING to KILLING
2015-08-25 17:17:21,087 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0002_01_000002
2015-08-25 17:17:21,087 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:21,087 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 17:17:21,094 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440492175555_0002_01_000002 is : 143
2015-08-25 17:17:21,108 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000002 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 17:17:21,108 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0002/container_1440492175555_0002_01_000002
2015-08-25 17:17:21,108 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0002	CONTAINERID=container_1440492175555_0002_01_000002
2015-08-25 17:17:21,109 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000002 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 17:17:21,109 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0002_01_000002 from application application_1440492175555_0002
2015-08-25 17:17:21,109 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0002
2015-08-25 17:17:22,091 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:22,092 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 17:17:22,092 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0002_01_000002
2015-08-25 17:17:22,778 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0002_01_000003 by user liyaohui
2015-08-25 17:17:22,778 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0002	CONTAINERID=container_1440492175555_0002_01_000003
2015-08-25 17:17:22,778 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0002_01_000003 to application application_1440492175555_0002
2015-08-25 17:17:22,779 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000003 transitioned from NEW to LOCALIZING
2015-08-25 17:17:22,779 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0002
2015-08-25 17:17:22,779 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0002
2015-08-25 17:17:22,779 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 17:17:22,779 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0002
2015-08-25 17:17:22,779 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000003 transitioned from LOCALIZING to LOCALIZED
2015-08-25 17:17:22,798 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000003 transitioned from LOCALIZED to RUNNING
2015-08-25 17:17:22,819 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0002/container_1440492175555_0002_01_000003/default_container_executor.sh]
2015-08-25 17:17:23,016 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0002_01_000003
2015-08-25 17:17:23,016 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0002_01_000002
2015-08-25 17:17:23,031 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 5907 for container-id container_1440492175555_0002_01_000001: 254.7 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 17:17:23,047 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6122 for container-id container_1440492175555_0002_01_000003: 34.6 MB of 1 GB physical memory used; 509.1 MB of 2.1 GB virtual memory used
2015-08-25 17:17:23,093 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:23,093 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:24,096 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:24,097 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:25,001 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0002_01_000003
2015-08-25 17:17:25,001 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0002	CONTAINERID=container_1440492175555_0002_01_000003
2015-08-25 17:17:25,001 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:25,001 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:25,002 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000003 transitioned from RUNNING to KILLING
2015-08-25 17:17:25,002 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0002_01_000003
2015-08-25 17:17:25,006 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440492175555_0002_01_000003 is : 143
2015-08-25 17:17:25,020 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000003 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 17:17:25,020 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0002/container_1440492175555_0002_01_000003
2015-08-25 17:17:25,020 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0002	CONTAINERID=container_1440492175555_0002_01_000003
2015-08-25 17:17:25,020 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000003 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 17:17:25,020 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0002_01_000003 from application application_1440492175555_0002
2015-08-25 17:17:25,020 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0002
2015-08-25 17:17:26,005 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:26,005 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 17:17:26,005 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0002_01_000003
2015-08-25 17:17:26,056 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0002_01_000003
2015-08-25 17:17:26,070 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 5907 for container-id container_1440492175555_0002_01_000001: 254.7 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 17:17:26,792 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0002_01_000004 by user liyaohui
2015-08-25 17:17:26,793 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0002	CONTAINERID=container_1440492175555_0002_01_000004
2015-08-25 17:17:26,793 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0002_01_000004 to application application_1440492175555_0002
2015-08-25 17:17:26,793 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000004 transitioned from NEW to LOCALIZING
2015-08-25 17:17:26,793 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0002
2015-08-25 17:17:26,793 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0002
2015-08-25 17:17:26,793 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 17:17:26,793 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0002
2015-08-25 17:17:26,793 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000004 transitioned from LOCALIZING to LOCALIZED
2015-08-25 17:17:26,813 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000004 transitioned from LOCALIZED to RUNNING
2015-08-25 17:17:26,830 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0002/container_1440492175555_0002_01_000004/default_container_executor.sh]
2015-08-25 17:17:27,007 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:27,007 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:28,008 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:28,009 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:28,947 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0002_01_000004
2015-08-25 17:17:28,947 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0002	CONTAINERID=container_1440492175555_0002_01_000004
2015-08-25 17:17:28,947 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000004 transitioned from RUNNING to KILLING
2015-08-25 17:17:28,947 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0002_01_000004
2015-08-25 17:17:28,948 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:28,948 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 17:17:28,952 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440492175555_0002_01_000004 is : 143
2015-08-25 17:17:28,963 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000004 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 17:17:28,963 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0002/container_1440492175555_0002_01_000004
2015-08-25 17:17:28,963 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0002	CONTAINERID=container_1440492175555_0002_01_000004
2015-08-25 17:17:28,963 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000004 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 17:17:28,963 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0002_01_000004 from application application_1440492175555_0002
2015-08-25 17:17:28,963 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0002
2015-08-25 17:17:29,070 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0002_01_000004
2015-08-25 17:17:29,070 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0002_01_000004
2015-08-25 17:17:29,084 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 5907 for container-id container_1440492175555_0002_01_000001: 254.7 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 17:17:29,950 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:29,950 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 17:17:29,951 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0002_01_000004
2015-08-25 17:17:30,953 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:31,805 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0002_01_000005 by user liyaohui
2015-08-25 17:17:31,805 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0002	CONTAINERID=container_1440492175555_0002_01_000005
2015-08-25 17:17:31,805 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0002_01_000005 to application application_1440492175555_0002
2015-08-25 17:17:31,805 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000005 transitioned from NEW to LOCALIZING
2015-08-25 17:17:31,805 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0002
2015-08-25 17:17:31,806 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0002
2015-08-25 17:17:31,806 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 17:17:31,806 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0002
2015-08-25 17:17:31,806 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000005 transitioned from LOCALIZING to LOCALIZED
2015-08-25 17:17:31,833 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000005 transitioned from LOCALIZED to RUNNING
2015-08-25 17:17:31,859 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0002/container_1440492175555_0002_01_000005/default_container_executor.sh]
2015-08-25 17:17:31,954 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:31,954 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:32,084 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0002_01_000005
2015-08-25 17:17:32,098 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 5907 for container-id container_1440492175555_0002_01_000001: 254.7 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 17:17:32,113 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6294 for container-id container_1440492175555_0002_01_000005: 34.5 MB of 1 GB physical memory used; 509.1 MB of 2.1 GB virtual memory used
2015-08-25 17:17:32,956 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:32,956 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:33,959 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:33,959 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:34,155 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0002_01_000005
2015-08-25 17:17:34,155 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0002	CONTAINERID=container_1440492175555_0002_01_000005
2015-08-25 17:17:34,156 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000005 transitioned from RUNNING to KILLING
2015-08-25 17:17:34,156 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0002_01_000005
2015-08-25 17:17:34,159 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:34,159 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 17:17:34,162 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440492175555_0002_01_000005 is : 143
2015-08-25 17:17:34,179 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000005 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 17:17:34,179 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0002/container_1440492175555_0002_01_000005
2015-08-25 17:17:34,180 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0002	CONTAINERID=container_1440492175555_0002_01_000005
2015-08-25 17:17:34,180 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000005 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 17:17:34,180 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0002_01_000005 from application application_1440492175555_0002
2015-08-25 17:17:34,181 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0002
2015-08-25 17:17:35,113 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0002_01_000005
2015-08-25 17:17:35,126 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 5907 for container-id container_1440492175555_0002_01_000001: 255.4 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 17:17:35,161 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:35,161 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 17:17:35,161 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0002_01_000005
2015-08-25 17:17:36,163 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:37,164 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:38,140 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 5907 for container-id container_1440492175555_0002_01_000001: 256.5 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 17:17:38,166 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:39,167 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:40,168 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:17:40,519 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container container_1440492175555_0002_01_000001 succeeded 
2015-08-25 17:17:40,519 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000001 transitioned from RUNNING to EXITED_WITH_SUCCESS
2015-08-25 17:17:40,520 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0002_01_000001
2015-08-25 17:17:40,530 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0002/container_1440492175555_0002_01_000001
2015-08-25 17:17:40,530 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Succeeded	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0002	CONTAINERID=container_1440492175555_0002_01_000001
2015-08-25 17:17:40,530 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0002_01_000001 transitioned from EXITED_WITH_SUCCESS to DONE
2015-08-25 17:17:40,530 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0002_01_000001 from application application_1440492175555_0002
2015-08-25 17:17:40,530 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0002
2015-08-25 17:17:41,140 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0002_01_000001
2015-08-25 17:17:41,169 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 2 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_COMPLETE diagnostics: "" exit_status: 0
2015-08-25 17:17:41,169 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0002_01_000001
2015-08-25 17:17:41,176 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1440492175555_0002_000001 (auth:SIMPLE)
2015-08-25 17:17:41,181 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0002_01_000001
2015-08-25 17:17:42,171 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440492175555_0002 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP
2015-08-25 17:17:42,171 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0002
2015-08-25 17:17:42,171 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_STOP for appId application_1440492175555_0002
2015-08-25 17:17:42,171 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440492175555_0002 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED
2015-08-25 17:17:42,171 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler: Scheduling Log Deletion for application: application_1440492175555_0002, with delay of 10800 seconds
2015-08-25 17:21:39,365 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1440492175555_0003_000001 (auth:SIMPLE)
2015-08-25 17:21:39,369 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0003_01_000001 by user liyaohui
2015-08-25 17:21:39,369 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Creating a new application reference for app application_1440492175555_0003
2015-08-25 17:21:39,369 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0003	CONTAINERID=container_1440492175555_0003_01_000001
2015-08-25 17:21:39,369 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440492175555_0003 transitioned from NEW to INITING
2015-08-25 17:21:39,369 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0003_01_000001 to application application_1440492175555_0003
2015-08-25 17:21:39,369 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440492175555_0003 transitioned from INITING to RUNNING
2015-08-25 17:21:39,369 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000001 transitioned from NEW to LOCALIZING
2015-08-25 17:21:39,369 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0003
2015-08-25 17:21:39,369 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0003/job.splitmetainfo transitioned from INIT to DOWNLOADING
2015-08-25 17:21:39,369 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0003/job.jar transitioned from INIT to DOWNLOADING
2015-08-25 17:21:39,369 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0003/job.split transitioned from INIT to DOWNLOADING
2015-08-25 17:21:39,369 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0003/job.xml transitioned from INIT to DOWNLOADING
2015-08-25 17:21:39,369 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1440492175555_0003_01_000001
2015-08-25 17:21:39,374 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1440492175555_0003_01_000001.tokens. Credentials list: 
2015-08-25 17:21:39,375 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user liyaohui
2015-08-25 17:21:39,385 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1440492175555_0003_01_000001.tokens to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0003/container_1440492175555_0003_01_000001.tokens
2015-08-25 17:21:39,385 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: CWD set to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0003 = file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0003
2015-08-25 17:21:39,475 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0003/job.splitmetainfo transitioned from DOWNLOADING to LOCALIZED
2015-08-25 17:21:39,715 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0003/job.jar transitioned from DOWNLOADING to LOCALIZED
2015-08-25 17:21:39,735 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0003/job.split transitioned from DOWNLOADING to LOCALIZED
2015-08-25 17:21:39,753 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0003/job.xml transitioned from DOWNLOADING to LOCALIZED
2015-08-25 17:21:39,753 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000001 transitioned from LOCALIZING to LOCALIZED
2015-08-25 17:21:39,776 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000001 transitioned from LOCALIZED to RUNNING
2015-08-25 17:21:39,796 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0003/container_1440492175555_0003_01_000001/default_container_executor.sh]
2015-08-25 17:21:40,358 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:41,146 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0003_01_000001
2015-08-25 17:21:41,160 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6640 for container-id container_1440492175555_0003_01_000001: 86.8 MB of 2 GB physical memory used; 1.3 GB of 4.2 GB virtual memory used
2015-08-25 17:21:41,360 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:42,362 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:43,364 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:44,173 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6640 for container-id container_1440492175555_0003_01_000001: 253.9 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 17:21:44,366 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:45,219 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1440492175555_0003_000001 (auth:SIMPLE)
2015-08-25 17:21:45,223 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0003_01_000002 by user liyaohui
2015-08-25 17:21:45,223 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0003	CONTAINERID=container_1440492175555_0003_01_000002
2015-08-25 17:21:45,223 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0003_01_000002 to application application_1440492175555_0003
2015-08-25 17:21:45,224 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000002 transitioned from NEW to LOCALIZING
2015-08-25 17:21:45,224 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0003
2015-08-25 17:21:45,224 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0003
2015-08-25 17:21:45,224 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 17:21:45,224 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0003
2015-08-25 17:21:45,224 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000002 transitioned from LOCALIZING to LOCALIZED
2015-08-25 17:21:45,246 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000002 transitioned from LOCALIZED to RUNNING
2015-08-25 17:21:45,269 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0003/container_1440492175555_0003_01_000002/default_container_executor.sh]
2015-08-25 17:21:45,368 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:45,368 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:46,369 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:46,370 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:47,174 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0003_01_000002
2015-08-25 17:21:47,187 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6765 for container-id container_1440492175555_0003_01_000002: 102.1 MB of 1 GB physical memory used; 528.9 MB of 2.1 GB virtual memory used
2015-08-25 17:21:47,201 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6640 for container-id container_1440492175555_0003_01_000001: 254.7 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 17:21:47,372 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:47,372 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:47,618 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0003_01_000002
2015-08-25 17:21:47,618 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0003	CONTAINERID=container_1440492175555_0003_01_000002
2015-08-25 17:21:47,619 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000002 transitioned from RUNNING to KILLING
2015-08-25 17:21:47,619 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0003_01_000002
2015-08-25 17:21:47,619 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:47,619 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 17:21:47,628 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440492175555_0003_01_000002 is : 143
2015-08-25 17:21:47,643 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000002 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 17:21:47,643 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0003	CONTAINERID=container_1440492175555_0003_01_000002
2015-08-25 17:21:47,643 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000002 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 17:21:47,643 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0003_01_000002 from application application_1440492175555_0003
2015-08-25 17:21:47,643 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0003
2015-08-25 17:21:47,643 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0003/container_1440492175555_0003_01_000002
2015-08-25 17:21:48,621 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:48,621 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 17:21:48,621 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0003_01_000002
2015-08-25 17:21:49,125 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0003_01_000003 by user liyaohui
2015-08-25 17:21:49,125 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0003	CONTAINERID=container_1440492175555_0003_01_000003
2015-08-25 17:21:49,125 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0003_01_000003 to application application_1440492175555_0003
2015-08-25 17:21:49,125 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000003 transitioned from NEW to LOCALIZING
2015-08-25 17:21:49,126 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0003
2015-08-25 17:21:49,126 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0003
2015-08-25 17:21:49,126 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 17:21:49,126 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0003
2015-08-25 17:21:49,126 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000003 transitioned from LOCALIZING to LOCALIZED
2015-08-25 17:21:49,148 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000003 transitioned from LOCALIZED to RUNNING
2015-08-25 17:21:49,170 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0003/container_1440492175555_0003_01_000003/default_container_executor.sh]
2015-08-25 17:21:49,623 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:49,623 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:50,201 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0003_01_000003
2015-08-25 17:21:50,201 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0003_01_000002
2015-08-25 17:21:50,215 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6640 for container-id container_1440492175555_0003_01_000001: 254.9 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 17:21:50,228 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6856 for container-id container_1440492175555_0003_01_000003: 64.1 MB of 1 GB physical memory used; 515.8 MB of 2.1 GB virtual memory used
2015-08-25 17:21:50,625 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:50,625 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:51,627 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:51,627 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:51,672 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0003_01_000003
2015-08-25 17:21:51,672 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0003	CONTAINERID=container_1440492175555_0003_01_000003
2015-08-25 17:21:51,672 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000003 transitioned from RUNNING to KILLING
2015-08-25 17:21:51,672 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0003_01_000003
2015-08-25 17:21:51,673 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:51,673 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 17:21:51,680 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440492175555_0003_01_000003 is : 143
2015-08-25 17:21:51,691 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000003 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 17:21:51,692 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0003	CONTAINERID=container_1440492175555_0003_01_000003
2015-08-25 17:21:51,692 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000003 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 17:21:51,692 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0003/container_1440492175555_0003_01_000003
2015-08-25 17:21:51,692 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0003_01_000003 from application application_1440492175555_0003
2015-08-25 17:21:51,692 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0003
2015-08-25 17:21:52,674 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:52,674 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 17:21:52,674 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0003_01_000003
2015-08-25 17:21:53,137 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0003_01_000004 by user liyaohui
2015-08-25 17:21:53,137 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0003	CONTAINERID=container_1440492175555_0003_01_000004
2015-08-25 17:21:53,137 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0003_01_000004 to application application_1440492175555_0003
2015-08-25 17:21:53,137 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000004 transitioned from NEW to LOCALIZING
2015-08-25 17:21:53,137 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0003
2015-08-25 17:21:53,137 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0003
2015-08-25 17:21:53,138 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 17:21:53,138 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0003
2015-08-25 17:21:53,138 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000004 transitioned from LOCALIZING to LOCALIZED
2015-08-25 17:21:53,159 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000004 transitioned from LOCALIZED to RUNNING
2015-08-25 17:21:53,177 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0003/container_1440492175555_0003_01_000004/default_container_executor.sh]
2015-08-25 17:21:53,228 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0003_01_000004
2015-08-25 17:21:53,228 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0003_01_000003
2015-08-25 17:21:53,241 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6640 for container-id container_1440492175555_0003_01_000001: 255.3 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 17:21:53,254 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6945 for container-id container_1440492175555_0003_01_000004: 14.6 MB of 1 GB physical memory used; 492.9 MB of 2.1 GB virtual memory used
2015-08-25 17:21:53,676 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:53,677 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:54,680 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:54,680 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:55,402 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0003_01_000004
2015-08-25 17:21:55,402 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0003	CONTAINERID=container_1440492175555_0003_01_000004
2015-08-25 17:21:55,402 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:55,402 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000004 transitioned from RUNNING to KILLING
2015-08-25 17:21:55,402 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0003_01_000004
2015-08-25 17:21:55,402 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 17:21:55,411 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440492175555_0003_01_000004 is : 143
2015-08-25 17:21:55,419 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000004 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 17:21:55,419 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0003/container_1440492175555_0003_01_000004
2015-08-25 17:21:55,420 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0003	CONTAINERID=container_1440492175555_0003_01_000004
2015-08-25 17:21:55,420 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000004 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 17:21:55,420 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0003_01_000004 from application application_1440492175555_0003
2015-08-25 17:21:55,420 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0003
2015-08-25 17:21:56,254 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0003_01_000004
2015-08-25 17:21:56,266 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6640 for container-id container_1440492175555_0003_01_000001: 255.3 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 17:21:56,405 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:56,405 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 17:21:56,405 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0003_01_000004
2015-08-25 17:21:57,406 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:58,152 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0003_01_000005 by user liyaohui
2015-08-25 17:21:58,152 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0003	CONTAINERID=container_1440492175555_0003_01_000005
2015-08-25 17:21:58,152 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0003_01_000005 to application application_1440492175555_0003
2015-08-25 17:21:58,153 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000005 transitioned from NEW to LOCALIZING
2015-08-25 17:21:58,153 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0003
2015-08-25 17:21:58,153 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0003
2015-08-25 17:21:58,153 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 17:21:58,153 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0003
2015-08-25 17:21:58,153 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000005 transitioned from LOCALIZING to LOCALIZED
2015-08-25 17:21:58,173 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000005 transitioned from LOCALIZED to RUNNING
2015-08-25 17:21:58,199 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0003/container_1440492175555_0003_01_000005/default_container_executor.sh]
2015-08-25 17:21:58,407 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:58,408 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:59,266 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0003_01_000005
2015-08-25 17:21:59,281 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 7030 for container-id container_1440492175555_0003_01_000005: 70.6 MB of 1 GB physical memory used; 520.7 MB of 2.1 GB virtual memory used
2015-08-25 17:21:59,294 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6640 for container-id container_1440492175555_0003_01_000001: 255.3 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 17:21:59,410 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:21:59,410 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:22:00,411 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:22:00,412 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:22:00,418 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0003_01_000005
2015-08-25 17:22:00,418 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0003	CONTAINERID=container_1440492175555_0003_01_000005
2015-08-25 17:22:00,418 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:22:00,418 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000005 transitioned from RUNNING to KILLING
2015-08-25 17:22:00,418 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0003_01_000005
2015-08-25 17:22:00,418 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 17:22:00,426 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440492175555_0003_01_000005 is : 143
2015-08-25 17:22:00,457 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000005 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 17:22:00,457 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0003/container_1440492175555_0003_01_000005
2015-08-25 17:22:00,458 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0003	CONTAINERID=container_1440492175555_0003_01_000005
2015-08-25 17:22:00,458 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000005 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 17:22:00,458 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0003_01_000005 from application application_1440492175555_0003
2015-08-25 17:22:00,458 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0003
2015-08-25 17:22:01,421 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:22:01,422 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 17:22:01,422 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0003_01_000005
2015-08-25 17:22:02,294 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0003_01_000005
2015-08-25 17:22:02,307 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6640 for container-id container_1440492175555_0003_01_000001: 256.6 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 17:22:02,423 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:22:03,424 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:22:04,426 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:22:05,319 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6640 for container-id container_1440492175555_0003_01_000001: 256.8 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 17:22:05,428 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:22:06,429 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 17:22:06,791 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container container_1440492175555_0003_01_000001 succeeded 
2015-08-25 17:22:06,791 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000001 transitioned from RUNNING to EXITED_WITH_SUCCESS
2015-08-25 17:22:06,791 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0003_01_000001
2015-08-25 17:22:06,802 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0003/container_1440492175555_0003_01_000001
2015-08-25 17:22:06,802 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Succeeded	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0003	CONTAINERID=container_1440492175555_0003_01_000001
2015-08-25 17:22:06,802 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0003_01_000001 transitioned from EXITED_WITH_SUCCESS to DONE
2015-08-25 17:22:06,802 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0003_01_000001 from application application_1440492175555_0003
2015-08-25 17:22:06,802 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0003
2015-08-25 17:22:07,430 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 3 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_COMPLETE diagnostics: "" exit_status: 0
2015-08-25 17:22:07,430 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0003_01_000001
2015-08-25 17:22:07,438 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1440492175555_0003_000001 (auth:SIMPLE)
2015-08-25 17:22:07,441 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0003_01_000001
2015-08-25 17:22:08,319 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0003_01_000001
2015-08-25 17:22:08,432 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440492175555_0003 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP
2015-08-25 17:22:08,432 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0003
2015-08-25 17:22:08,433 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_STOP for appId application_1440492175555_0003
2015-08-25 17:22:08,433 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440492175555_0003 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED
2015-08-25 17:22:08,433 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler: Scheduling Log Deletion for application: application_1440492175555_0003, with delay of 10800 seconds
2015-08-25 18:47:05,101 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1440492175555_0004_000001 (auth:SIMPLE)
2015-08-25 18:47:05,105 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0004_01_000001 by user liyaohui
2015-08-25 18:47:05,105 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Creating a new application reference for app application_1440492175555_0004
2015-08-25 18:47:05,105 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0004	CONTAINERID=container_1440492175555_0004_01_000001
2015-08-25 18:47:05,106 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440492175555_0004 transitioned from NEW to INITING
2015-08-25 18:47:05,106 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0004_01_000001 to application application_1440492175555_0004
2015-08-25 18:47:05,106 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440492175555_0004 transitioned from INITING to RUNNING
2015-08-25 18:47:05,106 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000001 transitioned from NEW to LOCALIZING
2015-08-25 18:47:05,106 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0004
2015-08-25 18:47:05,106 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0004/job.splitmetainfo transitioned from INIT to DOWNLOADING
2015-08-25 18:47:05,106 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0004/job.jar transitioned from INIT to DOWNLOADING
2015-08-25 18:47:05,106 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0004/job.split transitioned from INIT to DOWNLOADING
2015-08-25 18:47:05,106 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0004/job.xml transitioned from INIT to DOWNLOADING
2015-08-25 18:47:05,106 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1440492175555_0004_01_000001
2015-08-25 18:47:05,111 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1440492175555_0004_01_000001.tokens. Credentials list: 
2015-08-25 18:47:05,113 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user liyaohui
2015-08-25 18:47:05,122 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1440492175555_0004_01_000001.tokens to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0004/container_1440492175555_0004_01_000001.tokens
2015-08-25 18:47:05,122 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: CWD set to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0004 = file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0004
2015-08-25 18:47:05,196 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0004/job.splitmetainfo transitioned from DOWNLOADING to LOCALIZED
2015-08-25 18:47:05,420 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0004/job.jar transitioned from DOWNLOADING to LOCALIZED
2015-08-25 18:47:05,439 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0004/job.split transitioned from DOWNLOADING to LOCALIZED
2015-08-25 18:47:05,465 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0004/job.xml transitioned from DOWNLOADING to LOCALIZED
2015-08-25 18:47:05,465 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000001 transitioned from LOCALIZING to LOCALIZED
2015-08-25 18:47:05,484 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000001 transitioned from LOCALIZED to RUNNING
2015-08-25 18:47:05,501 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0004/container_1440492175555_0004_01_000001/default_container_executor.sh]
2015-08-25 18:47:06,095 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:07,097 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:08,098 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:08,444 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0004_01_000001
2015-08-25 18:47:08,458 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 7821 for container-id container_1440492175555_0004_01_000001: 158.7 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 18:47:09,099 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:10,100 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:11,003 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1440492175555_0004_000001 (auth:SIMPLE)
2015-08-25 18:47:11,007 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0004_01_000002 by user liyaohui
2015-08-25 18:47:11,007 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0004	CONTAINERID=container_1440492175555_0004_01_000002
2015-08-25 18:47:11,007 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0004_01_000002 to application application_1440492175555_0004
2015-08-25 18:47:11,008 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000002 transitioned from NEW to LOCALIZING
2015-08-25 18:47:11,008 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0004
2015-08-25 18:47:11,008 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0004
2015-08-25 18:47:11,008 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 18:47:11,008 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0004
2015-08-25 18:47:11,008 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000002 transitioned from LOCALIZING to LOCALIZED
2015-08-25 18:47:11,047 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000002 transitioned from LOCALIZED to RUNNING
2015-08-25 18:47:11,075 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0004/container_1440492175555_0004_01_000002/default_container_executor.sh]
2015-08-25 18:47:11,101 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:11,101 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:11,458 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0004_01_000002
2015-08-25 18:47:11,471 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 7821 for container-id container_1440492175555_0004_01_000001: 254.9 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 18:47:11,495 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 7946 for container-id container_1440492175555_0004_01_000002: 51.5 MB of 1 GB physical memory used; 511.3 MB of 2.1 GB virtual memory used
2015-08-25 18:47:12,103 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:12,103 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:13,104 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:13,105 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:13,440 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0004_01_000002
2015-08-25 18:47:13,440 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0004	CONTAINERID=container_1440492175555_0004_01_000002
2015-08-25 18:47:13,440 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000002 transitioned from RUNNING to KILLING
2015-08-25 18:47:13,440 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0004_01_000002
2015-08-25 18:47:13,440 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:13,440 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 18:47:13,446 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440492175555_0004_01_000002 is : 143
2015-08-25 18:47:13,456 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000002 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 18:47:13,456 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0004	CONTAINERID=container_1440492175555_0004_01_000002
2015-08-25 18:47:13,456 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000002 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 18:47:13,456 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0004_01_000002 from application application_1440492175555_0004
2015-08-25 18:47:13,456 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0004
2015-08-25 18:47:13,457 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0004/container_1440492175555_0004_01_000002
2015-08-25 18:47:14,441 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:14,441 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 18:47:14,442 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0004_01_000002
2015-08-25 18:47:14,496 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0004_01_000002
2015-08-25 18:47:14,509 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 7821 for container-id container_1440492175555_0004_01_000001: 255.1 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 18:47:14,911 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0004_01_000003 by user liyaohui
2015-08-25 18:47:14,912 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0004_01_000003 to application application_1440492175555_0004
2015-08-25 18:47:14,912 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0004	CONTAINERID=container_1440492175555_0004_01_000003
2015-08-25 18:47:14,912 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000003 transitioned from NEW to LOCALIZING
2015-08-25 18:47:14,912 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0004
2015-08-25 18:47:14,912 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0004
2015-08-25 18:47:14,912 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 18:47:14,912 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0004
2015-08-25 18:47:14,913 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000003 transitioned from LOCALIZING to LOCALIZED
2015-08-25 18:47:14,930 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000003 transitioned from LOCALIZED to RUNNING
2015-08-25 18:47:14,947 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0004/container_1440492175555_0004_01_000003/default_container_executor.sh]
2015-08-25 18:47:15,442 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:15,443 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:16,444 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:16,444 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:17,269 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0004_01_000003
2015-08-25 18:47:17,269 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0004	CONTAINERID=container_1440492175555_0004_01_000003
2015-08-25 18:47:17,269 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000003 transitioned from RUNNING to KILLING
2015-08-25 18:47:17,269 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:17,269 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0004_01_000003
2015-08-25 18:47:17,269 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 18:47:17,274 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440492175555_0004_01_000003 is : 143
2015-08-25 18:47:17,285 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000003 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 18:47:17,285 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0004/container_1440492175555_0004_01_000003
2015-08-25 18:47:17,286 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0004	CONTAINERID=container_1440492175555_0004_01_000003
2015-08-25 18:47:17,286 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000003 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 18:47:17,286 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0004_01_000003 from application application_1440492175555_0004
2015-08-25 18:47:17,286 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0004
2015-08-25 18:47:17,509 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0004_01_000003
2015-08-25 18:47:17,509 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0004_01_000003
2015-08-25 18:47:17,523 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 7821 for container-id container_1440492175555_0004_01_000001: 255.3 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 18:47:18,274 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:18,274 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 18:47:18,274 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0004_01_000003
2015-08-25 18:47:18,924 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0004_01_000004 by user liyaohui
2015-08-25 18:47:18,925 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0004	CONTAINERID=container_1440492175555_0004_01_000004
2015-08-25 18:47:18,925 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0004_01_000004 to application application_1440492175555_0004
2015-08-25 18:47:18,925 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000004 transitioned from NEW to LOCALIZING
2015-08-25 18:47:18,925 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0004
2015-08-25 18:47:18,925 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0004
2015-08-25 18:47:18,925 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 18:47:18,925 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0004
2015-08-25 18:47:18,925 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000004 transitioned from LOCALIZING to LOCALIZED
2015-08-25 18:47:18,943 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000004 transitioned from LOCALIZED to RUNNING
2015-08-25 18:47:18,962 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0004/container_1440492175555_0004_01_000004/default_container_executor.sh]
2015-08-25 18:47:19,275 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:19,275 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:20,277 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:20,277 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:20,523 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0004_01_000004
2015-08-25 18:47:20,537 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 7821 for container-id container_1440492175555_0004_01_000001: 255.3 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 18:47:20,552 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 8123 for container-id container_1440492175555_0004_01_000004: 91.3 MB of 1 GB physical memory used; 527.4 MB of 2.1 GB virtual memory used
2015-08-25 18:47:21,280 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:21,280 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:21,298 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0004_01_000004
2015-08-25 18:47:21,298 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0004	CONTAINERID=container_1440492175555_0004_01_000004
2015-08-25 18:47:21,298 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000004 transitioned from RUNNING to KILLING
2015-08-25 18:47:21,298 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0004_01_000004
2015-08-25 18:47:21,299 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:21,299 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 18:47:21,303 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440492175555_0004_01_000004 is : 143
2015-08-25 18:47:21,315 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000004 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 18:47:21,315 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0004/container_1440492175555_0004_01_000004
2015-08-25 18:47:21,315 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0004	CONTAINERID=container_1440492175555_0004_01_000004
2015-08-25 18:47:21,315 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000004 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 18:47:21,315 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0004_01_000004 from application application_1440492175555_0004
2015-08-25 18:47:21,316 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0004
2015-08-25 18:47:22,300 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:22,300 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 18:47:22,300 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0004_01_000004
2015-08-25 18:47:23,301 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:23,553 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0004_01_000004
2015-08-25 18:47:23,566 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 7821 for container-id container_1440492175555_0004_01_000001: 255.3 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 18:47:23,942 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0004_01_000005 by user liyaohui
2015-08-25 18:47:23,942 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0004	CONTAINERID=container_1440492175555_0004_01_000005
2015-08-25 18:47:23,942 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0004_01_000005 to application application_1440492175555_0004
2015-08-25 18:47:23,942 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000005 transitioned from NEW to LOCALIZING
2015-08-25 18:47:23,942 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0004
2015-08-25 18:47:23,942 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0004
2015-08-25 18:47:23,942 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 18:47:23,942 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0004
2015-08-25 18:47:23,942 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000005 transitioned from LOCALIZING to LOCALIZED
2015-08-25 18:47:23,964 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000005 transitioned from LOCALIZED to RUNNING
2015-08-25 18:47:23,982 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0004/container_1440492175555_0004_01_000005/default_container_executor.sh]
2015-08-25 18:47:24,301 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:24,302 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:25,303 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:25,303 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:26,119 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0004_01_000005
2015-08-25 18:47:26,119 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0004	CONTAINERID=container_1440492175555_0004_01_000005
2015-08-25 18:47:26,119 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:26,119 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000005 transitioned from RUNNING to KILLING
2015-08-25 18:47:26,119 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0004_01_000005
2015-08-25 18:47:26,119 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 18:47:26,128 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440492175555_0004_01_000005 is : 143
2015-08-25 18:47:26,139 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000005 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 18:47:26,139 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0004/container_1440492175555_0004_01_000005
2015-08-25 18:47:26,139 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0004	CONTAINERID=container_1440492175555_0004_01_000005
2015-08-25 18:47:26,139 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000005 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 18:47:26,139 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0004_01_000005 from application application_1440492175555_0004
2015-08-25 18:47:26,139 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0004
2015-08-25 18:47:26,566 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0004_01_000005
2015-08-25 18:47:26,566 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0004_01_000005
2015-08-25 18:47:26,580 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 7821 for container-id container_1440492175555_0004_01_000001: 256.1 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 18:47:27,120 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:27,121 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 18:47:27,121 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0004_01_000005
2015-08-25 18:47:28,124 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:29,125 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:29,594 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 7821 for container-id container_1440492175555_0004_01_000001: 257 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 18:47:30,126 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:31,127 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:32,128 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:47:32,480 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container container_1440492175555_0004_01_000001 succeeded 
2015-08-25 18:47:32,480 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000001 transitioned from RUNNING to EXITED_WITH_SUCCESS
2015-08-25 18:47:32,481 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0004_01_000001
2015-08-25 18:47:32,491 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0004/container_1440492175555_0004_01_000001
2015-08-25 18:47:32,492 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Succeeded	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0004	CONTAINERID=container_1440492175555_0004_01_000001
2015-08-25 18:47:32,492 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0004_01_000001 transitioned from EXITED_WITH_SUCCESS to DONE
2015-08-25 18:47:32,492 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0004_01_000001 from application application_1440492175555_0004
2015-08-25 18:47:32,492 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0004
2015-08-25 18:47:32,594 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0004_01_000001
2015-08-25 18:47:33,129 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 4 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_COMPLETE diagnostics: "" exit_status: 0
2015-08-25 18:47:33,129 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0004_01_000001
2015-08-25 18:47:33,137 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1440492175555_0004_000001 (auth:SIMPLE)
2015-08-25 18:47:33,139 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0004_01_000001
2015-08-25 18:47:34,131 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440492175555_0004 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP
2015-08-25 18:47:34,131 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0004
2015-08-25 18:47:34,131 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_STOP for appId application_1440492175555_0004
2015-08-25 18:47:34,131 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440492175555_0004 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED
2015-08-25 18:47:34,131 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler: Scheduling Log Deletion for application: application_1440492175555_0004, with delay of 10800 seconds
2015-08-25 18:50:34,243 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1440492175555_0005_000001 (auth:SIMPLE)
2015-08-25 18:50:34,247 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0005_01_000001 by user liyaohui
2015-08-25 18:50:34,248 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Creating a new application reference for app application_1440492175555_0005
2015-08-25 18:50:34,248 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0005	CONTAINERID=container_1440492175555_0005_01_000001
2015-08-25 18:50:34,248 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440492175555_0005 transitioned from NEW to INITING
2015-08-25 18:50:34,248 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0005_01_000001 to application application_1440492175555_0005
2015-08-25 18:50:34,248 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440492175555_0005 transitioned from INITING to RUNNING
2015-08-25 18:50:34,248 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000001 transitioned from NEW to LOCALIZING
2015-08-25 18:50:34,248 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0005
2015-08-25 18:50:34,248 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0005/job.splitmetainfo transitioned from INIT to DOWNLOADING
2015-08-25 18:50:34,248 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0005/job.jar transitioned from INIT to DOWNLOADING
2015-08-25 18:50:34,248 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0005/job.split transitioned from INIT to DOWNLOADING
2015-08-25 18:50:34,248 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0005/job.xml transitioned from INIT to DOWNLOADING
2015-08-25 18:50:34,248 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1440492175555_0005_01_000001
2015-08-25 18:50:34,260 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1440492175555_0005_01_000001.tokens. Credentials list: 
2015-08-25 18:50:34,261 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user liyaohui
2015-08-25 18:50:34,271 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1440492175555_0005_01_000001.tokens to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0005/container_1440492175555_0005_01_000001.tokens
2015-08-25 18:50:34,271 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: CWD set to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0005 = file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0005
2015-08-25 18:50:34,347 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0005/job.splitmetainfo transitioned from DOWNLOADING to LOCALIZED
2015-08-25 18:50:34,565 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0005/job.jar transitioned from DOWNLOADING to LOCALIZED
2015-08-25 18:50:34,588 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0005/job.split transitioned from DOWNLOADING to LOCALIZED
2015-08-25 18:50:34,618 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0005/job.xml transitioned from DOWNLOADING to LOCALIZED
2015-08-25 18:50:34,618 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000001 transitioned from LOCALIZING to LOCALIZED
2015-08-25 18:50:34,640 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000001 transitioned from LOCALIZED to RUNNING
2015-08-25 18:50:34,660 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0005/container_1440492175555_0005_01_000001/default_container_executor.sh]
2015-08-25 18:50:35,235 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:35,599 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0005_01_000001
2015-08-25 18:50:35,613 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 8689 for container-id container_1440492175555_0005_01_000001: 66.4 MB of 2 GB physical memory used; 1.3 GB of 4.2 GB virtual memory used
2015-08-25 18:50:36,236 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:37,237 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:38,238 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:38,633 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 8689 for container-id container_1440492175555_0005_01_000001: 256.0 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 18:50:39,240 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:40,128 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1440492175555_0005_000001 (auth:SIMPLE)
2015-08-25 18:50:40,131 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0005_01_000002 by user liyaohui
2015-08-25 18:50:40,132 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0005	CONTAINERID=container_1440492175555_0005_01_000002
2015-08-25 18:50:40,132 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0005_01_000002 to application application_1440492175555_0005
2015-08-25 18:50:40,132 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000002 transitioned from NEW to LOCALIZING
2015-08-25 18:50:40,132 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0005
2015-08-25 18:50:40,132 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0005
2015-08-25 18:50:40,132 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 18:50:40,132 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0005
2015-08-25 18:50:40,132 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000002 transitioned from LOCALIZING to LOCALIZED
2015-08-25 18:50:40,152 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000002 transitioned from LOCALIZED to RUNNING
2015-08-25 18:50:40,169 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0005/container_1440492175555_0005_01_000002/default_container_executor.sh]
2015-08-25 18:50:40,241 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:40,241 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:41,242 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:41,242 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:41,635 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0005_01_000002
2015-08-25 18:50:41,650 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 8689 for container-id container_1440492175555_0005_01_000001: 255.1 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 18:50:41,665 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 8814 for container-id container_1440492175555_0005_01_000002: 90.5 MB of 1 GB physical memory used; 526.2 MB of 2.1 GB virtual memory used
2015-08-25 18:50:42,243 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:42,243 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:42,423 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0005_01_000002
2015-08-25 18:50:42,423 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0005	CONTAINERID=container_1440492175555_0005_01_000002
2015-08-25 18:50:42,423 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:42,423 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:42,423 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000002 transitioned from RUNNING to KILLING
2015-08-25 18:50:42,424 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0005_01_000002
2015-08-25 18:50:42,432 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440492175555_0005_01_000002 is : 143
2015-08-25 18:50:42,447 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000002 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 18:50:42,447 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0005	CONTAINERID=container_1440492175555_0005_01_000002
2015-08-25 18:50:42,447 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000002 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 18:50:42,447 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0005_01_000002 from application application_1440492175555_0005
2015-08-25 18:50:42,447 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0005
2015-08-25 18:50:42,447 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0005/container_1440492175555_0005_01_000002
2015-08-25 18:50:43,428 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:43,428 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 18:50:43,428 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0005_01_000002
2015-08-25 18:50:44,047 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0005_01_000003 by user liyaohui
2015-08-25 18:50:44,047 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0005	CONTAINERID=container_1440492175555_0005_01_000003
2015-08-25 18:50:44,047 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0005_01_000003 to application application_1440492175555_0005
2015-08-25 18:50:44,048 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000003 transitioned from NEW to LOCALIZING
2015-08-25 18:50:44,048 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0005
2015-08-25 18:50:44,048 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0005
2015-08-25 18:50:44,048 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 18:50:44,048 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0005
2015-08-25 18:50:44,048 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000003 transitioned from LOCALIZING to LOCALIZED
2015-08-25 18:50:44,075 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000003 transitioned from LOCALIZED to RUNNING
2015-08-25 18:50:44,099 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0005/container_1440492175555_0005_01_000003/default_container_executor.sh]
2015-08-25 18:50:44,429 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:44,429 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:44,665 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0005_01_000003
2015-08-25 18:50:44,665 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0005_01_000002
2015-08-25 18:50:44,679 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 8904 for container-id container_1440492175555_0005_01_000003: 57.4 MB of 1 GB physical memory used; 512.3 MB of 2.1 GB virtual memory used
2015-08-25 18:50:44,693 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 8689 for container-id container_1440492175555_0005_01_000001: 255.4 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 18:50:45,431 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:45,432 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:46,432 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:46,433 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:46,457 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0005_01_000003
2015-08-25 18:50:46,457 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0005	CONTAINERID=container_1440492175555_0005_01_000003
2015-08-25 18:50:46,457 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000003 transitioned from RUNNING to KILLING
2015-08-25 18:50:46,457 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0005_01_000003
2015-08-25 18:50:46,457 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:46,457 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 18:50:46,462 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440492175555_0005_01_000003 is : 143
2015-08-25 18:50:46,476 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000003 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 18:50:46,477 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0005/container_1440492175555_0005_01_000003
2015-08-25 18:50:46,477 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0005	CONTAINERID=container_1440492175555_0005_01_000003
2015-08-25 18:50:46,477 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000003 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 18:50:46,477 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0005_01_000003 from application application_1440492175555_0005
2015-08-25 18:50:46,477 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0005
2015-08-25 18:50:47,458 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:47,458 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 18:50:47,458 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0005_01_000003
2015-08-25 18:50:47,694 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0005_01_000003
2015-08-25 18:50:47,707 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 8689 for container-id container_1440492175555_0005_01_000001: 255.4 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 18:50:48,056 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0005_01_000004 by user liyaohui
2015-08-25 18:50:48,056 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0005	CONTAINERID=container_1440492175555_0005_01_000004
2015-08-25 18:50:48,056 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0005_01_000004 to application application_1440492175555_0005
2015-08-25 18:50:48,060 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000004 transitioned from NEW to LOCALIZING
2015-08-25 18:50:48,060 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0005
2015-08-25 18:50:48,060 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0005
2015-08-25 18:50:48,060 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 18:50:48,060 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0005
2015-08-25 18:50:48,060 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000004 transitioned from LOCALIZING to LOCALIZED
2015-08-25 18:50:48,079 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000004 transitioned from LOCALIZED to RUNNING
2015-08-25 18:50:48,096 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0005/container_1440492175555_0005_01_000004/default_container_executor.sh]
2015-08-25 18:50:48,459 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:48,459 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:49,460 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:49,460 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:50,341 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0005_01_000004
2015-08-25 18:50:50,341 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0005	CONTAINERID=container_1440492175555_0005_01_000004
2015-08-25 18:50:50,341 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000004 transitioned from RUNNING to KILLING
2015-08-25 18:50:50,341 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0005_01_000004
2015-08-25 18:50:50,342 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:50,342 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 18:50:50,350 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440492175555_0005_01_000004 is : 143
2015-08-25 18:50:50,361 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000004 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 18:50:50,362 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0005/container_1440492175555_0005_01_000004
2015-08-25 18:50:50,363 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0005	CONTAINERID=container_1440492175555_0005_01_000004
2015-08-25 18:50:50,363 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000004 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 18:50:50,364 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0005_01_000004 from application application_1440492175555_0005
2015-08-25 18:50:50,364 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0005
2015-08-25 18:50:50,708 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0005_01_000004
2015-08-25 18:50:50,708 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0005_01_000004
2015-08-25 18:50:50,721 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 8689 for container-id container_1440492175555_0005_01_000001: 255.4 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 18:50:51,342 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:51,343 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 18:50:51,343 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0005_01_000004
2015-08-25 18:50:52,343 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:53,070 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0005_01_000005 by user liyaohui
2015-08-25 18:50:53,070 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0005	CONTAINERID=container_1440492175555_0005_01_000005
2015-08-25 18:50:53,070 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0005_01_000005 to application application_1440492175555_0005
2015-08-25 18:50:53,070 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000005 transitioned from NEW to LOCALIZING
2015-08-25 18:50:53,070 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0005
2015-08-25 18:50:53,070 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0005
2015-08-25 18:50:53,070 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 18:50:53,070 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0005
2015-08-25 18:50:53,071 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000005 transitioned from LOCALIZING to LOCALIZED
2015-08-25 18:50:53,090 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000005 transitioned from LOCALIZED to RUNNING
2015-08-25 18:50:53,108 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0005/container_1440492175555_0005_01_000005/default_container_executor.sh]
2015-08-25 18:50:53,348 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:53,348 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:53,721 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0005_01_000005
2015-08-25 18:50:53,736 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 8689 for container-id container_1440492175555_0005_01_000001: 255.4 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 18:50:53,750 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 9078 for container-id container_1440492175555_0005_01_000005: 57.5 MB of 1 GB physical memory used; 513.9 MB of 2.1 GB virtual memory used
2015-08-25 18:50:54,352 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:54,352 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:55,353 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:55,353 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:55,440 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0005_01_000005
2015-08-25 18:50:55,440 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0005	CONTAINERID=container_1440492175555_0005_01_000005
2015-08-25 18:50:55,440 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000005 transitioned from RUNNING to KILLING
2015-08-25 18:50:55,440 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:55,440 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0005_01_000005
2015-08-25 18:50:55,440 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 18:50:55,449 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440492175555_0005_01_000005 is : 143
2015-08-25 18:50:55,456 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000005 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 18:50:55,456 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0005/container_1440492175555_0005_01_000005
2015-08-25 18:50:55,456 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0005	CONTAINERID=container_1440492175555_0005_01_000005
2015-08-25 18:50:55,456 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000005 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 18:50:55,456 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0005_01_000005 from application application_1440492175555_0005
2015-08-25 18:50:55,456 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0005
2015-08-25 18:50:56,442 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:56,442 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 18:50:56,442 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0005_01_000005
2015-08-25 18:50:56,750 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0005_01_000005
2015-08-25 18:50:56,763 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 8689 for container-id container_1440492175555_0005_01_000001: 256.1 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 18:50:57,443 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:58,444 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:59,445 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:50:59,777 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 8689 for container-id container_1440492175555_0005_01_000001: 257.2 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 18:51:00,446 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:51:01,447 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:51:01,936 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container container_1440492175555_0005_01_000001 succeeded 
2015-08-25 18:51:01,936 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000001 transitioned from RUNNING to EXITED_WITH_SUCCESS
2015-08-25 18:51:01,936 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0005_01_000001
2015-08-25 18:51:01,946 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0005/container_1440492175555_0005_01_000001
2015-08-25 18:51:01,946 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Succeeded	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0005	CONTAINERID=container_1440492175555_0005_01_000001
2015-08-25 18:51:01,946 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0005_01_000001 transitioned from EXITED_WITH_SUCCESS to DONE
2015-08-25 18:51:01,946 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0005_01_000001 from application application_1440492175555_0005
2015-08-25 18:51:01,946 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0005
2015-08-25 18:51:02,447 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 5 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_COMPLETE diagnostics: "" exit_status: 0
2015-08-25 18:51:02,448 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0005_01_000001
2015-08-25 18:51:02,454 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1440492175555_0005_000001 (auth:SIMPLE)
2015-08-25 18:51:02,464 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0005_01_000001
2015-08-25 18:51:02,777 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0005_01_000001
2015-08-25 18:51:03,449 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440492175555_0005 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP
2015-08-25 18:51:03,449 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_STOP for appId application_1440492175555_0005
2015-08-25 18:51:03,449 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0005
2015-08-25 18:51:03,449 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440492175555_0005 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED
2015-08-25 18:51:03,449 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler: Scheduling Log Deletion for application: application_1440492175555_0005, with delay of 10800 seconds
2015-08-25 18:54:30,551 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1440492175555_0006_000001 (auth:SIMPLE)
2015-08-25 18:54:30,557 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0006_01_000001 by user liyaohui
2015-08-25 18:54:30,558 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Creating a new application reference for app application_1440492175555_0006
2015-08-25 18:54:30,558 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0006	CONTAINERID=container_1440492175555_0006_01_000001
2015-08-25 18:54:30,558 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440492175555_0006 transitioned from NEW to INITING
2015-08-25 18:54:30,558 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0006_01_000001 to application application_1440492175555_0006
2015-08-25 18:54:30,558 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440492175555_0006 transitioned from INITING to RUNNING
2015-08-25 18:54:30,558 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000001 transitioned from NEW to LOCALIZING
2015-08-25 18:54:30,558 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0006
2015-08-25 18:54:30,558 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0006/job.splitmetainfo transitioned from INIT to DOWNLOADING
2015-08-25 18:54:30,558 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0006/job.jar transitioned from INIT to DOWNLOADING
2015-08-25 18:54:30,558 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0006/job.split transitioned from INIT to DOWNLOADING
2015-08-25 18:54:30,558 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0006/job.xml transitioned from INIT to DOWNLOADING
2015-08-25 18:54:30,558 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1440492175555_0006_01_000001
2015-08-25 18:54:30,562 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1440492175555_0006_01_000001.tokens. Credentials list: 
2015-08-25 18:54:30,564 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user liyaohui
2015-08-25 18:54:30,574 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1440492175555_0006_01_000001.tokens to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0006/container_1440492175555_0006_01_000001.tokens
2015-08-25 18:54:30,574 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: CWD set to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0006 = file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0006
2015-08-25 18:54:30,670 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0006/job.splitmetainfo transitioned from DOWNLOADING to LOCALIZED
2015-08-25 18:54:30,873 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0006/job.jar transitioned from DOWNLOADING to LOCALIZED
2015-08-25 18:54:30,891 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0006/job.split transitioned from DOWNLOADING to LOCALIZED
2015-08-25 18:54:30,910 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0006/job.xml transitioned from DOWNLOADING to LOCALIZED
2015-08-25 18:54:30,910 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000001 transitioned from LOCALIZING to LOCALIZED
2015-08-25 18:54:30,929 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000001 transitioned from LOCALIZED to RUNNING
2015-08-25 18:54:30,949 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0006/container_1440492175555_0006_01_000001/default_container_executor.sh]
2015-08-25 18:54:31,545 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:32,548 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:32,783 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0006_01_000001
2015-08-25 18:54:32,800 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 9386 for container-id container_1440492175555_0006_01_000001: 101.1 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 18:54:33,549 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:34,550 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:35,551 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:35,812 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 9386 for container-id container_1440492175555_0006_01_000001: 256.3 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 18:54:36,416 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1440492175555_0006_000001 (auth:SIMPLE)
2015-08-25 18:54:36,420 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0006_01_000002 by user liyaohui
2015-08-25 18:54:36,420 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0006	CONTAINERID=container_1440492175555_0006_01_000002
2015-08-25 18:54:36,420 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0006_01_000002 to application application_1440492175555_0006
2015-08-25 18:54:36,420 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000002 transitioned from NEW to LOCALIZING
2015-08-25 18:54:36,420 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0006
2015-08-25 18:54:36,420 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0006
2015-08-25 18:54:36,420 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 18:54:36,420 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0006
2015-08-25 18:54:36,421 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000002 transitioned from LOCALIZING to LOCALIZED
2015-08-25 18:54:36,446 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000002 transitioned from LOCALIZED to RUNNING
2015-08-25 18:54:36,465 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0006/container_1440492175555_0006_01_000002/default_container_executor.sh]
2015-08-25 18:54:36,552 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:36,552 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:37,554 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:37,554 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:38,555 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:38,555 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:38,810 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0006_01_000002
2015-08-25 18:54:38,810 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0006	CONTAINERID=container_1440492175555_0006_01_000002
2015-08-25 18:54:38,810 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000002 transitioned from RUNNING to KILLING
2015-08-25 18:54:38,810 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0006_01_000002
2015-08-25 18:54:38,810 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:38,811 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 18:54:38,813 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0006_01_000002
2015-08-25 18:54:38,819 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440492175555_0006_01_000002 is : 143
2015-08-25 18:54:38,833 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000002 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 18:54:38,834 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0006	CONTAINERID=container_1440492175555_0006_01_000002
2015-08-25 18:54:38,834 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000002 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 18:54:38,834 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0006_01_000002 from application application_1440492175555_0006
2015-08-25 18:54:38,834 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0006
2015-08-25 18:54:38,834 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0006/container_1440492175555_0006_01_000002
2015-08-25 18:54:38,835 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 9386 for container-id container_1440492175555_0006_01_000001: 257.2 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 18:54:39,812 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:39,812 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 18:54:39,812 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0006_01_000002
2015-08-25 18:54:40,326 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0006_01_000003 by user liyaohui
2015-08-25 18:54:40,327 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0006	CONTAINERID=container_1440492175555_0006_01_000003
2015-08-25 18:54:40,327 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0006_01_000003 to application application_1440492175555_0006
2015-08-25 18:54:40,327 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000003 transitioned from NEW to LOCALIZING
2015-08-25 18:54:40,327 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0006
2015-08-25 18:54:40,327 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0006
2015-08-25 18:54:40,327 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 18:54:40,328 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0006
2015-08-25 18:54:40,328 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000003 transitioned from LOCALIZING to LOCALIZED
2015-08-25 18:54:40,349 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000003 transitioned from LOCALIZED to RUNNING
2015-08-25 18:54:40,368 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0006/container_1440492175555_0006_01_000003/default_container_executor.sh]
2015-08-25 18:54:40,813 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:40,813 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:41,814 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:41,814 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:41,835 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0006_01_000003
2015-08-25 18:54:41,835 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0006_01_000002
2015-08-25 18:54:41,853 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 9386 for container-id container_1440492175555_0006_01_000001: 257.5 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 18:54:41,870 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 9601 for container-id container_1440492175555_0006_01_000003: 88.3 MB of 1 GB physical memory used; 525.6 MB of 2.1 GB virtual memory used
2015-08-25 18:54:42,602 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0006_01_000003
2015-08-25 18:54:42,602 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0006	CONTAINERID=container_1440492175555_0006_01_000003
2015-08-25 18:54:42,602 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000003 transitioned from RUNNING to KILLING
2015-08-25 18:54:42,602 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0006_01_000003
2015-08-25 18:54:42,602 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:42,603 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 18:54:42,608 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440492175555_0006_01_000003 is : 143
2015-08-25 18:54:42,622 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000003 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 18:54:42,622 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0006/container_1440492175555_0006_01_000003
2015-08-25 18:54:42,623 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0006	CONTAINERID=container_1440492175555_0006_01_000003
2015-08-25 18:54:42,623 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000003 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 18:54:42,623 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0006_01_000003 from application application_1440492175555_0006
2015-08-25 18:54:42,623 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0006
2015-08-25 18:54:43,605 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:43,605 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 18:54:43,605 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0006_01_000003
2015-08-25 18:54:44,336 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0006_01_000004 by user liyaohui
2015-08-25 18:54:44,336 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0006	CONTAINERID=container_1440492175555_0006_01_000004
2015-08-25 18:54:44,337 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0006_01_000004 to application application_1440492175555_0006
2015-08-25 18:54:44,337 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000004 transitioned from NEW to LOCALIZING
2015-08-25 18:54:44,337 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0006
2015-08-25 18:54:44,337 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0006
2015-08-25 18:54:44,337 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 18:54:44,337 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0006
2015-08-25 18:54:44,337 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000004 transitioned from LOCALIZING to LOCALIZED
2015-08-25 18:54:44,356 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000004 transitioned from LOCALIZED to RUNNING
2015-08-25 18:54:44,373 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0006/container_1440492175555_0006_01_000004/default_container_executor.sh]
2015-08-25 18:54:44,606 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:44,606 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:44,870 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0006_01_000004
2015-08-25 18:54:44,870 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0006_01_000003
2015-08-25 18:54:44,885 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 9688 for container-id container_1440492175555_0006_01_000004: 56.5 MB of 1 GB physical memory used; 513.1 MB of 2.1 GB virtual memory used
2015-08-25 18:54:44,900 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 9386 for container-id container_1440492175555_0006_01_000001: 257.5 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 18:54:45,607 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:45,607 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:46,609 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:46,609 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:46,729 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0006_01_000004
2015-08-25 18:54:46,729 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0006	CONTAINERID=container_1440492175555_0006_01_000004
2015-08-25 18:54:46,729 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000004 transitioned from RUNNING to KILLING
2015-08-25 18:54:46,729 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0006_01_000004
2015-08-25 18:54:46,729 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:46,730 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 18:54:46,735 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440492175555_0006_01_000004 is : 143
2015-08-25 18:54:46,745 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000004 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 18:54:46,745 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0006/container_1440492175555_0006_01_000004
2015-08-25 18:54:46,746 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0006	CONTAINERID=container_1440492175555_0006_01_000004
2015-08-25 18:54:46,746 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000004 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 18:54:46,746 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0006_01_000004 from application application_1440492175555_0006
2015-08-25 18:54:46,746 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0006
2015-08-25 18:54:47,731 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:47,731 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 18:54:47,732 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0006_01_000004
2015-08-25 18:54:47,900 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0006_01_000004
2015-08-25 18:54:47,913 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 9386 for container-id container_1440492175555_0006_01_000001: 257.5 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 18:54:48,732 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:49,349 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0006_01_000005 by user liyaohui
2015-08-25 18:54:49,349 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0006	CONTAINERID=container_1440492175555_0006_01_000005
2015-08-25 18:54:49,349 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0006_01_000005 to application application_1440492175555_0006
2015-08-25 18:54:49,349 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000005 transitioned from NEW to LOCALIZING
2015-08-25 18:54:49,349 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0006
2015-08-25 18:54:49,349 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0006
2015-08-25 18:54:49,349 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 18:54:49,349 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0006
2015-08-25 18:54:49,349 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000005 transitioned from LOCALIZING to LOCALIZED
2015-08-25 18:54:49,369 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000005 transitioned from LOCALIZED to RUNNING
2015-08-25 18:54:49,387 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0006/container_1440492175555_0006_01_000005/default_container_executor.sh]
2015-08-25 18:54:49,733 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:49,733 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:50,734 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:50,734 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:50,914 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0006_01_000005
2015-08-25 18:54:50,942 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 9386 for container-id container_1440492175555_0006_01_000001: 257.5 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 18:54:50,957 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 9775 for container-id container_1440492175555_0006_01_000005: 90.2 MB of 1 GB physical memory used; 525.8 MB of 2.1 GB virtual memory used
2015-08-25 18:54:51,677 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0006_01_000005
2015-08-25 18:54:51,677 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0006	CONTAINERID=container_1440492175555_0006_01_000005
2015-08-25 18:54:51,677 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000005 transitioned from RUNNING to KILLING
2015-08-25 18:54:51,677 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:51,677 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0006_01_000005
2015-08-25 18:54:51,678 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 18:54:51,687 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440492175555_0006_01_000005 is : 143
2015-08-25 18:54:51,702 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000005 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 18:54:51,702 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0006/container_1440492175555_0006_01_000005
2015-08-25 18:54:51,703 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0006	CONTAINERID=container_1440492175555_0006_01_000005
2015-08-25 18:54:51,703 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000005 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 18:54:51,703 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0006_01_000005 from application application_1440492175555_0006
2015-08-25 18:54:51,703 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0006
2015-08-25 18:54:52,679 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:52,679 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 18:54:52,679 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0006_01_000005
2015-08-25 18:54:53,680 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:53,958 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0006_01_000005
2015-08-25 18:54:53,972 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 9386 for container-id container_1440492175555_0006_01_000001: 259.1 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 18:54:54,681 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:55,682 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:56,683 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:56,986 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 9386 for container-id container_1440492175555_0006_01_000001: 259.1 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 18:54:57,683 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 18:54:58,036 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container container_1440492175555_0006_01_000001 succeeded 
2015-08-25 18:54:58,036 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000001 transitioned from RUNNING to EXITED_WITH_SUCCESS
2015-08-25 18:54:58,036 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0006_01_000001
2015-08-25 18:54:58,056 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Succeeded	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0006	CONTAINERID=container_1440492175555_0006_01_000001
2015-08-25 18:54:58,056 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0006_01_000001 transitioned from EXITED_WITH_SUCCESS to DONE
2015-08-25 18:54:58,056 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0006_01_000001 from application application_1440492175555_0006
2015-08-25 18:54:58,056 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0006
2015-08-25 18:54:58,056 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0006/container_1440492175555_0006_01_000001
2015-08-25 18:54:58,684 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 6 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_COMPLETE diagnostics: "" exit_status: 0
2015-08-25 18:54:58,685 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0006_01_000001
2015-08-25 18:54:58,693 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1440492175555_0006_000001 (auth:SIMPLE)
2015-08-25 18:54:58,697 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0006_01_000001
2015-08-25 18:54:59,686 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440492175555_0006 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP
2015-08-25 18:54:59,686 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_STOP for appId application_1440492175555_0006
2015-08-25 18:54:59,686 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0006
2015-08-25 18:54:59,686 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440492175555_0006 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED
2015-08-25 18:54:59,686 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler: Scheduling Log Deletion for application: application_1440492175555_0006, with delay of 10800 seconds
2015-08-25 18:54:59,986 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0006_01_000001
2015-08-25 19:47:51,351 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1440492175555_0007_000001 (auth:SIMPLE)
2015-08-25 19:47:51,358 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0007_01_000001 by user liyaohui
2015-08-25 19:47:51,358 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Creating a new application reference for app application_1440492175555_0007
2015-08-25 19:47:51,358 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0007	CONTAINERID=container_1440492175555_0007_01_000001
2015-08-25 19:47:51,359 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440492175555_0007 transitioned from NEW to INITING
2015-08-25 19:47:51,359 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0007_01_000001 to application application_1440492175555_0007
2015-08-25 19:47:51,359 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440492175555_0007 transitioned from INITING to RUNNING
2015-08-25 19:47:51,359 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000001 transitioned from NEW to LOCALIZING
2015-08-25 19:47:51,359 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0007
2015-08-25 19:47:51,359 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0007/job.splitmetainfo transitioned from INIT to DOWNLOADING
2015-08-25 19:47:51,359 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0007/job.jar transitioned from INIT to DOWNLOADING
2015-08-25 19:47:51,359 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0007/job.split transitioned from INIT to DOWNLOADING
2015-08-25 19:47:51,359 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0007/job.xml transitioned from INIT to DOWNLOADING
2015-08-25 19:47:51,359 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1440492175555_0007_01_000001
2015-08-25 19:47:51,364 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1440492175555_0007_01_000001.tokens. Credentials list: 
2015-08-25 19:47:51,365 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user liyaohui
2015-08-25 19:47:51,374 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1440492175555_0007_01_000001.tokens to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0007/container_1440492175555_0007_01_000001.tokens
2015-08-25 19:47:51,374 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: CWD set to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0007 = file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0007
2015-08-25 19:47:51,454 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0007/job.splitmetainfo transitioned from DOWNLOADING to LOCALIZED
2015-08-25 19:47:51,701 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0007/job.jar transitioned from DOWNLOADING to LOCALIZED
2015-08-25 19:47:51,721 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0007/job.split transitioned from DOWNLOADING to LOCALIZED
2015-08-25 19:47:51,739 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0007/job.xml transitioned from DOWNLOADING to LOCALIZED
2015-08-25 19:47:51,739 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000001 transitioned from LOCALIZING to LOCALIZED
2015-08-25 19:47:51,759 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000001 transitioned from LOCALIZED to RUNNING
2015-08-25 19:47:51,776 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0007/container_1440492175555_0007_01_000001/default_container_executor.sh]
2015-08-25 19:47:52,338 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:47:53,343 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:47:54,072 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0007_01_000001
2015-08-25 19:47:54,087 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 11294 for container-id container_1440492175555_0007_01_000001: 75.1 MB of 2 GB physical memory used; 1.3 GB of 4.2 GB virtual memory used
2015-08-25 19:47:54,343 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:47:55,344 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:47:56,345 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:47:57,100 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 11294 for container-id container_1440492175555_0007_01_000001: 208.6 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 19:47:57,348 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:47:58,349 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:47:58,522 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1440492175555_0007_000001 (auth:SIMPLE)
2015-08-25 19:47:58,525 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0007_01_000002 by user liyaohui
2015-08-25 19:47:58,526 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0007	CONTAINERID=container_1440492175555_0007_01_000002
2015-08-25 19:47:58,526 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0007_01_000002 to application application_1440492175555_0007
2015-08-25 19:47:58,526 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000002 transitioned from NEW to LOCALIZING
2015-08-25 19:47:58,526 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0007
2015-08-25 19:47:58,526 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0007
2015-08-25 19:47:58,526 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 19:47:58,526 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0007
2015-08-25 19:47:58,526 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000002 transitioned from LOCALIZING to LOCALIZED
2015-08-25 19:47:58,545 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000002 transitioned from LOCALIZED to RUNNING
2015-08-25 19:47:58,568 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0007/container_1440492175555_0007_01_000002/default_container_executor.sh]
2015-08-25 19:47:59,350 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:47:59,350 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:00,100 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0007_01_000002
2015-08-25 19:48:00,113 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 11294 for container-id container_1440492175555_0007_01_000001: 210.4 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 19:48:00,126 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 11424 for container-id container_1440492175555_0007_01_000002: 89.9 MB of 1 GB physical memory used; 526.0 MB of 2.1 GB virtual memory used
2015-08-25 19:48:00,352 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:00,352 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:00,721 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0007_01_000002
2015-08-25 19:48:00,721 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0007	CONTAINERID=container_1440492175555_0007_01_000002
2015-08-25 19:48:00,721 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000002 transitioned from RUNNING to KILLING
2015-08-25 19:48:00,721 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0007_01_000002
2015-08-25 19:48:00,721 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:00,721 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 19:48:00,725 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440492175555_0007_01_000002 is : 143
2015-08-25 19:48:00,741 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000002 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 19:48:00,741 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0007/container_1440492175555_0007_01_000002
2015-08-25 19:48:00,743 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0007	CONTAINERID=container_1440492175555_0007_01_000002
2015-08-25 19:48:00,743 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000002 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 19:48:00,743 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0007_01_000002 from application application_1440492175555_0007
2015-08-25 19:48:00,743 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0007
2015-08-25 19:48:01,722 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:01,722 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 2 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 19:48:01,722 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0007_01_000002
2015-08-25 19:48:02,429 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0007_01_000003 by user liyaohui
2015-08-25 19:48:02,429 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0007	CONTAINERID=container_1440492175555_0007_01_000003
2015-08-25 19:48:02,429 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0007_01_000003 to application application_1440492175555_0007
2015-08-25 19:48:02,430 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000003 transitioned from NEW to LOCALIZING
2015-08-25 19:48:02,430 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0007
2015-08-25 19:48:02,430 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0007
2015-08-25 19:48:02,430 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 19:48:02,430 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0007
2015-08-25 19:48:02,430 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000003 transitioned from LOCALIZING to LOCALIZED
2015-08-25 19:48:02,449 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000003 transitioned from LOCALIZED to RUNNING
2015-08-25 19:48:02,466 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0007/container_1440492175555_0007_01_000003/default_container_executor.sh]
2015-08-25 19:48:02,723 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:02,723 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:03,126 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0007_01_000003
2015-08-25 19:48:03,127 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0007_01_000002
2015-08-25 19:48:03,140 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 11294 for container-id container_1440492175555_0007_01_000001: 210.6 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 19:48:03,153 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 11509 for container-id container_1440492175555_0007_01_000003: 57.4 MB of 1 GB physical memory used; 513.2 MB of 2.1 GB virtual memory used
2015-08-25 19:48:03,725 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:03,725 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:04,525 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0007_01_000003
2015-08-25 19:48:04,525 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0007	CONTAINERID=container_1440492175555_0007_01_000003
2015-08-25 19:48:04,525 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000003 transitioned from RUNNING to KILLING
2015-08-25 19:48:04,525 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0007_01_000003
2015-08-25 19:48:04,525 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:04,525 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 19:48:04,530 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440492175555_0007_01_000003 is : 143
2015-08-25 19:48:04,541 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000003 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 19:48:04,541 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0007/container_1440492175555_0007_01_000003
2015-08-25 19:48:04,541 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0007	CONTAINERID=container_1440492175555_0007_01_000003
2015-08-25 19:48:04,541 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000003 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 19:48:04,541 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0007_01_000003 from application application_1440492175555_0007
2015-08-25 19:48:04,541 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0007
2015-08-25 19:48:05,526 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:05,527 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 3 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 19:48:05,527 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0007_01_000003
2015-08-25 19:48:06,153 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0007_01_000003
2015-08-25 19:48:06,165 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 11294 for container-id container_1440492175555_0007_01_000001: 210.6 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 19:48:06,451 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0007_01_000004 by user liyaohui
2015-08-25 19:48:06,452 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0007	CONTAINERID=container_1440492175555_0007_01_000004
2015-08-25 19:48:06,452 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0007_01_000004 to application application_1440492175555_0007
2015-08-25 19:48:06,452 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000004 transitioned from NEW to LOCALIZING
2015-08-25 19:48:06,452 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0007
2015-08-25 19:48:06,452 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0007
2015-08-25 19:48:06,452 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 19:48:06,452 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0007
2015-08-25 19:48:06,452 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000004 transitioned from LOCALIZING to LOCALIZED
2015-08-25 19:48:06,472 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000004 transitioned from LOCALIZED to RUNNING
2015-08-25 19:48:06,490 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0007/container_1440492175555_0007_01_000004/default_container_executor.sh]
2015-08-25 19:48:06,527 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:06,527 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:07,528 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:07,528 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:08,529 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:08,529 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:08,563 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0007_01_000004
2015-08-25 19:48:08,564 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0007	CONTAINERID=container_1440492175555_0007_01_000004
2015-08-25 19:48:08,564 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000004 transitioned from RUNNING to KILLING
2015-08-25 19:48:08,564 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0007_01_000004
2015-08-25 19:48:08,564 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:08,564 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 19:48:08,569 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440492175555_0007_01_000004 is : 143
2015-08-25 19:48:08,580 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000004 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 19:48:08,580 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0007/container_1440492175555_0007_01_000004
2015-08-25 19:48:08,581 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0007	CONTAINERID=container_1440492175555_0007_01_000004
2015-08-25 19:48:08,581 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000004 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 19:48:08,581 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0007_01_000004 from application application_1440492175555_0007
2015-08-25 19:48:08,581 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0007
2015-08-25 19:48:09,165 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0007_01_000004
2015-08-25 19:48:09,166 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0007_01_000004
2015-08-25 19:48:09,178 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 11294 for container-id container_1440492175555_0007_01_000001: 210.6 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 19:48:09,567 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:09,567 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 4 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 19:48:09,567 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0007_01_000004
2015-08-25 19:48:10,568 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:11,468 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440492175555_0007_01_000005 by user liyaohui
2015-08-25 19:48:11,468 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0007	CONTAINERID=container_1440492175555_0007_01_000005
2015-08-25 19:48:11,469 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440492175555_0007_01_000005 to application application_1440492175555_0007
2015-08-25 19:48:11,469 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000005 transitioned from NEW to LOCALIZING
2015-08-25 19:48:11,469 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440492175555_0007
2015-08-25 19:48:11,469 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440492175555_0007
2015-08-25 19:48:11,469 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 19:48:11,470 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440492175555_0007
2015-08-25 19:48:11,470 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000005 transitioned from LOCALIZING to LOCALIZED
2015-08-25 19:48:11,488 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000005 transitioned from LOCALIZED to RUNNING
2015-08-25 19:48:11,506 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0007/container_1440492175555_0007_01_000005/default_container_executor.sh]
2015-08-25 19:48:11,569 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:11,569 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:12,178 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440492175555_0007_01_000005
2015-08-25 19:48:12,191 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 11294 for container-id container_1440492175555_0007_01_000001: 210.6 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 19:48:12,204 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 11671 for container-id container_1440492175555_0007_01_000005: 63.0 MB of 1 GB physical memory used; 514.3 MB of 2.1 GB virtual memory used
2015-08-25 19:48:12,570 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:12,570 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:13,571 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:13,571 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:13,604 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0007_01_000005
2015-08-25 19:48:13,605 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440492175555_0007	CONTAINERID=container_1440492175555_0007_01_000005
2015-08-25 19:48:13,605 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:13,605 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000005 transitioned from RUNNING to KILLING
2015-08-25 19:48:13,605 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0007_01_000005
2015-08-25 19:48:13,605 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 19:48:13,613 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440492175555_0007_01_000005 is : 143
2015-08-25 19:48:13,621 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000005 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 19:48:13,621 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0007/container_1440492175555_0007_01_000005
2015-08-25 19:48:13,622 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0007	CONTAINERID=container_1440492175555_0007_01_000005
2015-08-25 19:48:13,622 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000005 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 19:48:13,622 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0007_01_000005 from application application_1440492175555_0007
2015-08-25 19:48:13,622 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0007
2015-08-25 19:48:14,606 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:14,607 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 5 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 19:48:14,607 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0007_01_000005
2015-08-25 19:48:15,204 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0007_01_000005
2015-08-25 19:48:15,216 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 11294 for container-id container_1440492175555_0007_01_000001: 211.4 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 19:48:15,607 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:16,608 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:17,609 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:18,228 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 11294 for container-id container_1440492175555_0007_01_000001: 213.2 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 19:48:18,610 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:19,610 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:20,611 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 19:48:20,688 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container container_1440492175555_0007_01_000001 succeeded 
2015-08-25 19:48:20,689 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000001 transitioned from RUNNING to EXITED_WITH_SUCCESS
2015-08-25 19:48:20,689 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440492175555_0007_01_000001
2015-08-25 19:48:20,700 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0007/container_1440492175555_0007_01_000001
2015-08-25 19:48:20,700 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Succeeded	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440492175555_0007	CONTAINERID=container_1440492175555_0007_01_000001
2015-08-25 19:48:20,700 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440492175555_0007_01_000001 transitioned from EXITED_WITH_SUCCESS to DONE
2015-08-25 19:48:20,700 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440492175555_0007_01_000001 from application application_1440492175555_0007
2015-08-25 19:48:20,700 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440492175555_0007
2015-08-25 19:48:21,228 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440492175555_0007_01_000001
2015-08-25 19:48:21,611 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 7 cluster_timestamp: 1440492175555 } attemptId: 1 } id: 1 } state: C_COMPLETE diagnostics: "" exit_status: 0
2015-08-25 19:48:21,611 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440492175555_0007_01_000001
2015-08-25 19:48:21,615 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1440492175555_0007_000001 (auth:SIMPLE)
2015-08-25 19:48:21,618 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440492175555_0007_01_000001
2015-08-25 19:48:22,612 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440492175555_0007 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP
2015-08-25 19:48:22,612 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440492175555_0007
2015-08-25 19:48:22,612 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_STOP for appId application_1440492175555_0007
2015-08-25 19:48:22,612 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440492175555_0007 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED
2015-08-25 19:48:22,612 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler: Scheduling Log Deletion for application: application_1440492175555_0007, with delay of 10800 seconds
2015-08-25 19:55:00,190 ERROR org.apache.hadoop.yarn.server.nodemanager.NodeManager: RECEIVED SIGNAL 15: SIGTERM
2015-08-25 19:55:00,197 INFO org.mortbay.log: Stopped SelectChannelConnector@0.0.0.0:8042
2015-08-25 19:55:00,200 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Applications still running : [application_1440492175555_0007, application_1440492175555_0005, application_1440492175555_0006, application_1440492175555_0003, application_1440492175555_0004, application_1440492175555_0001, application_1440492175555_0002]
2015-08-25 19:55:00,200 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Waiting for Applications to be Finished
2015-08-25 19:55:04,200 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Done waiting for Applications to be Finished. Still alive: [application_1440492175555_0007, application_1440492175555_0005, application_1440492175555_0006, application_1440492175555_0003, application_1440492175555_0004, application_1440492175555_0001, application_1440492175555_0002]
2015-08-25 19:55:04,200 INFO org.apache.hadoop.ipc.Server: Stopping server on 57636
2015-08-25 19:55:04,201 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 57636
2015-08-25 19:55:04,201 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2015-08-25 20:10:32,864 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-08-25 20:10:32,887 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2015-08-25 20:10:33,460 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-08-25 20:10:33,832 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2015-08-25 20:10:33,833 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2015-08-25 20:10:33,834 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2015-08-25 20:10:33,834 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2015-08-25 20:10:33,835 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2015-08-25 20:10:33,835 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2015-08-25 20:10:33,859 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2015-08-25 20:10:33,859 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2015-08-25 20:10:33,906 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-08-25 20:10:33,966 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-08-25 20:10:33,966 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2015-08-25 20:10:33,981 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2015-08-25 20:10:33,982 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2015-08-25 20:10:34,019 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1437982264755
2015-08-25 20:10:34,027 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1436941685461
2015-08-25 20:10:34,035 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1436929195743
2015-08-25 20:10:34,035 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1440504633983
2015-08-25 20:10:34,038 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1440504633983/liyaohui
2015-08-25 20:10:34,038 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1440492178206
2015-08-25 20:10:34,075 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2015-08-25 20:10:34,121 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2015-08-25 20:10:34,121 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2015-08-25 20:10:34,172 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@16b83cc
2015-08-25 20:10:34,172 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2015-08-25 20:10:34,172 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2015-08-25 20:10:34,172 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2015-08-25 20:10:34,175 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.9 G). Thrashing might happen.
2015-08-25 20:10:34,179 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2015-08-25 20:10:34,250 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 35822
2015-08-25 20:10:34,268 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2015-08-25 20:10:34,269 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2015-08-25 20:10:34,269 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-08-25 20:10:34,269 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 35822: starting
2015-08-25 20:10:34,276 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : ubuntu01:35822
2015-08-25 20:10:34,276 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at ubuntu01/127.0.1.1:35822
2015-08-25 20:10:34,291 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2015-08-25 20:10:34,292 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2015-08-25 20:10:34,292 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-08-25 20:10:34,292 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2015-08-25 20:10:34,293 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2015-08-25 20:10:34,316 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2015-08-25 20:10:34,329 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2015-08-25 20:10:34,331 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2015-08-25 20:10:34,363 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-08-25 20:10:34,415 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-08-25 20:10:34,417 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2015-08-25 20:10:34,417 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-08-25 20:10:34,417 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-08-25 20:10:34,420 INFO org.apache.hadoop.http.HttpServer: adding path spec: /node/*
2015-08-25 20:10:34,420 INFO org.apache.hadoop.http.HttpServer: adding path spec: /ws/*
2015-08-25 20:10:34,422 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 8042
2015-08-25 20:10:34,422 INFO org.mortbay.log: jetty-6.1.26
2015-08-25 20:10:34,449 INFO org.mortbay.log: Extract jar:file:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2015-08-25 20:10:34,797 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:8042
2015-08-25 20:10:34,797 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app /node started at 8042
2015-08-25 20:10:35,107 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2015-08-25 20:10:35,141 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8031
2015-08-25 20:10:35,321 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id -1981729219
2015-08-25 20:10:35,324 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for nm-tokens, got key with id :-574400876
2015-08-25 20:10:35,324 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as ubuntu01:35822 with total resource of <memory:8192, vCores:8>
2015-08-25 20:10:35,325 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2015-08-25 20:14:01,845 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1440504631392_0001_000001 (auth:SIMPLE)
2015-08-25 20:14:01,983 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440504631392_0001_01_000001 by user liyaohui
2015-08-25 20:14:02,006 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Creating a new application reference for app application_1440504631392_0001
2015-08-25 20:14:02,009 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440504631392_0001	CONTAINERID=container_1440504631392_0001_01_000001
2015-08-25 20:14:02,009 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440504631392_0001 transitioned from NEW to INITING
2015-08-25 20:14:02,009 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440504631392_0001_01_000001 to application application_1440504631392_0001
2015-08-25 20:14:02,014 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440504631392_0001 transitioned from INITING to RUNNING
2015-08-25 20:14:02,021 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000001 transitioned from NEW to LOCALIZING
2015-08-25 20:14:02,022 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440504631392_0001
2015-08-25 20:14:02,030 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440504631392_0001/job.splitmetainfo transitioned from INIT to DOWNLOADING
2015-08-25 20:14:02,030 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440504631392_0001/job.jar transitioned from INIT to DOWNLOADING
2015-08-25 20:14:02,030 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440504631392_0001/job.split transitioned from INIT to DOWNLOADING
2015-08-25 20:14:02,030 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440504631392_0001/job.xml transitioned from INIT to DOWNLOADING
2015-08-25 20:14:02,030 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1440504631392_0001_01_000001
2015-08-25 20:14:02,134 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1440504631392_0001_01_000001.tokens. Credentials list: 
2015-08-25 20:14:02,147 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user liyaohui
2015-08-25 20:14:02,210 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /home/liyaohui/hadoop/tmp/nm-local-dir/nmPrivate/container_1440504631392_0001_01_000001.tokens to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440504631392_0001/container_1440504631392_0001_01_000001.tokens
2015-08-25 20:14:02,210 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: CWD set to /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440504631392_0001 = file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440504631392_0001
2015-08-25 20:14:02,628 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:02,908 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440504631392_0001/job.splitmetainfo transitioned from DOWNLOADING to LOCALIZED
2015-08-25 20:14:03,231 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440504631392_0001/job.jar transitioned from DOWNLOADING to LOCALIZED
2015-08-25 20:14:03,269 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440504631392_0001/job.split transitioned from DOWNLOADING to LOCALIZED
2015-08-25 20:14:03,305 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://ubuntu01:9000/tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440504631392_0001/job.xml transitioned from DOWNLOADING to LOCALIZED
2015-08-25 20:14:03,306 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000001 transitioned from LOCALIZING to LOCALIZED
2015-08-25 20:14:03,637 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000001 transitioned from LOCALIZED to RUNNING
2015-08-25 20:14:03,637 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:03,674 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440504631392_0001/container_1440504631392_0001_01_000001/default_container_executor.sh]
2015-08-25 20:14:04,336 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440504631392_0001_01_000001
2015-08-25 20:14:04,362 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 3917 for container-id container_1440504631392_0001_01_000001: 62.2 MB of 2 GB physical memory used; 1.3 GB of 4.2 GB virtual memory used
2015-08-25 20:14:04,639 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:05,641 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:06,644 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:07,416 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 3917 for container-id container_1440504631392_0001_01_000001: 241.6 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 20:14:07,647 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:08,649 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:09,352 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1440504631392_0001_000001 (auth:SIMPLE)
2015-08-25 20:14:09,359 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440504631392_0001_01_000002 by user liyaohui
2015-08-25 20:14:09,359 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440504631392_0001	CONTAINERID=container_1440504631392_0001_01_000002
2015-08-25 20:14:09,359 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440504631392_0001_01_000002 to application application_1440504631392_0001
2015-08-25 20:14:09,360 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000002 transitioned from NEW to LOCALIZING
2015-08-25 20:14:09,360 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440504631392_0001
2015-08-25 20:14:09,360 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440504631392_0001
2015-08-25 20:14:09,360 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 20:14:09,363 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440504631392_0001
2015-08-25 20:14:09,363 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000002 transitioned from LOCALIZING to LOCALIZED
2015-08-25 20:14:09,397 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000002 transitioned from LOCALIZED to RUNNING
2015-08-25 20:14:09,418 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440504631392_0001/container_1440504631392_0001_01_000002/default_container_executor.sh]
2015-08-25 20:14:09,651 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:09,651 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:10,417 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440504631392_0001_01_000002
2015-08-25 20:14:10,440 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 4042 for container-id container_1440504631392_0001_01_000002: 70.3 MB of 1 GB physical memory used; 520.4 MB of 2.1 GB virtual memory used
2015-08-25 20:14:10,465 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 3917 for container-id container_1440504631392_0001_01_000001: 253.9 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 20:14:10,654 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:10,654 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:11,633 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440504631392_0001_01_000002
2015-08-25 20:14:11,634 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440504631392_0001	CONTAINERID=container_1440504631392_0001_01_000002
2015-08-25 20:14:11,634 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000002 transitioned from RUNNING to KILLING
2015-08-25 20:14:11,634 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440504631392_0001_01_000002
2015-08-25 20:14:11,634 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:11,635 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 2 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 20:14:11,642 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440504631392_0001_01_000002 is : 143
2015-08-25 20:14:11,679 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000002 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 20:14:11,681 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440504631392_0001/container_1440504631392_0001_01_000002
2015-08-25 20:14:11,681 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440504631392_0001	CONTAINERID=container_1440504631392_0001_01_000002
2015-08-25 20:14:11,684 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000002 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 20:14:11,685 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440504631392_0001_01_000002 from application application_1440504631392_0001
2015-08-25 20:14:11,685 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440504631392_0001
2015-08-25 20:14:12,638 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:12,638 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 2 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 20:14:12,639 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440504631392_0001_01_000002
2015-08-25 20:14:13,262 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440504631392_0001_01_000003 by user liyaohui
2015-08-25 20:14:13,262 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440504631392_0001	CONTAINERID=container_1440504631392_0001_01_000003
2015-08-25 20:14:13,262 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440504631392_0001_01_000003 to application application_1440504631392_0001
2015-08-25 20:14:13,262 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000003 transitioned from NEW to LOCALIZING
2015-08-25 20:14:13,262 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440504631392_0001
2015-08-25 20:14:13,262 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440504631392_0001
2015-08-25 20:14:13,263 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 20:14:13,263 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440504631392_0001
2015-08-25 20:14:13,263 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000003 transitioned from LOCALIZING to LOCALIZED
2015-08-25 20:14:13,287 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000003 transitioned from LOCALIZED to RUNNING
2015-08-25 20:14:13,310 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440504631392_0001/container_1440504631392_0001_01_000003/default_container_executor.sh]
2015-08-25 20:14:13,465 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440504631392_0001_01_000003
2015-08-25 20:14:13,465 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440504631392_0001_01_000002
2015-08-25 20:14:13,481 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 4132 for container-id container_1440504631392_0001_01_000003: 29.3 MB of 1 GB physical memory used; 506.6 MB of 2.1 GB virtual memory used
2015-08-25 20:14:13,497 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 3917 for container-id container_1440504631392_0001_01_000001: 254.1 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 20:14:13,647 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:13,647 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:14,652 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:14,652 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:15,606 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440504631392_0001_01_000003
2015-08-25 20:14:15,606 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440504631392_0001	CONTAINERID=container_1440504631392_0001_01_000003
2015-08-25 20:14:15,606 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000003 transitioned from RUNNING to KILLING
2015-08-25 20:14:15,606 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440504631392_0001_01_000003
2015-08-25 20:14:15,608 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:15,608 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 3 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 20:14:15,629 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440504631392_0001_01_000003 is : 143
2015-08-25 20:14:15,644 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000003 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 20:14:15,644 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440504631392_0001/container_1440504631392_0001_01_000003
2015-08-25 20:14:15,645 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440504631392_0001	CONTAINERID=container_1440504631392_0001_01_000003
2015-08-25 20:14:15,645 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000003 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 20:14:15,645 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440504631392_0001_01_000003 from application application_1440504631392_0001
2015-08-25 20:14:15,645 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440504631392_0001
2015-08-25 20:14:16,497 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440504631392_0001_01_000003
2015-08-25 20:14:16,511 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 3917 for container-id container_1440504631392_0001_01_000001: 254.3 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 20:14:16,611 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:16,611 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 3 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 20:14:16,611 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440504631392_0001_01_000003
2015-08-25 20:14:17,272 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440504631392_0001_01_000004 by user liyaohui
2015-08-25 20:14:17,272 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440504631392_0001	CONTAINERID=container_1440504631392_0001_01_000004
2015-08-25 20:14:17,272 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440504631392_0001_01_000004 to application application_1440504631392_0001
2015-08-25 20:14:17,273 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000004 transitioned from NEW to LOCALIZING
2015-08-25 20:14:17,273 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440504631392_0001
2015-08-25 20:14:17,273 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440504631392_0001
2015-08-25 20:14:17,273 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 20:14:17,273 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440504631392_0001
2015-08-25 20:14:17,273 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000004 transitioned from LOCALIZING to LOCALIZED
2015-08-25 20:14:17,293 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000004 transitioned from LOCALIZED to RUNNING
2015-08-25 20:14:17,316 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440504631392_0001/container_1440504631392_0001_01_000004/default_container_executor.sh]
2015-08-25 20:14:17,613 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:17,614 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 4 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:18,616 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:18,616 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 4 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:19,471 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440504631392_0001_01_000004
2015-08-25 20:14:19,471 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440504631392_0001	CONTAINERID=container_1440504631392_0001_01_000004
2015-08-25 20:14:19,471 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000004 transitioned from RUNNING to KILLING
2015-08-25 20:14:19,471 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440504631392_0001_01_000004
2015-08-25 20:14:19,472 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:19,472 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 4 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 20:14:19,477 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440504631392_0001_01_000004 is : 143
2015-08-25 20:14:19,490 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000004 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 20:14:19,490 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440504631392_0001	CONTAINERID=container_1440504631392_0001_01_000004
2015-08-25 20:14:19,490 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000004 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 20:14:19,491 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440504631392_0001/container_1440504631392_0001_01_000004
2015-08-25 20:14:19,491 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440504631392_0001_01_000004 from application application_1440504631392_0001
2015-08-25 20:14:19,491 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440504631392_0001
2015-08-25 20:14:19,511 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440504631392_0001_01_000004
2015-08-25 20:14:19,511 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440504631392_0001_01_000004
2015-08-25 20:14:19,525 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 3917 for container-id container_1440504631392_0001_01_000001: 254.4 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 20:14:20,474 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:20,474 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 4 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 20:14:20,474 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440504631392_0001_01_000004
2015-08-25 20:14:21,476 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:22,287 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1440504631392_0001_01_000005 by user liyaohui
2015-08-25 20:14:22,287 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440504631392_0001	CONTAINERID=container_1440504631392_0001_01_000005
2015-08-25 20:14:22,287 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Adding container_1440504631392_0001_01_000005 to application application_1440504631392_0001
2015-08-25 20:14:22,288 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000005 transitioned from NEW to LOCALIZING
2015-08-25 20:14:22,288 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1440504631392_0001
2015-08-25 20:14:22,288 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1440504631392_0001
2015-08-25 20:14:22,288 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2015-08-25 20:14:22,288 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1440504631392_0001
2015-08-25 20:14:22,288 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000005 transitioned from LOCALIZING to LOCALIZED
2015-08-25 20:14:22,312 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000005 transitioned from LOCALIZED to RUNNING
2015-08-25 20:14:22,335 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [nice, -n, 0, bash, /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440504631392_0001/container_1440504631392_0001_01_000005/default_container_executor.sh]
2015-08-25 20:14:22,479 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:22,479 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:22,525 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1440504631392_0001_01_000005
2015-08-25 20:14:22,549 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 4305 for container-id container_1440504631392_0001_01_000005: 34.0 MB of 1 GB physical memory used; 509.1 MB of 2.1 GB virtual memory used
2015-08-25 20:14:22,565 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 3917 for container-id container_1440504631392_0001_01_000001: 254.4 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 20:14:23,482 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:23,482 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:24,484 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:24,485 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:24,577 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440504631392_0001_01_000005
2015-08-25 20:14:24,577 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	IP=127.0.0.1	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1440504631392_0001	CONTAINERID=container_1440504631392_0001_01_000005
2015-08-25 20:14:24,577 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000005 transitioned from RUNNING to KILLING
2015-08-25 20:14:24,578 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440504631392_0001_01_000005
2015-08-25 20:14:24,579 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:24,579 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 5 } state: C_RUNNING diagnostics: "Container killed by the ApplicationMaster.\n" exit_status: -1000
2015-08-25 20:14:24,585 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1440504631392_0001_01_000005 is : 143
2015-08-25 20:14:24,605 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000005 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2015-08-25 20:14:24,606 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440504631392_0001/container_1440504631392_0001_01_000005
2015-08-25 20:14:24,606 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440504631392_0001	CONTAINERID=container_1440504631392_0001_01_000005
2015-08-25 20:14:24,606 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000005 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2015-08-25 20:14:24,606 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440504631392_0001_01_000005 from application application_1440504631392_0001
2015-08-25 20:14:24,606 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440504631392_0001
2015-08-25 20:14:25,565 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440504631392_0001_01_000005
2015-08-25 20:14:25,581 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 3917 for container-id container_1440504631392_0001_01_000001: 255.0 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 20:14:25,582 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:25,582 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 5 } state: C_COMPLETE diagnostics: "Container killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\n" exit_status: 143
2015-08-25 20:14:25,582 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440504631392_0001_01_000005
2015-08-25 20:14:26,584 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:27,586 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:28,590 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:28,597 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 3917 for container-id container_1440504631392_0001_01_000001: 256.0 MB of 2 GB physical memory used; 1.4 GB of 4.2 GB virtual memory used
2015-08-25 20:14:29,591 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:30,593 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_RUNNING diagnostics: "" exit_status: -1000
2015-08-25 20:14:30,957 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Container container_1440504631392_0001_01_000001 succeeded 
2015-08-25 20:14:30,957 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000001 transitioned from RUNNING to EXITED_WITH_SUCCESS
2015-08-25 20:14:30,957 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1440504631392_0001_01_000001
2015-08-25 20:14:30,969 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440504631392_0001/container_1440504631392_0001_01_000001
2015-08-25 20:14:30,969 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=liyaohui	OPERATION=Container Finished - Succeeded	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1440504631392_0001	CONTAINERID=container_1440504631392_0001_01_000001
2015-08-25 20:14:30,969 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1440504631392_0001_01_000001 transitioned from EXITED_WITH_SUCCESS to DONE
2015-08-25 20:14:30,969 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Removing container_1440504631392_0001_01_000001 from application application_1440504631392_0001
2015-08-25 20:14:30,969 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1440504631392_0001
2015-08-25 20:14:31,595 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out status for container: container_id { app_attempt_id { application_id { id: 1 cluster_timestamp: 1440504631392 } attemptId: 1 } id: 1 } state: C_COMPLETE diagnostics: "" exit_status: 0
2015-08-25 20:14:31,595 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed container container_1440504631392_0001_01_000001
2015-08-25 20:14:31,597 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1440504631392_0001_01_000001
2015-08-25 20:14:31,610 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1440504631392_0001_000001 (auth:SIMPLE)
2015-08-25 20:14:31,615 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1440504631392_0001_01_000001
2015-08-25 20:14:32,600 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440504631392_0001 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP
2015-08-25 20:14:32,601 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/liyaohui/hadoop/tmp/nm-local-dir/usercache/liyaohui/appcache/application_1440504631392_0001
2015-08-25 20:14:32,601 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_STOP for appId application_1440504631392_0001
2015-08-25 20:14:32,602 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Application application_1440504631392_0001 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED
2015-08-25 20:14:32,602 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler: Scheduling Log Deletion for application: application_1440504631392_0001, with delay of 10800 seconds
2015-08-25 20:14:58,619 ERROR org.apache.hadoop.yarn.server.nodemanager.NodeManager: RECEIVED SIGNAL 15: SIGTERM
2015-08-25 20:14:58,662 INFO org.mortbay.log: Stopped SelectChannelConnector@0.0.0.0:8042
2015-08-25 20:14:58,668 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Applications still running : [application_1440504631392_0001]
2015-08-25 20:14:58,668 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Waiting for Applications to be Finished
2015-08-25 20:15:02,669 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Done waiting for Applications to be Finished. Still alive: [application_1440504631392_0001]
2015-08-25 20:15:02,669 INFO org.apache.hadoop.ipc.Server: Stopping server on 35822
2015-08-25 20:15:02,670 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 35822
2015-08-25 20:15:02,670 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2015-09-01 20:58:41,789 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-09-01 20:58:41,838 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2015-09-01 20:58:42,466 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-01 20:58:42,860 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2015-09-01 20:58:42,861 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2015-09-01 20:58:42,861 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2015-09-01 20:58:42,862 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2015-09-01 20:58:42,862 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2015-09-01 20:58:42,863 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2015-09-01 20:58:42,886 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2015-09-01 20:58:42,886 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2015-09-01 20:58:42,939 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-09-01 20:58:43,003 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-09-01 20:58:43,003 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2015-09-01 20:58:43,020 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2015-09-01 20:58:43,020 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2015-09-01 20:58:43,054 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1437982264755
2015-09-01 20:58:43,064 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1436941685461
2015-09-01 20:58:43,066 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1436929195743
2015-09-01 20:58:43,067 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1440492178206
2015-09-01 20:58:43,079 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1441112323022
2015-09-01 20:58:43,084 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1441112323022/liyaohui
2015-09-01 20:58:43,098 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2015-09-01 20:58:43,148 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2015-09-01 20:58:43,148 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2015-09-01 20:58:43,198 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@16b83cc
2015-09-01 20:58:43,199 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2015-09-01 20:58:43,199 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2015-09-01 20:58:43,199 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2015-09-01 20:58:43,204 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.9 G). Thrashing might happen.
2015-09-01 20:58:43,209 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2015-09-01 20:58:43,261 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 49377
2015-09-01 20:58:43,282 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2015-09-01 20:58:43,282 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2015-09-01 20:58:43,283 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-09-01 20:58:43,283 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 49377: starting
2015-09-01 20:58:43,293 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : ubuntu01:49377
2015-09-01 20:58:43,293 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at ubuntu01/127.0.1.1:49377
2015-09-01 20:58:43,317 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2015-09-01 20:58:43,318 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2015-09-01 20:58:43,318 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-09-01 20:58:43,318 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2015-09-01 20:58:43,319 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2015-09-01 20:58:43,341 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2015-09-01 20:58:43,355 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2015-09-01 20:58:43,357 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2015-09-01 20:58:43,389 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-09-01 20:58:43,442 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-09-01 20:58:43,443 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2015-09-01 20:58:43,444 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-09-01 20:58:43,444 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-09-01 20:58:43,447 INFO org.apache.hadoop.http.HttpServer: adding path spec: /node/*
2015-09-01 20:58:43,447 INFO org.apache.hadoop.http.HttpServer: adding path spec: /ws/*
2015-09-01 20:58:43,449 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 8042
2015-09-01 20:58:43,449 INFO org.mortbay.log: jetty-6.1.26
2015-09-01 20:58:43,476 INFO org.mortbay.log: Extract jar:file:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2015-09-01 20:58:43,838 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:8042
2015-09-01 20:58:43,838 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app /node started at 8042
2015-09-01 20:58:44,151 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2015-09-01 20:58:44,184 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8031
2015-09-01 20:58:44,376 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 407331200
2015-09-01 20:58:44,379 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for nm-tokens, got key with id :1187739532
2015-09-01 20:58:44,379 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as ubuntu01:49377 with total resource of <memory:8192, vCores:8>
2015-09-01 20:58:44,380 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2015-09-01 22:30:26,114 ERROR org.apache.hadoop.yarn.server.nodemanager.NodeManager: RECEIVED SIGNAL 15: SIGTERM
2015-09-01 22:30:26,120 INFO org.mortbay.log: Stopped SelectChannelConnector@0.0.0.0:8042
2015-09-01 22:30:26,220 INFO org.apache.hadoop.ipc.Server: Stopping server on 49377
2015-09-01 22:30:26,221 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 49377
2015-09-01 22:30:26,221 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.
2015-09-01 22:30:26,221 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2015-09-01 22:30:26,230 INFO org.apache.hadoop.ipc.Server: Stopping server on 8040
2015-09-01 22:30:26,231 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8040
2015-09-01 22:30:26,231 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2015-09-01 22:30:26,231 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Public cache exiting
2015-09-01 22:30:26,232 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NodeManager metrics system...
2015-09-01 22:30:26,232 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system stopped.
2015-09-01 22:30:26,232 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system shutdown complete.
2015-09-01 22:30:26,232 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at ubuntu01/127.0.1.1
************************************************************/
2015-09-01 22:33:11,711 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-09-01 22:33:11,722 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2015-09-01 22:33:12,413 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-01 22:33:12,687 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2015-09-01 22:33:12,688 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2015-09-01 22:33:12,689 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2015-09-01 22:33:12,689 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2015-09-01 22:33:12,690 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2015-09-01 22:33:12,690 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2015-09-01 22:33:12,711 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2015-09-01 22:33:12,712 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2015-09-01 22:33:12,763 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-09-01 22:33:12,829 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-09-01 22:33:12,829 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2015-09-01 22:33:12,846 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2015-09-01 22:33:12,847 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2015-09-01 22:33:12,861 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1437982264755
2015-09-01 22:33:12,862 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1436941685461
2015-09-01 22:33:12,864 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1441117992848
2015-09-01 22:33:12,864 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1436929195743
2015-09-01 22:33:12,864 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1440492178206
2015-09-01 22:33:12,877 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2015-09-01 22:33:12,894 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2015-09-01 22:33:12,894 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2015-09-01 22:33:12,948 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@a7bfbc
2015-09-01 22:33:12,948 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2015-09-01 22:33:12,948 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2015-09-01 22:33:12,948 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2015-09-01 22:33:12,952 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.9 G). Thrashing might happen.
2015-09-01 22:33:12,956 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2015-09-01 22:33:13,004 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 51218
2015-09-01 22:33:13,020 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2015-09-01 22:33:13,021 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2015-09-01 22:33:13,021 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-09-01 22:33:13,021 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 51218: starting
2015-09-01 22:33:13,031 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : ubuntu01:51218
2015-09-01 22:33:13,031 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at ubuntu01/127.0.1.1:51218
2015-09-01 22:33:13,037 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2015-09-01 22:33:13,039 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2015-09-01 22:33:13,039 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-09-01 22:33:13,039 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2015-09-01 22:33:13,040 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2015-09-01 22:33:13,051 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2015-09-01 22:33:13,064 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2015-09-01 22:33:13,068 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2015-09-01 22:33:13,106 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-09-01 22:33:13,168 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-09-01 22:33:13,169 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2015-09-01 22:33:13,169 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-09-01 22:33:13,169 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-09-01 22:33:13,172 INFO org.apache.hadoop.http.HttpServer: adding path spec: /node/*
2015-09-01 22:33:13,172 INFO org.apache.hadoop.http.HttpServer: adding path spec: /ws/*
2015-09-01 22:33:13,174 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 8042
2015-09-01 22:33:13,174 INFO org.mortbay.log: jetty-6.1.26
2015-09-01 22:33:13,203 INFO org.mortbay.log: Extract jar:file:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2015-09-01 22:33:13,618 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:8042
2015-09-01 22:33:13,619 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app /node started at 8042
2015-09-01 22:33:13,940 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2015-09-01 22:33:13,976 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8031
2015-09-01 22:33:14,163 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id -989100065
2015-09-01 22:33:14,166 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for nm-tokens, got key with id :2118115667
2015-09-01 22:33:14,167 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as ubuntu01:51218 with total resource of <memory:8192, vCores:8>
2015-09-01 22:33:14,167 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2015-09-01 22:41:21,511 ERROR org.apache.hadoop.yarn.server.nodemanager.NodeManager: RECEIVED SIGNAL 15: SIGTERM
2015-09-01 22:41:21,619 INFO org.mortbay.log: Stopped SelectChannelConnector@0.0.0.0:8042
2015-09-01 22:41:21,719 INFO org.apache.hadoop.ipc.Server: Stopping server on 51218
2015-09-01 22:41:21,720 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 51218
2015-09-01 22:41:21,720 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2015-09-01 22:41:21,721 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.
2015-09-01 22:41:21,728 INFO org.apache.hadoop.ipc.Server: Stopping server on 8040
2015-09-01 22:41:21,728 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2015-09-01 22:41:21,729 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8040
2015-09-01 22:41:21,729 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Public cache exiting
2015-09-01 22:41:21,729 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NodeManager metrics system...
2015-09-01 22:41:21,730 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system stopped.
2015-09-01 22:41:21,730 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system shutdown complete.
2015-09-01 22:41:21,730 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at ubuntu01/127.0.1.1
************************************************************/
2015-09-02 09:16:46,156 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-09-02 09:16:46,184 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2015-09-02 09:16:46,904 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-02 09:16:47,226 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2015-09-02 09:16:47,227 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2015-09-02 09:16:47,227 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2015-09-02 09:16:47,227 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2015-09-02 09:16:47,228 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2015-09-02 09:16:47,228 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2015-09-02 09:16:47,249 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2015-09-02 09:16:47,249 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2015-09-02 09:16:47,298 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-09-02 09:16:47,371 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-09-02 09:16:47,371 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2015-09-02 09:16:47,390 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2015-09-02 09:16:47,390 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2015-09-02 09:16:47,438 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1437982264755
2015-09-02 09:16:47,445 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1436941685461
2015-09-02 09:16:47,450 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1441117992848
2015-09-02 09:16:47,458 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1436929195743
2015-09-02 09:16:47,459 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1441156607392
2015-09-02 09:16:47,459 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/home/liyaohui/hadoop/tmp/nm-local-dir/usercache_DEL_1440492178206
2015-09-02 09:16:47,484 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2015-09-02 09:16:47,528 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2015-09-02 09:16:47,528 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2015-09-02 09:16:47,580 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@a7bfbc
2015-09-02 09:16:47,580 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2015-09-02 09:16:47,581 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2015-09-02 09:16:47,581 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2015-09-02 09:16:47,584 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.9 G). Thrashing might happen.
2015-09-02 09:16:47,589 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2015-09-02 09:16:47,643 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 59455
2015-09-02 09:16:47,661 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2015-09-02 09:16:47,661 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2015-09-02 09:16:47,661 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-09-02 09:16:47,662 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 59455: starting
2015-09-02 09:16:47,669 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : ubuntu01:59455
2015-09-02 09:16:47,669 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at ubuntu01/127.0.1.1:59455
2015-09-02 09:16:47,677 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2015-09-02 09:16:47,678 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2015-09-02 09:16:47,679 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-09-02 09:16:47,679 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2015-09-02 09:16:47,679 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2015-09-02 09:16:47,701 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2015-09-02 09:16:47,714 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2015-09-02 09:16:47,717 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2015-09-02 09:16:47,748 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-09-02 09:16:47,801 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-09-02 09:16:47,803 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2015-09-02 09:16:47,803 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-09-02 09:16:47,803 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-09-02 09:16:47,806 INFO org.apache.hadoop.http.HttpServer: adding path spec: /node/*
2015-09-02 09:16:47,806 INFO org.apache.hadoop.http.HttpServer: adding path spec: /ws/*
2015-09-02 09:16:47,808 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 8042
2015-09-02 09:16:47,808 INFO org.mortbay.log: jetty-6.1.26
2015-09-02 09:16:47,835 INFO org.mortbay.log: Extract jar:file:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2015-09-02 09:16:48,172 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:8042
2015-09-02 09:16:48,172 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app /node started at 8042
2015-09-02 09:16:48,482 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2015-09-02 09:16:48,515 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8031
2015-09-02 09:16:48,696 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id -633447117
2015-09-02 09:16:48,699 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for nm-tokens, got key with id :1532714875
2015-09-02 09:16:48,700 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as ubuntu01:59455 with total resource of <memory:8192, vCores:8>
2015-09-02 09:16:48,700 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2015-09-02 16:59:24,229 ERROR org.apache.hadoop.yarn.server.nodemanager.NodeManager: RECEIVED SIGNAL 15: SIGTERM
2015-09-02 16:59:24,351 INFO org.mortbay.log: Stopped SelectChannelConnector@0.0.0.0:8042
2015-09-02 16:59:24,452 INFO org.apache.hadoop.ipc.Server: Stopping server on 59455
2015-09-02 16:59:24,452 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 59455
2015-09-02 16:59:24,452 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2015-09-02 16:59:24,453 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.
2015-09-02 16:59:24,462 INFO org.apache.hadoop.ipc.Server: Stopping server on 8040
2015-09-02 16:59:24,462 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8040
2015-09-02 16:59:24,463 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2015-09-02 16:59:24,463 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Public cache exiting
2015-09-02 16:59:24,463 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NodeManager metrics system...
2015-09-02 16:59:24,464 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system stopped.
2015-09-02 16:59:24,464 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system shutdown complete.
2015-09-02 16:59:24,464 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at ubuntu01/127.0.1.1
************************************************************/
