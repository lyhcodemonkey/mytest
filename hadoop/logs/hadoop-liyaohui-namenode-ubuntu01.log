2015-07-05 06:30:51,774 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-07-05 06:30:51,780 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-07-05 06:30:51,982 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-07-05 06:30:52,067 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-07-05 06:30:52,067 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2015-07-05 06:30:52,181 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-07-05 06:30:52,322 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-07-05 06:30:52,372 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-07-05 06:30:52,374 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2015-07-05 06:30:52,374 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-07-05 06:30:52,374 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-07-05 06:30:52,403 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2015-07-05 06:30:52,415 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2015-07-05 06:30:52,415 INFO org.mortbay.log: jetty-6.1.26
2015-07-05 06:30:52,722 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2015-07-05 06:30:52,722 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2015-07-05 06:30:52,749 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2015-07-05 06:30:52,749 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2015-07-05 06:30:52,809 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2015-07-05 06:30:52,809 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2015-07-05 06:30:52,811 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-07-05 06:30:52,814 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-07-05 06:30:52,814 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-07-05 06:30:52,815 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2015-07-05 06:30:52,815 INFO org.apache.hadoop.util.GSet: capacity      = 2^22 = 4194304 entries
2015-07-05 06:30:52,826 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-07-05 06:30:52,827 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-07-05 06:30:52,827 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-07-05 06:30:52,827 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-07-05 06:30:52,827 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-07-05 06:30:52,827 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-07-05 06:30:52,827 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-07-05 06:30:52,827 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-07-05 06:30:52,833 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = liyaohui (auth:SIMPLE)
2015-07-05 06:30:52,833 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-07-05 06:30:52,833 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-07-05 06:30:52,833 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-07-05 06:30:52,835 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-07-05 06:30:53,079 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-07-05 06:30:53,080 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-07-05 06:30:53,080 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2015-07-05 06:30:53,080 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-07-05 06:30:53,083 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-07-05 06:30:53,087 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-07-05 06:30:53,087 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-07-05 06:30:53,087 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-07-05 06:30:53,088 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2015-07-05 06:30:53,088 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2015-07-05 06:30:53,090 INFO org.apache.hadoop.util.GSet: Computing capacity for map Namenode Retry Cache
2015-07-05 06:30:53,090 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-07-05 06:30:53,090 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory = 889 MB
2015-07-05 06:30:53,090 INFO org.apache.hadoop.util.GSet: capacity      = 2^16 = 65536 entries
2015-07-05 06:30:53,143 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/liyaohui/hadoop/tmp/dfs/name/in_use.lock acquired by nodename 11233@ubuntu01
2015-07-05 06:30:53,179 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/liyaohui/hadoop/tmp/dfs/name/current
2015-07-05 06:30:53,181 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2015-07-05 06:30:53,190 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000000000 using no compression
2015-07-05 06:30:53,190 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 1
2015-07-05 06:30:53,194 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2015-07-05 06:30:53,195 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000000000 of size 200 bytes loaded in 0 seconds.
2015-07-05 06:30:53,195 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000000000
2015-07-05 06:30:53,200 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2015-07-05 06:30:53,510 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-07-05 06:30:53,511 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 419 msecs
2015-07-05 06:30:54,005 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ubuntu01:9000
2015-07-05 06:30:54,025 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2015-07-05 06:30:54,045 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2015-07-05 06:30:54,053 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2015-07-05 06:30:54,053 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2015-07-05 06:30:54,053 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2015-07-05 06:30:54,069 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2015-07-05 06:30:54,070 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2015-07-05 06:30:54,070 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2015-07-05 06:30:54,070 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2015-07-05 06:30:54,070 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2015-07-05 06:30:54,070 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 16 msec
2015-07-05 06:30:54,070 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 1 secs
2015-07-05 06:30:54,070 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2015-07-05 06:30:54,070 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2015-07-05 06:30:54,091 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-07-05 06:30:54,091 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2015-07-05 06:30:54,094 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ubuntu01/127.0.1.1:9000
2015-07-05 06:30:54,094 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2015-07-05 06:30:58,123 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1, storageID=DS-1927886287-127.0.1.1-50010-1436049057919, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62;nsid=783537164;c=0) storage DS-1927886287-127.0.1.1-50010-1436049057919
2015-07-05 06:30:58,125 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2015-07-05 06:30:58,226 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 127.0.0.1:50010 after starting up or becoming active. Its block contents are no longer considered stale
2015-07-05 06:30:58,226 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(127.0.0.1, storageID=DS-1927886287-127.0.1.1-50010-1436049057919, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62;nsid=783537164;c=0), blocks: 0, processing time: 2 msecs
2015-07-05 06:31:23,284 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2015-07-05 06:31:23,286 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ubuntu01/127.0.1.1
************************************************************/
2015-07-15 10:59:38,137 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-07-15 10:59:38,157 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-07-15 10:59:38,457 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-07-15 10:59:38,536 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-07-15 10:59:38,536 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2015-07-15 10:59:38,637 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-07-15 10:59:38,823 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-07-15 10:59:38,875 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-07-15 10:59:38,877 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2015-07-15 10:59:38,877 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-07-15 10:59:38,877 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-07-15 10:59:38,913 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2015-07-15 10:59:38,926 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2015-07-15 10:59:38,926 INFO org.mortbay.log: jetty-6.1.26
2015-07-15 10:59:39,269 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2015-07-15 10:59:39,269 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2015-07-15 10:59:39,338 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2015-07-15 10:59:39,338 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2015-07-15 10:59:39,425 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2015-07-15 10:59:39,425 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2015-07-15 10:59:39,427 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-07-15 10:59:39,430 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-07-15 10:59:39,430 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-07-15 10:59:39,431 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2015-07-15 10:59:39,431 INFO org.apache.hadoop.util.GSet: capacity      = 2^22 = 4194304 entries
2015-07-15 10:59:39,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-07-15 10:59:39,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-07-15 10:59:39,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-07-15 10:59:39,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-07-15 10:59:39,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-07-15 10:59:39,444 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-07-15 10:59:39,444 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-07-15 10:59:39,444 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-07-15 10:59:39,450 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = liyaohui (auth:SIMPLE)
2015-07-15 10:59:39,450 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-07-15 10:59:39,450 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-07-15 10:59:39,450 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-07-15 10:59:39,452 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-07-15 10:59:39,734 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-07-15 10:59:39,734 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-07-15 10:59:39,734 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2015-07-15 10:59:39,734 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-07-15 10:59:39,737 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-07-15 10:59:39,741 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-07-15 10:59:39,741 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-07-15 10:59:39,741 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-07-15 10:59:39,742 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2015-07-15 10:59:39,742 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2015-07-15 10:59:39,754 INFO org.apache.hadoop.util.GSet: Computing capacity for map Namenode Retry Cache
2015-07-15 10:59:39,754 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-07-15 10:59:39,754 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory = 889 MB
2015-07-15 10:59:39,754 INFO org.apache.hadoop.util.GSet: capacity      = 2^16 = 65536 entries
2015-07-15 10:59:39,798 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/liyaohui/hadoop/tmp/dfs/name/in_use.lock acquired by nodename 3549@ubuntu01
2015-07-15 10:59:39,863 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/liyaohui/hadoop/tmp/dfs/name/current
2015-07-15 10:59:39,917 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000000001 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000000001-0000000000000000001
2015-07-15 10:59:39,957 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000000000 using no compression
2015-07-15 10:59:39,957 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 1
2015-07-15 10:59:39,961 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2015-07-15 10:59:39,961 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000000000 of size 200 bytes loaded in 0 seconds.
2015-07-15 10:59:39,962 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000000000
2015-07-15 10:59:39,962 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@669da8 expecting start txid #1
2015-07-15 10:59:39,962 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000000001-0000000000000000001
2015-07-15 10:59:39,964 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000000001-0000000000000000001' to transaction ID 1
2015-07-15 10:59:39,971 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000000001-0000000000000000001 of size 1048576 edits # 1 loaded in 0 seconds
2015-07-15 10:59:39,978 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage.ckpt_0000000000000000001 using no compression
2015-07-15 10:59:40,022 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage.ckpt_0000000000000000001 of size 200 bytes saved in 0 seconds.
2015-07-15 10:59:40,078 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 0
2015-07-15 10:59:40,095 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 2
2015-07-15 10:59:40,390 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-07-15 10:59:40,390 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 635 msecs
2015-07-15 10:59:40,916 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ubuntu01:9000
2015-07-15 10:59:40,948 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2015-07-15 10:59:40,969 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2015-07-15 10:59:40,998 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2015-07-15 10:59:40,999 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2015-07-15 10:59:40,999 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2015-07-15 10:59:41,015 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2015-07-15 10:59:41,015 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2015-07-15 10:59:41,015 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2015-07-15 10:59:41,015 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2015-07-15 10:59:41,015 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2015-07-15 10:59:41,015 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 16 msec
2015-07-15 10:59:41,015 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 1 secs
2015-07-15 10:59:41,016 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2015-07-15 10:59:41,016 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2015-07-15 10:59:41,037 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-07-15 10:59:41,037 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2015-07-15 10:59:41,039 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ubuntu01/127.0.1.1:9000
2015-07-15 10:59:41,039 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2015-07-15 10:59:44,408 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1, storageID=DS-1927886287-127.0.1.1-50010-1436049057919, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62;nsid=783537164;c=0) storage DS-1927886287-127.0.1.1-50010-1436049057919
2015-07-15 10:59:44,411 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2015-07-15 10:59:44,511 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 127.0.0.1:50010 after starting up or becoming active. Its block contents are no longer considered stale
2015-07-15 10:59:44,512 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(127.0.0.1, storageID=DS-1927886287-127.0.1.1-50010-1436049057919, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62;nsid=783537164;c=0), blocks: 0, processing time: 1 msecs
2015-07-15 11:00:37,939 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 11:00:38,345 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:00:38,347 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:00:38,375 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:00:38,376 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:00:48,910 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-07-15 11:00:48,910 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-07-15 11:00:48,910 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 2
2015-07-15 11:00:48,910 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 59 
2015-07-15 11:00:48,915 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 64 
2015-07-15 11:00:48,917 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000000002 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000000002-0000000000000000003
2015-07-15 11:00:48,917 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4
2015-07-15 11:00:49,434 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=3&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 11:00:49,576 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.14s at 0.00 KB/s
2015-07-15 11:00:49,576 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000003 size 200 bytes.
2015-07-15 11:00:49,597 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1
2015-07-15 11:00:49,597 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2015-07-15 11:01:58,178 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 66 
2015-07-15 11:01:58,302 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/COPYRIGHT._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:01:58,562 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:01:58,580 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/COPYRIGHT._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:01:58,633 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/LICENSE._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:01:58,638 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:01:58,651 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/LICENSE._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:01:58,674 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/README.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:01:58,682 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:01:58,692 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/README.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:01:58,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/THIRDPARTYLICENSEREADME-JAVAFX.txt._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:01:58,732 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:01:58,742 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/THIRDPARTYLICENSEREADME-JAVAFX.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:01:58,775 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/THIRDPARTYLICENSEREADME.txt._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:01:58,783 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:01:58,793 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/THIRDPARTYLICENSEREADME.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:01:58,841 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/ControlPanel._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:01:58,847 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:01:58,865 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/ControlPanel._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:01:58,891 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/appletviewer._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741831_1007{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:01:58,901 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073741831_1007{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:01:58,901 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/appletviewer._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:01:58,901 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741831_1007{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 5969
2015-07-15 11:01:59,312 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/appletviewer._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:01:59,335 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/extcheck._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741832_1008{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:01:59,355 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073741832_1008{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:01:59,355 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/extcheck._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:01:59,356 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741832_1008{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 5889
2015-07-15 11:01:59,760 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/extcheck._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:01:59,782 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/idlj._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741833_1009{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:01:59,787 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741833_1009{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:01:59,800 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/idlj._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:01:59,823 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741834_1010{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:01:59,829 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741834_1010{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:01:59,841 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:01:59,864 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/jarsigner._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741835_1011{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:01:59,871 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741835_1011{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:01:59,882 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/jarsigner._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:01:59,905 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/java._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741836_1012{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:01:59,911 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741836_1012{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:01:59,922 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:01:59,955 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/java-rmi.cgi._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741837_1013{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:01:59,960 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741837_1013{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:01:59,973 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/java-rmi.cgi._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:00,004 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/javac._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741838_1014{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:00,012 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741838_1014{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:00,024 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/javac._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:00,059 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/javadoc._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741839_1015{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:00,067 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741839_1015{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:00,075 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/javadoc._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:00,100 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/javafxpackager._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741840_1016{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:00,107 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741840_1016{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:00,116 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/javafxpackager._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:00,147 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/javah._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741841_1017{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:00,152 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741841_1017{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:00,167 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/javah._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:00,189 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/javap._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741842_1018{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:00,195 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741842_1018{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:00,207 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/javap._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:00,230 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/javapackager._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741843_1019{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:00,234 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741843_1019{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:00,238 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/javapackager._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:00,262 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/javaws._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741844_1020{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:00,270 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741844_1020{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:00,279 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/javaws._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:00,302 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/jcmd._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741845_1021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:00,306 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741845_1021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:00,319 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/jcmd._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:00,342 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/jconsole._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741846_1022{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:00,347 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741846_1022{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:00,360 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/jconsole._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:00,382 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/jcontrol._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741847_1023{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:00,387 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741847_1023{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:00,390 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/jcontrol._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:00,413 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/jdb._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741848_1024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:00,416 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741848_1024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:00,421 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/jdb._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:00,443 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/jdeps._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741849_1025{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:00,447 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741849_1025{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:00,452 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/jdeps._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:00,476 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/jhat._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741850_1026{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:00,480 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741850_1026{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:00,492 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/jhat._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:00,515 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/jinfo._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741851_1027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:00,519 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741851_1027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:00,523 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/jinfo._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:00,545 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/jjs._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741852_1028{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:00,549 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741852_1028{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:00,553 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/jjs._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:00,576 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/jmap._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741853_1029{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:00,579 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741853_1029{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:00,584 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/jmap._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:00,616 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/jmc._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741854_1030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:00,622 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741854_1030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:00,635 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/jmc._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:00,657 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/jmc.ini._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741855_1031{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:00,663 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741855_1031{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:00,675 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/jmc.ini._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:00,697 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/jps._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741856_1032{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:00,702 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741856_1032{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:00,706 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/jps._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:00,728 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/jrunscript._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741857_1033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:00,731 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741857_1033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:00,736 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/jrunscript._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:00,759 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/jsadebugd._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741858_1034{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:00,763 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741858_1034{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:00,767 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/jsadebugd._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:00,790 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/jstack._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741859_1035{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:00,794 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741859_1035{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:00,808 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/jstack._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:00,830 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/jstat._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741860_1036{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:00,834 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741860_1036{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:00,838 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/jstat._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:00,860 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/jstatd._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741861_1037{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:00,864 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741861_1037{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:00,869 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/jstatd._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:00,891 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/jvisualvm._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741862_1038{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:00,896 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741862_1038{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:00,899 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/jvisualvm._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:00,921 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/keytool._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741863_1039{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:00,926 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741863_1039{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:00,930 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/keytool._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:00,952 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/native2ascii._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741864_1040{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:00,958 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741864_1040{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:00,970 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/native2ascii._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:00,992 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/orbd._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741865_1041{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:01,005 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741865_1041{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:01,011 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/orbd._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:01,034 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/pack200._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741866_1042{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:01,040 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741866_1042{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:01,052 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/pack200._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:01,092 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/policytool._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741867_1043{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:01,100 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741867_1043{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:01,123 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/policytool._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:01,145 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/rmic._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741868_1044{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:01,149 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741868_1044{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:01,154 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/rmic._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:01,176 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/rmid._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741869_1045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:01,179 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741869_1045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:01,194 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/rmid._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:01,217 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/rmiregistry._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741870_1046{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:01,225 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741870_1046{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:01,235 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/rmiregistry._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:01,271 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/schemagen._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741871_1047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:01,277 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741871_1047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:01,286 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/schemagen._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:01,309 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/serialver._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741872_1048{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:01,315 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741872_1048{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:01,326 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/serialver._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:01,349 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/servertool._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741873_1049{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:01,355 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741873_1049{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:01,367 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/servertool._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:01,398 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/tnameserv._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741874_1050{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:01,408 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741874_1050{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:01,418 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/tnameserv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:01,442 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/unpack200._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741875_1051{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:01,449 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741875_1051{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:01,459 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/unpack200._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:01,481 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/wsgen._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741876_1052{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:01,485 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741876_1052{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:01,489 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/wsgen._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:01,511 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/wsimport._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741877_1053{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:01,516 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741877_1053{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:01,530 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/wsimport._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:01,552 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/bin/xjc._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741878_1054{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:01,557 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741878_1054{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:01,560 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/bin/xjc._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:01,602 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/3RDPARTY._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741879_1055{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:01,605 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741879_1055{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:01,621 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/3RDPARTY._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:01,657 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/LICENSE._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741880_1056{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:01,661 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741880_1056{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:01,672 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/LICENSE._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:01,695 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/NOTICE._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741881_1057{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:01,703 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073741881_1057{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:01,704 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/NOTICE._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:01,704 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741881_1057{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 13272
2015-07-15 11:02:02,124 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/NOTICE._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:02,160 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/README-JDK.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741882_1058{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:02,166 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073741882_1058{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:02,166 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/README-JDK.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:02,166 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741882_1058{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 908
2015-07-15 11:02:02,578 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/README-JDK.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:02,606 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/RELEASE-NOTES.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741883_1059{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:02,611 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741883_1059{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:02,618 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/RELEASE-NOTES.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:02,671 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/bin/NetworkServerControl._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741884_1060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:02,678 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741884_1060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:02,690 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/bin/NetworkServerControl._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:02,719 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/bin/NetworkServerControl.bat._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741885_1061{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:02,723 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741885_1061{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:02,740 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/bin/NetworkServerControl.bat._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:02,771 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/bin/dblook._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741886_1062{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:02,777 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741886_1062{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:02,791 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/bin/dblook._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:02,817 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/bin/dblook.bat._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741887_1063{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:02,822 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741887_1063{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:02,832 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/bin/dblook.bat._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:02,854 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/bin/derby_common.bat._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741888_1064{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:02,858 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741888_1064{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:02,873 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/bin/derby_common.bat._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:02,895 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/bin/ij._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741889_1065{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:02,902 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741889_1065{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:02,913 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/bin/ij._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:02,944 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/bin/ij.bat._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741890_1066{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:02,948 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741890_1066{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:02,964 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/bin/ij.bat._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:02,986 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/bin/setEmbeddedCP._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741891_1067{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:02,990 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741891_1067{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:02,995 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/bin/setEmbeddedCP._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:03,026 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/bin/setEmbeddedCP.bat._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741892_1068{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:03,030 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741892_1068{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:03,046 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/bin/setEmbeddedCP.bat._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:03,068 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/bin/setNetworkClientCP._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741893_1069{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:03,071 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741893_1069{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:03,076 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/bin/setNetworkClientCP._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:03,099 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/bin/setNetworkClientCP.bat._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741894_1070{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:03,104 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741894_1070{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:03,117 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/bin/setNetworkClientCP.bat._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:03,140 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/bin/setNetworkServerCP._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741895_1071{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:03,144 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741895_1071{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:03,147 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/bin/setNetworkServerCP._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:03,177 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/bin/setNetworkServerCP.bat._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741896_1072{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:03,182 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741896_1072{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:03,198 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/bin/setNetworkServerCP.bat._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:03,220 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/bin/startNetworkServer._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741897_1073{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:03,224 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741897_1073{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:03,229 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/bin/startNetworkServer._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:03,252 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/bin/startNetworkServer.bat._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741898_1074{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:03,257 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073741898_1074{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:03,257 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/bin/startNetworkServer.bat._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:03,258 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741898_1074{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 1397
2015-07-15 11:02:03,666 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/bin/startNetworkServer.bat._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:03,693 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/bin/stopNetworkServer._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741899_1075{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:03,697 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741899_1075{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:03,707 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/bin/stopNetworkServer._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:03,729 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/bin/stopNetworkServer.bat._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741900_1076{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:03,733 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741900_1076{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:03,737 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/bin/stopNetworkServer.bat._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:03,759 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/bin/sysinfo._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741901_1077{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:03,765 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741901_1077{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:03,778 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/bin/sysinfo._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:03,808 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/bin/sysinfo.bat._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741902_1078{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:03,812 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741902_1078{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:03,829 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/bin/sysinfo.bat._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:03,891 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/lib/derby.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741903_1079{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:03,942 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741903_1079{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:03,961 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/lib/derby.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:03,989 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/lib/derby.war._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741904_1080{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:03,992 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741904_1080{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:04,002 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/lib/derby.war._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:04,025 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/lib/derbyLocale_cs.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741905_1081{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:04,030 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741905_1081{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:04,043 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/lib/derbyLocale_cs.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:04,066 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/lib/derbyLocale_de_DE.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741906_1082{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:04,078 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741906_1082{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:04,083 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/lib/derbyLocale_de_DE.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:04,112 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/lib/derbyLocale_es.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741907_1083{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:04,116 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741907_1083{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:04,124 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/lib/derbyLocale_es.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:04,147 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/lib/derbyLocale_fr.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741908_1084{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:04,153 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741908_1084{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:04,165 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/lib/derbyLocale_fr.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:04,196 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/lib/derbyLocale_hu.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741909_1085{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:04,203 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741909_1085{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:04,216 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/lib/derbyLocale_hu.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:04,246 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/lib/derbyLocale_it.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741910_1086{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:04,253 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741910_1086{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:04,266 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/lib/derbyLocale_it.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:04,290 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/lib/derbyLocale_ja_JP.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741911_1087{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:04,293 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741911_1087{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:04,297 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/lib/derbyLocale_ja_JP.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:04,320 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/lib/derbyLocale_ko_KR.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741912_1088{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:04,326 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741912_1088{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:04,338 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/lib/derbyLocale_ko_KR.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:04,361 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/lib/derbyLocale_pl.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741913_1089{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:04,364 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741913_1089{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:04,378 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/lib/derbyLocale_pl.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:04,402 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/lib/derbyLocale_pt_BR.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741914_1090{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:04,406 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741914_1090{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:04,409 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/lib/derbyLocale_pt_BR.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:04,432 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/lib/derbyLocale_ru.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741915_1091{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:04,436 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741915_1091{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:04,439 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/lib/derbyLocale_ru.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:04,469 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/lib/derbyLocale_zh_CN.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741916_1092{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:04,473 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741916_1092{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:04,490 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/lib/derbyLocale_zh_CN.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:04,513 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/lib/derbyLocale_zh_TW.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741917_1093{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:04,518 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741917_1093{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:04,531 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/lib/derbyLocale_zh_TW.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:04,563 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/lib/derbyclient.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741918_1094{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:04,571 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741918_1094{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:04,592 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/lib/derbyclient.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:04,629 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/lib/derbynet.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741919_1095{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:04,635 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741919_1095{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:04,653 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/lib/derbynet.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:04,680 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/lib/derbyoptionaltools.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741920_1096{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:04,683 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741920_1096{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:04,694 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/lib/derbyoptionaltools.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:04,716 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/lib/derbyrun.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741921_1097{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:04,719 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741921_1097{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:04,724 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/lib/derbyrun.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:04,755 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/db/lib/derbytools.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741922_1098{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:04,759 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741922_1098{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:04,775 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/db/lib/derbytools.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:04,818 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/include/classfile_constants.h._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741923_1099{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:04,821 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741923_1099{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:04,846 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/include/classfile_constants.h._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:04,868 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/include/jawt.h._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741924_1100{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:04,872 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741924_1100{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:04,877 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/include/jawt.h._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:04,899 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/include/jdwpTransport.h._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741925_1101{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:04,902 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741925_1101{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:04,907 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/include/jdwpTransport.h._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:04,930 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/include/jni.h._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741926_1102{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:04,934 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741926_1102{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:04,948 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/include/jni.h._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:04,977 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/include/jvmti.h._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741927_1103{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:04,981 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741927_1103{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:04,999 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/include/jvmti.h._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:05,021 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/include/jvmticmlr.h._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741928_1104{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:05,027 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073741928_1104{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:05,027 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/include/jvmticmlr.h._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:05,027 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741928_1104{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 3774
2015-07-15 11:02:05,436 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/include/jvmticmlr.h._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:05,489 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/include/linux/jawt_md.h._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741929_1105{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:05,493 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741929_1105{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:05,508 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/include/linux/jawt_md.h._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:05,540 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/include/linux/jni_md.h._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741930_1106{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:05,543 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741930_1106{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:05,558 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/include/linux/jni_md.h._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:05,593 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/javafx-src.zip._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741931_1107{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:05,677 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741931_1107{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:05,691 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/javafx-src.zip._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:05,733 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/COPYRIGHT._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741932_1108{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:05,737 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741932_1108{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:05,752 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/COPYRIGHT._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:05,782 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/LICENSE._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741933_1109{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:05,788 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073741933_1109{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:05,788 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/LICENSE._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:05,788 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741933_1109{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 40
2015-07-15 11:02:06,199 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/LICENSE._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:06,221 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/README._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741934_1110{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:06,225 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741934_1110{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:06,240 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/README._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:06,263 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/THIRDPARTYLICENSEREADME-JAVAFX.txt._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741935_1111{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:06,268 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741935_1111{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:06,281 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/THIRDPARTYLICENSEREADME-JAVAFX.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:06,304 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/THIRDPARTYLICENSEREADME.txt._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741936_1112{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:06,309 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741936_1112{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:06,321 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/THIRDPARTYLICENSEREADME.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:06,343 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/Welcome.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741937_1113{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:06,348 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741937_1113{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:06,352 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/Welcome.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:06,396 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/bin/ControlPanel._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741938_1114{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:06,398 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741938_1114{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:06,413 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/bin/ControlPanel._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:06,434 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/bin/java._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741939_1115{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:06,438 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741939_1115{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:06,443 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/bin/java._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:06,479 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/bin/javaws._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741940_1116{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:06,483 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741940_1116{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:06,494 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/bin/javaws._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:06,516 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/bin/jcontrol._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741941_1117{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:06,520 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741941_1117{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:06,525 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/bin/jcontrol._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:06,559 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/bin/jjs._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741942_1118{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:06,562 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741942_1118{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:06,576 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/bin/jjs._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:06,604 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/bin/keytool._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741943_1119{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:06,607 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741943_1119{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:06,627 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/bin/keytool._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:06,657 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/bin/orbd._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741944_1120{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:06,663 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073741944_1120{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:06,664 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/bin/orbd._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:06,664 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741944_1120{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 6029
2015-07-15 11:02:07,074 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/bin/orbd._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:07,096 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/bin/pack200._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741945_1121{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:07,101 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741945_1121{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:07,105 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/bin/pack200._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:07,170 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/bin/policytool._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741946_1122{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:07,174 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741946_1122{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:07,186 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/bin/policytool._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:07,219 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/bin/rmid._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741947_1123{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:07,222 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741947_1123{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:07,237 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/bin/rmid._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:07,271 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/bin/rmiregistry._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741948_1124{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:07,276 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741948_1124{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:07,288 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/bin/rmiregistry._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:07,319 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/bin/servertool._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741949_1125{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:07,325 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741949_1125{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:07,339 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/bin/servertool._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:07,361 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/bin/tnameserv._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741950_1126{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:07,366 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741950_1126{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:07,369 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/bin/tnameserv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:07,399 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/bin/unpack200._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741951_1127{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:07,405 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741951_1127{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:07,420 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/bin/unpack200._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:07,488 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/calendars.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741952_1128{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:07,495 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741952_1128{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:07,512 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/calendars.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:07,534 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/charsets.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741953_1129{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:07,931 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741953_1129{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:08,206 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/charsets.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:08,244 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/classlist._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741954_1130{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:08,248 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741954_1130{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:08,264 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/classlist._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:08,313 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/cmm/CIEXYZ.pf._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741955_1131{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:08,316 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741955_1131{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:08,336 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/cmm/CIEXYZ.pf._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:08,369 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/cmm/GRAY.pf._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741956_1132{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:08,372 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741956_1132{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:08,386 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/cmm/GRAY.pf._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:08,414 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/cmm/LINEAR_RGB.pf._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741957_1133{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:08,417 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741957_1133{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:08,437 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/cmm/LINEAR_RGB.pf._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:08,460 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/cmm/PYCC.pf._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741958_1134{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:08,464 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741958_1134{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:08,468 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/cmm/PYCC.pf._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:08,495 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/cmm/sRGB.pf._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741959_1135{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:08,498 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073741959_1135{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:08,498 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/cmm/sRGB.pf._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:08,499 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741959_1135{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 3144
2015-07-15 11:02:08,905 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/cmm/sRGB.pf._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:08,933 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/content-types.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741960_1136{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:08,938 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741960_1136{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:08,956 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/content-types.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:08,978 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/currency.data._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741961_1137{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:08,983 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741961_1137{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:08,987 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/currency.data._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:09,028 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/deploy/MixedCodeMainDialog.ui._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741962_1138{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:09,031 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741962_1138{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:09,048 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/deploy/MixedCodeMainDialog.ui._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:09,074 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/deploy/MixedCodeMainDialogJs.ui._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741963_1139{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:09,077 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741963_1139{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:09,088 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/deploy/MixedCodeMainDialogJs.ui._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:09,123 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/deploy/cautionshield.icns._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741964_1140{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:09,126 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741964_1140{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:09,139 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/deploy/cautionshield.icns._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:09,168 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/deploy/ffjcext.zip._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741965_1141{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:09,171 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741965_1141{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:09,190 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/deploy/ffjcext.zip._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:09,212 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/deploy/java-icon.ico._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741966_1142{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:09,215 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741966_1142{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:09,221 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/deploy/java-icon.ico._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:09,242 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/deploy/messages.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741967_1143{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:09,247 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741967_1143{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:09,251 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/deploy/messages.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:09,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/deploy/messages_de.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741968_1144{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:09,277 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073741968_1144{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:09,277 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/deploy/messages_de.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:09,277 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741968_1144{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 3306
2015-07-15 11:02:09,689 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/deploy/messages_de.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:09,711 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/deploy/messages_es.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741969_1145{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:09,716 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073741969_1145{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:09,716 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/deploy/messages_es.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:09,717 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741969_1145{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 3600
2015-07-15 11:02:10,126 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/deploy/messages_es.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:10,148 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/deploy/messages_fr.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741970_1146{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:10,151 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741970_1146{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:10,157 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/deploy/messages_fr.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:10,188 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/deploy/messages_it.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741971_1147{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:10,192 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741971_1147{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:10,197 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/deploy/messages_it.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:10,228 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/deploy/messages_ja.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741972_1148{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:10,231 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741972_1148{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:10,248 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/deploy/messages_ja.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:10,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/deploy/messages_ko.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741973_1149{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:10,275 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741973_1149{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:10,279 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/deploy/messages_ko.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:10,300 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/deploy/messages_pt_BR.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741974_1150{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:10,304 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741974_1150{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:10,309 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/deploy/messages_pt_BR.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:10,331 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/deploy/messages_sv.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741975_1151{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:10,334 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741975_1151{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:10,340 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/deploy/messages_sv.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:10,361 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/deploy/messages_zh_CN.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741976_1152{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:10,364 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741976_1152{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:10,370 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/deploy/messages_zh_CN.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:10,404 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/deploy/messages_zh_HK.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741977_1153{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:10,407 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741977_1153{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:10,421 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/deploy/messages_zh_HK.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:10,443 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/deploy/messages_zh_TW.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741978_1154{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:10,446 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741978_1154{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:10,452 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/deploy/messages_zh_TW.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:10,486 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/deploy/mixcode_s.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741979_1155{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:10,489 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741979_1155{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:10,502 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/deploy/mixcode_s.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:10,524 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/deploy/splash.gif._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741980_1156{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:10,527 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741980_1156{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:10,533 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/deploy/splash.gif._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:10,555 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/deploy/splash@2x.gif._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741981_1157{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:10,558 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741981_1157{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:10,563 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/deploy/splash@2x.gif._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:10,594 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/deploy.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741982_1158{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:10,628 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073741982_1158{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:10,628 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/deploy.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:10,628 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741982_1158{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 2149107
2015-07-15 11:02:11,042 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/deploy.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:11,094 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/applications/sun-java.desktop._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741983_1159{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:11,099 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741983_1159{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:11,103 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/applications/sun-java.desktop._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:11,124 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/applications/sun-javaws.desktop._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741984_1160{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:11,128 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741984_1160{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:11,133 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/applications/sun-javaws.desktop._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:11,155 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/applications/sun_java.desktop._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741985_1161{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:11,157 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741985_1161{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:11,164 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/applications/sun_java.desktop._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:11,260 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/HighContrast/16x16/apps/sun-java.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741986_1162{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:11,263 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741986_1162{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:11,276 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/HighContrast/16x16/apps/sun-java.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:11,311 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/HighContrast/16x16/apps/sun-javaws.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741987_1163{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:11,314 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741987_1163{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:11,326 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/HighContrast/16x16/apps/sun-javaws.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:11,361 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/HighContrast/16x16/apps/sun-jcontrol.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741988_1164{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:11,364 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741988_1164{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:11,377 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/HighContrast/16x16/apps/sun-jcontrol.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:11,442 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/HighContrast/16x16/mimetypes/gnome-mime-application-x-java-archive.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741989_1165{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:11,445 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741989_1165{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:11,459 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/HighContrast/16x16/mimetypes/gnome-mime-application-x-java-archive.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:11,492 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/HighContrast/16x16/mimetypes/gnome-mime-application-x-java-jnlp-file.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741990_1166{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:11,498 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741990_1166{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:11,510 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/HighContrast/16x16/mimetypes/gnome-mime-application-x-java-jnlp-file.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:11,542 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/HighContrast/16x16/mimetypes/gnome-mime-text-x-java.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741991_1167{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:11,546 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741991_1167{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:11,560 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/HighContrast/16x16/mimetypes/gnome-mime-text-x-java.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:11,603 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/HighContrast/48x48/apps/sun-java.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741992_1168{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:11,605 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741992_1168{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:11,611 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/HighContrast/48x48/apps/sun-java.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:11,633 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/HighContrast/48x48/apps/sun-javaws.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741993_1169{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:11,635 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741993_1169{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:11,642 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/HighContrast/48x48/apps/sun-javaws.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:11,663 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/HighContrast/48x48/apps/sun-jcontrol.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741994_1170{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:11,666 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741994_1170{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:11,672 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/HighContrast/48x48/apps/sun-jcontrol.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:11,704 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/HighContrast/48x48/mimetypes/gnome-mime-application-x-java-archive.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741995_1171{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:11,709 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741995_1171{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:11,713 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/HighContrast/48x48/mimetypes/gnome-mime-application-x-java-archive.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:11,735 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/HighContrast/48x48/mimetypes/gnome-mime-application-x-java-jnlp-file.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741996_1172{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:11,738 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741996_1172{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:11,744 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/HighContrast/48x48/mimetypes/gnome-mime-application-x-java-jnlp-file.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:11,765 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/HighContrast/48x48/mimetypes/gnome-mime-text-x-java.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741997_1173{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:11,768 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741997_1173{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:11,774 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/HighContrast/48x48/mimetypes/gnome-mime-text-x-java.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:11,835 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/HighContrastInverse/16x16/apps/sun-java.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741998_1174{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:11,838 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741998_1174{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:11,855 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/HighContrastInverse/16x16/apps/sun-java.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:11,878 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/HighContrastInverse/16x16/apps/sun-javaws.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073741999_1175{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:11,880 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073741999_1175{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:11,886 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/HighContrastInverse/16x16/apps/sun-javaws.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:11,908 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/HighContrastInverse/16x16/apps/sun-jcontrol.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742000_1176{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:11,912 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742000_1176{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:11,917 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/HighContrastInverse/16x16/apps/sun-jcontrol.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:11,949 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/HighContrastInverse/16x16/mimetypes/gnome-mime-application-x-java-archive.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742001_1177{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:11,952 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742001_1177{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:11,957 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/HighContrastInverse/16x16/mimetypes/gnome-mime-application-x-java-archive.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:12,001 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/HighContrastInverse/16x16/mimetypes/gnome-mime-application-x-java-jnlp-file.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742002_1178{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:12,007 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742002_1178{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:12,018 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/HighContrastInverse/16x16/mimetypes/gnome-mime-application-x-java-jnlp-file.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:12,040 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/HighContrastInverse/16x16/mimetypes/gnome-mime-text-x-java.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742003_1179{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:12,047 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742003_1179{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:12,059 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/HighContrastInverse/16x16/mimetypes/gnome-mime-text-x-java.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:12,101 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/HighContrastInverse/48x48/apps/sun-java.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742004_1180{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:12,104 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742004_1180{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:12,141 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/HighContrastInverse/48x48/apps/sun-java.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:12,162 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/HighContrastInverse/48x48/apps/sun-javaws.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742005_1181{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:12,165 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742005_1181{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:12,171 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/HighContrastInverse/48x48/apps/sun-javaws.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:12,203 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/HighContrastInverse/48x48/apps/sun-jcontrol.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742006_1182{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:12,206 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742006_1182{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:12,232 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/HighContrastInverse/48x48/apps/sun-jcontrol.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:12,264 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/HighContrastInverse/48x48/mimetypes/gnome-mime-application-x-java-archive.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742007_1183{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:12,267 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742007_1183{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:12,273 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/HighContrastInverse/48x48/mimetypes/gnome-mime-application-x-java-archive.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:12,294 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/HighContrastInverse/48x48/mimetypes/gnome-mime-application-x-java-jnlp-file.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742008_1184{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:12,298 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742008_1184{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:12,303 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/HighContrastInverse/48x48/mimetypes/gnome-mime-application-x-java-jnlp-file.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:12,325 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/HighContrastInverse/48x48/mimetypes/gnome-mime-text-x-java.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742009_1185{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:12,328 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742009_1185{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:12,334 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/HighContrastInverse/48x48/mimetypes/gnome-mime-text-x-java.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:12,417 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/LowContrast/16x16/apps/sun-java.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742010_1186{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:12,424 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742010_1186{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:12,435 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/LowContrast/16x16/apps/sun-java.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:12,461 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/LowContrast/16x16/apps/sun-javaws.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742011_1187{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:12,469 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742011_1187{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:12,469 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/LowContrast/16x16/apps/sun-javaws.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:12,469 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742011_1187{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 519
2015-07-15 11:02:12,873 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/LowContrast/16x16/apps/sun-javaws.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:12,908 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/LowContrast/16x16/apps/sun-jcontrol.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742012_1188{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:12,911 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742012_1188{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:12,924 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/LowContrast/16x16/apps/sun-jcontrol.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:12,990 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/LowContrast/16x16/mimetypes/gnome-mime-application-x-java-archive.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742013_1189{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:12,994 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742013_1189{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:13,005 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/LowContrast/16x16/mimetypes/gnome-mime-application-x-java-archive.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:13,040 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/LowContrast/16x16/mimetypes/gnome-mime-application-x-java-jnlp-file.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742014_1190{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:13,056 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742014_1190{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:13,056 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742014_1190{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 525
2015-07-15 11:02:13,056 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/LowContrast/16x16/mimetypes/gnome-mime-application-x-java-jnlp-file.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:13,463 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/LowContrast/16x16/mimetypes/gnome-mime-application-x-java-jnlp-file.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:13,498 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/LowContrast/16x16/mimetypes/gnome-mime-text-x-java.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742015_1191{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:13,512 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742015_1191{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:13,524 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/LowContrast/16x16/mimetypes/gnome-mime-text-x-java.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:13,592 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/LowContrast/48x48/apps/sun-java.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742016_1192{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:13,601 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742016_1192{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:13,616 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/LowContrast/48x48/apps/sun-java.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:13,643 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/LowContrast/48x48/apps/sun-javaws.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742017_1193{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:13,647 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742017_1193{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:13,666 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/LowContrast/48x48/apps/sun-javaws.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:13,692 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/LowContrast/48x48/apps/sun-jcontrol.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742018_1194{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:13,696 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742018_1194{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:13,707 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/LowContrast/48x48/apps/sun-jcontrol.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:13,763 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/LowContrast/48x48/mimetypes/gnome-mime-application-x-java-archive.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742019_1195{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:13,766 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742019_1195{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:13,778 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/LowContrast/48x48/mimetypes/gnome-mime-application-x-java-archive.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:13,809 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/LowContrast/48x48/mimetypes/gnome-mime-application-x-java-jnlp-file.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742020_1196{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:13,812 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742020_1196{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:13,829 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/LowContrast/48x48/mimetypes/gnome-mime-application-x-java-jnlp-file.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:13,851 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/LowContrast/48x48/mimetypes/gnome-mime-text-x-java.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742021_1197{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:13,854 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742021_1197{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:13,860 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/LowContrast/48x48/mimetypes/gnome-mime-text-x-java.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:13,925 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/hicolor/16x16/apps/sun-java.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742022_1198{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:13,928 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742022_1198{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:13,941 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/hicolor/16x16/apps/sun-java.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:13,976 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/hicolor/16x16/apps/sun-javaws.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742023_1199{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:13,979 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742023_1199{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:13,992 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/hicolor/16x16/apps/sun-javaws.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:14,027 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/hicolor/16x16/apps/sun-jcontrol.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742024_1200{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:14,029 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742024_1200{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:14,043 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/hicolor/16x16/apps/sun-jcontrol.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:14,085 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/hicolor/16x16/mimetypes/gnome-mime-application-x-java-archive.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742025_1201{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:14,088 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742025_1201{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:14,104 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/hicolor/16x16/mimetypes/gnome-mime-application-x-java-archive.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:14,126 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/hicolor/16x16/mimetypes/gnome-mime-application-x-java-jnlp-file.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742026_1202{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:14,129 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742026_1202{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:14,134 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/hicolor/16x16/mimetypes/gnome-mime-application-x-java-jnlp-file.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:14,156 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/hicolor/16x16/mimetypes/gnome-mime-text-x-java.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742027_1203{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:14,160 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742027_1203{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:14,165 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/hicolor/16x16/mimetypes/gnome-mime-text-x-java.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:14,215 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/hicolor/48x48/apps/sun-java.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742028_1204{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:14,218 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742028_1204{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:14,236 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/hicolor/48x48/apps/sun-java.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:14,258 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/hicolor/48x48/apps/sun-javaws.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742029_1205{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:14,264 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742029_1205{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:14,277 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/hicolor/48x48/apps/sun-javaws.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:14,303 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/hicolor/48x48/apps/sun-jcontrol.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742030_1206{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:14,309 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742030_1206{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:14,318 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/hicolor/48x48/apps/sun-jcontrol.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:14,354 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/hicolor/48x48/mimetypes/gnome-mime-application-x-java-archive.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742031_1207{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:14,357 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742031_1207{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:14,368 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/hicolor/48x48/mimetypes/gnome-mime-application-x-java-archive.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:14,390 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/hicolor/48x48/mimetypes/gnome-mime-application-x-java-jnlp-file.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742032_1208{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:14,397 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742032_1208{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:14,409 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/hicolor/48x48/mimetypes/gnome-mime-application-x-java-jnlp-file.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:14,432 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/icons/hicolor/48x48/mimetypes/gnome-mime-text-x-java.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742033_1209{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:14,435 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742033_1209{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:14,440 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/icons/hicolor/48x48/mimetypes/gnome-mime-text-x-java.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:14,514 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/mime/packages/x-java-archive.xml._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742034_1210{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:14,517 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742034_1210{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:14,531 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/mime/packages/x-java-archive.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:14,553 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/desktop/mime/packages/x-java-jnlp-file.xml._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742035_1211{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:14,556 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742035_1211{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:14,562 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/desktop/mime/packages/x-java-jnlp-file.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:14,593 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/ext/cldrdata.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742036_1212{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:14,626 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742036_1212{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:14,633 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/ext/cldrdata.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:14,655 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/ext/dnsns.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742037_1213{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:14,660 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742037_1213{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:14,660 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/ext/dnsns.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:14,660 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742037_1213{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 8286
2015-07-15 11:02:15,070 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/ext/dnsns.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:15,092 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/ext/jfxrt.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742038_1214{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:15,209 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742038_1214{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:15,444 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/ext/jfxrt.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:15,683 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/ext/localedata.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742039_1215{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:15,694 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742039_1215{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:15,701 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/ext/localedata.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:15,723 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/ext/meta-index._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742040_1216{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:15,727 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742040_1216{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:15,732 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/ext/meta-index._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:15,753 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/ext/nashorn.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742041_1217{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:15,765 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742041_1217{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:15,772 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/ext/nashorn.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:15,794 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/ext/sunec.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742042_1218{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:15,798 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742042_1218{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:15,803 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/ext/sunec.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:15,824 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/ext/sunjce_provider.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742043_1219{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:15,829 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742043_1219{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:15,833 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/ext/sunjce_provider.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:15,855 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/ext/sunpkcs11.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742044_1220{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:15,859 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742044_1220{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:15,864 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/ext/sunpkcs11.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:15,885 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/ext/zipfs.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742045_1221{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:15,890 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742045_1221{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:15,894 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/ext/zipfs.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:15,920 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/flavormap.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742046_1222{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:15,923 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742046_1222{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:15,935 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/flavormap.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:15,957 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/fontconfig.RedHat.5.bfc._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742047_1223{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:15,960 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742047_1223{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:15,966 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/fontconfig.RedHat.5.bfc._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:16,000 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/fontconfig.RedHat.5.properties.src._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742048_1224{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:16,002 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742048_1224{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:16,016 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/fontconfig.RedHat.5.properties.src._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:16,042 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/fontconfig.RedHat.6.bfc._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742049_1225{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:16,045 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742049_1225{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:16,073 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/fontconfig.RedHat.6.bfc._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:16,101 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/fontconfig.RedHat.6.properties.src._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742050_1226{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:16,104 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742050_1226{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:16,128 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/fontconfig.RedHat.6.properties.src._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:16,164 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/fontconfig.SuSE.10.bfc._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742051_1227{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:16,167 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742051_1227{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:16,179 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/fontconfig.SuSE.10.bfc._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:16,207 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/fontconfig.SuSE.10.properties.src._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742052_1228{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:16,211 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742052_1228{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:16,230 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/fontconfig.SuSE.10.properties.src._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:16,277 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/fontconfig.SuSE.11.bfc._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742053_1229{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:16,281 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742053_1229{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:16,281 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/fontconfig.SuSE.11.bfc._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:16,281 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742053_1229{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 7032
2015-07-15 11:02:16,688 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/fontconfig.SuSE.11.bfc._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:16,710 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/fontconfig.SuSE.11.properties.src._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742054_1230{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:16,714 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742054_1230{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:16,718 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/fontconfig.SuSE.11.properties.src._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:16,740 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/fontconfig.Turbo.bfc._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742055_1231{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:16,743 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742055_1231{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:16,749 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/fontconfig.Turbo.bfc._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:16,770 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/fontconfig.Turbo.properties.src._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742056_1232{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:16,773 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742056_1232{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:16,779 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/fontconfig.Turbo.properties.src._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:16,813 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/fontconfig.bfc._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742057_1233{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:16,816 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742057_1233{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:16,830 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/fontconfig.bfc._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:16,852 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/fontconfig.properties.src._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742058_1234{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:16,855 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742058_1234{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:16,861 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/fontconfig.properties.src._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:16,916 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/fonts/LucidaBrightDemiBold.ttf._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742059_1235{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:16,923 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742059_1235{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:16,932 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/fonts/LucidaBrightDemiBold.ttf._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:16,955 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/fonts/LucidaBrightDemiItalic.ttf._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742060_1236{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:16,959 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742060_1236{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:16,973 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/fonts/LucidaBrightDemiItalic.ttf._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:17,006 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/fonts/LucidaBrightItalic.ttf._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742061_1237{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:17,009 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742061_1237{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:17,018 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 11:02:17,024 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/fonts/LucidaBrightItalic.ttf._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:17,028 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:02:17,029 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:02:17,035 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:02:17,035 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:02:17,149 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/fonts/LucidaBrightRegular.ttf._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742062_1238{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:17,155 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742062_1238{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:17,187 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/fonts/LucidaBrightRegular.ttf._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:17,224 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/fonts/LucidaSansDemiBold.ttf._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742063_1239{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:17,230 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742063_1239{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:17,247 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/fonts/LucidaSansDemiBold.ttf._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:17,280 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/fonts/LucidaSansRegular.ttf._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742064_1240{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:17,290 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742064_1240{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:17,308 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/fonts/LucidaSansRegular.ttf._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:17,332 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/fonts/LucidaTypewriterBold.ttf._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742065_1241{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:17,336 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742065_1241{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:17,339 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/fonts/LucidaTypewriterBold.ttf._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:17,376 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/fonts/LucidaTypewriterRegular.ttf._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742066_1242{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:17,382 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742066_1242{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:17,400 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/fonts/LucidaTypewriterRegular.ttf._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:17,422 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/fonts/fonts.dir._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742067_1243{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:17,425 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742067_1243{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:17,431 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/fonts/fonts.dir._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:17,452 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/hijrah-config-umalqura.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742068_1244{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:17,455 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742068_1244{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:17,461 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/hijrah-config-umalqura.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:17,508 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/client/Xusage.txt._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742069_1245{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:17,510 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742069_1245{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:17,522 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/client/Xusage.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:17,551 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/client/libjsig.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742070_1246{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:17,554 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742070_1246{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:17,573 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/client/libjsig.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:17,594 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/client/libjvm.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742071_1247{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:17,647 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742071_1247{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:17,817 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/client/libjvm.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:17,849 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/jli/libjli.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742072_1248{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:17,853 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742072_1248{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:17,858 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/jli/libjli.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:17,879 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/jvm.cfg._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742073_1249{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:17,884 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742073_1249{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:17,888 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/jvm.cfg._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:17,916 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libattach.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742074_1250{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:17,919 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742074_1250{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:17,939 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libattach.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:17,971 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libavplugin-53.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742075_1251{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:17,974 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742075_1251{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:17,990 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libavplugin-53.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:18,021 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libavplugin-54.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742076_1252{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:18,025 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742076_1252{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:18,041 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libavplugin-54.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:18,076 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libawt.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742077_1253{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:18,086 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742077_1253{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:18,102 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libawt.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:18,129 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libawt_headless.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742078_1254{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:18,134 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742078_1254{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:18,143 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libawt_headless.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:18,172 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libawt_xawt.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742079_1255{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:18,186 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742079_1255{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:18,186 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libawt_xawt.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:18,186 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742079_1255{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 392795
2015-07-15 11:02:18,600 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libawt_xawt.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:18,624 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libbci.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742080_1256{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:18,637 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742080_1256{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:18,641 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libbci.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:18,664 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libdcpr.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742081_1257{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:18,669 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742081_1257{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:18,672 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libdcpr.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:18,708 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libdecora_sse.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742082_1258{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:18,711 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742082_1258{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:18,722 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libdecora_sse.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:18,746 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libdeploy.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742083_1259{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:18,749 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742083_1259{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:18,753 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libdeploy.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:18,780 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libdt_socket.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742084_1260{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:18,783 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742084_1260{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:18,794 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libdt_socket.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:18,817 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libfontmanager.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742085_1261{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:18,829 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742085_1261{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:18,845 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libfontmanager.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:18,881 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libfxplugins.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742086_1262{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:18,885 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742086_1262{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:18,895 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libfxplugins.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:18,918 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libglass.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742087_1263{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:18,933 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742087_1263{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:18,946 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libglass.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:18,980 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libgstreamer-lite.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742088_1264{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:19,164 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:02:19,165 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:02:19,171 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:02:19,171 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:02:19,180 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742088_1264{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:19,325 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libgstreamer-lite.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:19,470 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libhprof.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742089_1265{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:19,475 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742089_1265{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:19,485 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libhprof.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:19,513 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libinstrument.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742090_1266{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:19,516 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742090_1266{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:19,536 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libinstrument.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:19,570 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libj2gss.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742091_1267{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:19,575 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742091_1267{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:19,607 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libj2gss.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:19,639 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libj2pcsc.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742092_1268{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:19,642 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742092_1268{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:19,658 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libj2pcsc.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:19,694 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libj2pkcs11.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742093_1269{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:19,698 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742093_1269{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:19,709 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libj2pkcs11.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:19,731 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libjaas_unix.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742094_1270{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:19,733 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742094_1270{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:19,740 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libjaas_unix.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:19,772 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libjava.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742095_1271{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:19,775 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742095_1271{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:19,801 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libjava.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:19,823 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libjava_crw_demo.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742096_1272{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:19,826 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742096_1272{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:19,831 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libjava_crw_demo.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:19,853 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libjavafx_font.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742097_1273{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:19,856 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742097_1273{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:19,862 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libjavafx_font.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:19,888 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libjavafx_font_freetype.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742098_1274{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:19,891 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742098_1274{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:19,903 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libjavafx_font_freetype.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:19,925 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libjavafx_font_pango.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742099_1275{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:19,927 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742099_1275{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:19,933 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libjavafx_font_pango.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:19,965 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libjavafx_font_t2k.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742100_1276{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:19,980 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742100_1276{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:19,994 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libjavafx_font_t2k.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:20,031 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libjavafx_iio.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742101_1277{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:20,036 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742101_1277{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:20,045 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libjavafx_iio.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:20,080 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libjawt.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742102_1278{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:20,082 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742102_1278{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:20,096 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libjawt.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:20,132 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libjdwp.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742103_1279{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:20,137 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742103_1279{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:20,147 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libjdwp.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:20,176 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libjfr.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742104_1280{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:20,179 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742104_1280{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:20,198 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libjfr.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:20,228 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libjfxmedia.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742105_1281{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:20,234 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742105_1281{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:20,248 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libjfxmedia.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:20,279 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libjfxwebkit.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742106_1282{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:21,648 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742106_1282{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:21,807 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libjfxwebkit.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:21,837 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libjpeg.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742107_1283{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:21,841 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742107_1283{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:21,856 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libjpeg.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:21,882 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libjsdt.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742108_1284{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:21,884 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742108_1284{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:21,896 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libjsdt.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:21,918 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libjsig.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742109_1285{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:21,921 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742109_1285{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:21,927 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libjsig.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:21,948 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libjsound.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742110_1286{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:21,951 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742110_1286{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:21,957 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libjsound.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:21,992 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libjsoundalsa.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742111_1287{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:21,995 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742111_1287{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:22,008 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libjsoundalsa.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:22,038 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libkcms.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742112_1288{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:22,044 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742112_1288{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:22,059 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libkcms.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:22,100 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/liblcms.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742113_1289{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:22,106 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742113_1289{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:22,120 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/liblcms.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:22,142 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libmanagement.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742114_1290{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:22,146 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742114_1290{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:22,151 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libmanagement.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:22,179 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libmlib_image.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742115_1291{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:22,193 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742115_1291{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:22,202 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libmlib_image.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:22,223 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libnet.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742116_1292{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:22,226 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742116_1292{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:22,232 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libnet.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:22,254 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libnio.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742117_1293{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:22,262 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742117_1293{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:22,262 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libnio.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:22,264 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742117_1293{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 80641
2015-07-15 11:02:22,669 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libnio.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:22,693 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libnpjp2.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742118_1294{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:22,697 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742118_1294{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:22,700 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libnpjp2.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:22,726 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libnpt.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742119_1295{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:22,735 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742119_1295{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:22,751 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libnpt.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:22,773 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libprism_common.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742120_1296{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:22,776 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742120_1296{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:22,792 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libprism_common.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:22,814 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libprism_es2.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742121_1297{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:22,818 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742121_1297{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:22,818 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libprism_es2.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:22,818 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742121_1297{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 57820
2015-07-15 11:02:23,229 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libprism_es2.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:23,266 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libprism_sw.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742122_1298{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:23,269 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742122_1298{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:23,280 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libprism_sw.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:23,301 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libresource.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742123_1299{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:23,304 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742123_1299{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:23,310 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libresource.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:23,333 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libsaproc.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742124_1300{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:23,335 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742124_1300{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:23,341 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libsaproc.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:23,363 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libsctp.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742125_1301{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:23,366 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742125_1301{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:23,371 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libsctp.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:23,403 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libsplashscreen.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742126_1302{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:23,408 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742126_1302{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:23,422 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libsplashscreen.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:23,444 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libsunec.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742127_1303{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:23,450 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742127_1303{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:23,463 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libsunec.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:23,486 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libt2k.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742128_1304{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:23,491 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742128_1304{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:23,493 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libt2k.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:23,528 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libunpack.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742129_1305{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:23,532 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742129_1305{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:23,544 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libunpack.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:23,566 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libverify.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742130_1306{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:23,569 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742130_1306{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:23,585 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libverify.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:23,607 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/libzip.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742131_1307{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:23,610 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742131_1307{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:23,616 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/libzip.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:23,647 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/server/Xusage.txt._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742132_1308{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:23,650 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742132_1308{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:23,656 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/server/Xusage.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:23,678 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/server/libjsig.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742133_1309{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:23,688 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742133_1309{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:23,697 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/server/libjsig.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:23,719 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/i386/server/libjvm.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742134_1310{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:24,027 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742134_1310{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:24,246 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/i386/server/libjvm.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:24,312 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/images/cursors/cursors.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742135_1311{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:24,315 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742135_1311{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:24,328 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/images/cursors/cursors.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:24,361 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/images/cursors/invalid32x32.gif._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742136_1312{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:24,365 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742136_1312{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:24,378 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/images/cursors/invalid32x32.gif._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:24,401 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/images/cursors/motif_CopyDrop32x32.gif._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742137_1313{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:24,403 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742137_1313{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:24,409 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/images/cursors/motif_CopyDrop32x32.gif._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:24,431 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/images/cursors/motif_CopyNoDrop32x32.gif._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742138_1314{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:24,433 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742138_1314{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:24,440 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/images/cursors/motif_CopyNoDrop32x32.gif._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:24,461 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/images/cursors/motif_LinkDrop32x32.gif._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742139_1315{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:24,465 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742139_1315{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:24,480 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/images/cursors/motif_LinkDrop32x32.gif._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:24,508 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/images/cursors/motif_LinkNoDrop32x32.gif._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742140_1316{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:24,512 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742140_1316{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:24,521 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/images/cursors/motif_LinkNoDrop32x32.gif._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:24,543 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/images/cursors/motif_MoveDrop32x32.gif._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742141_1317{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:24,545 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742141_1317{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:24,551 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/images/cursors/motif_MoveDrop32x32.gif._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:24,585 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/images/cursors/motif_MoveNoDrop32x32.gif._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742142_1318{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:24,589 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742142_1318{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:24,602 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/images/cursors/motif_MoveNoDrop32x32.gif._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:24,643 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/images/icons/sun-java.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742143_1319{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:24,646 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742143_1319{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:24,663 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/images/icons/sun-java.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:24,697 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/images/icons/sun-java_HighContrast.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742144_1320{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:24,705 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742144_1320{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:24,724 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/images/icons/sun-java_HighContrast.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:24,746 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/images/icons/sun-java_HighContrastInverse.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742145_1321{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:24,750 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742145_1321{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:24,755 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/images/icons/sun-java_HighContrastInverse.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:24,776 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/images/icons/sun-java_LowContrast.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742146_1322{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:24,779 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742146_1322{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:24,785 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/images/icons/sun-java_LowContrast.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:24,819 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/javafx.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742147_1323{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:24,821 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742147_1323{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:24,836 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/javafx.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:24,869 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/javaws.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742148_1324{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:24,878 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742148_1324{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:24,897 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/javaws.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:24,919 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/jce.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742149_1325{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:24,922 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742149_1325{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:24,928 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/jce.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:24,953 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/jexec._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742150_1326{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:24,956 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742150_1326{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:24,969 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/jexec._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:25,022 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/jfr/default.jfc._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742151_1327{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:25,024 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742151_1327{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:25,040 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/jfr/default.jfc._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:25,062 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/jfr/profile.jfc._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742152_1328{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:25,064 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742152_1328{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:25,070 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/jfr/profile.jfc._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:25,092 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/jfr.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742153_1329{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:25,097 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742153_1329{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:25,101 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/jfr.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:25,132 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/jfxswt.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742154_1330{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:25,135 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742154_1330{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:25,152 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/jfxswt.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:25,175 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/jsse.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742155_1331{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:25,180 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742155_1331{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:25,192 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/jsse.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:25,227 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/jvm.hprof.txt._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742156_1332{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:25,230 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742156_1332{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:25,243 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/jvm.hprof.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:25,325 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/locale/de/LC_MESSAGES/sunw_java_plugin.mo._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742157_1333{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:25,328 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742157_1333{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:25,360 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/locale/de/LC_MESSAGES/sunw_java_plugin.mo._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:25,427 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/locale/es/LC_MESSAGES/sunw_java_plugin.mo._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742158_1334{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:25,429 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742158_1334{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:25,437 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/locale/es/LC_MESSAGES/sunw_java_plugin.mo._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:25,478 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/locale/fr/LC_MESSAGES/sunw_java_plugin.mo._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742159_1335{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:25,480 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742159_1335{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:25,487 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/locale/fr/LC_MESSAGES/sunw_java_plugin.mo._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:25,529 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/locale/it/LC_MESSAGES/sunw_java_plugin.mo._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742160_1336{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:25,535 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742160_1336{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:25,549 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/locale/it/LC_MESSAGES/sunw_java_plugin.mo._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:25,611 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/locale/ja/LC_MESSAGES/sunw_java_plugin.mo._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742161_1337{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:25,614 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742161_1337{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:25,620 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/locale/ja/LC_MESSAGES/sunw_java_plugin.mo._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:25,671 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/locale/ko/LC_MESSAGES/sunw_java_plugin.mo._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742162_1338{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:25,674 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742162_1338{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:25,681 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/locale/ko/LC_MESSAGES/sunw_java_plugin.mo._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:25,723 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/locale/ko.UTF-8/LC_MESSAGES/sunw_java_plugin.mo._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742163_1339{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:25,726 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742163_1339{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:25,732 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/locale/ko.UTF-8/LC_MESSAGES/sunw_java_plugin.mo._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:25,774 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/locale/pt_BR/LC_MESSAGES/sunw_java_plugin.mo._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742164_1340{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:25,776 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742164_1340{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:25,783 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/locale/pt_BR/LC_MESSAGES/sunw_java_plugin.mo._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:25,824 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/locale/sv/LC_MESSAGES/sunw_java_plugin.mo._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742165_1341{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:25,831 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742165_1341{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:25,844 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/locale/sv/LC_MESSAGES/sunw_java_plugin.mo._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:25,886 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/locale/zh/LC_MESSAGES/sunw_java_plugin.mo._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742166_1342{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:25,892 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742166_1342{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:25,905 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/locale/zh/LC_MESSAGES/sunw_java_plugin.mo._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:25,967 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/locale/zh.GBK/LC_MESSAGES/sunw_java_plugin.mo._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742167_1343{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:25,970 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742167_1343{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:25,976 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/locale/zh.GBK/LC_MESSAGES/sunw_java_plugin.mo._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:26,034 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/locale/zh_HK.BIG5HK/LC_MESSAGES/sunw_java_plugin.mo._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742168_1344{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:26,040 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742168_1344{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:26,057 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/locale/zh_HK.BIG5HK/LC_MESSAGES/sunw_java_plugin.mo._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:26,120 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/locale/zh_TW/LC_MESSAGES/sunw_java_plugin.mo._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742169_1345{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:26,122 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742169_1345{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:26,128 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/locale/zh_TW/LC_MESSAGES/sunw_java_plugin.mo._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:26,191 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/locale/zh_TW.BIG5/LC_MESSAGES/sunw_java_plugin.mo._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742170_1346{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:26,194 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742170_1346{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:26,200 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/locale/zh_TW.BIG5/LC_MESSAGES/sunw_java_plugin.mo._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:26,221 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/logging.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742171_1347{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:26,223 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742171_1347{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:26,230 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/logging.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:26,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/management/jmxremote.access._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742172_1348{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:26,275 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742172_1348{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:26,291 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/management/jmxremote.access._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:26,313 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/management/jmxremote.password.template._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742173_1349{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:26,316 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742173_1349{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:26,322 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/management/jmxremote.password.template._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:26,343 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/management/management.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742174_1350{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:26,346 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742174_1350{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:26,352 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/management/management.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:26,387 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/management/snmp.acl.template._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742175_1351{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:26,389 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742175_1351{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:26,403 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/management/snmp.acl.template._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:26,432 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/management-agent.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742176_1352{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:26,436 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742176_1352{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:26,436 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/management-agent.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:26,444 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742176_1352{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 381
2015-07-15 11:02:26,841 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/management-agent.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:26,862 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/meta-index._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742177_1353{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:26,866 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742177_1353{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:26,866 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/meta-index._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:26,866 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742177_1353{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 2034
2015-07-15 11:02:27,278 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/meta-index._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:27,310 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/net.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742178_1354{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:27,313 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742178_1354{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:27,313 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/net.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:27,316 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742178_1354{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 3070
2015-07-15 11:02:27,333 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:02:27,333 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:02:27,338 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:02:27,339 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:02:27,726 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/net.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:27,789 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/oblique-fonts/LucidaSansDemiOblique.ttf._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742179_1355{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:27,793 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742179_1355{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:27,807 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/oblique-fonts/LucidaSansDemiOblique.ttf._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:27,838 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/oblique-fonts/LucidaSansOblique.ttf._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742180_1356{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:27,844 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742180_1356{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:27,858 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/oblique-fonts/LucidaSansOblique.ttf._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:27,889 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/oblique-fonts/LucidaTypewriterBoldOblique.ttf._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742181_1357{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:27,892 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742181_1357{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:27,909 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/oblique-fonts/LucidaTypewriterBoldOblique.ttf._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:27,932 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/oblique-fonts/LucidaTypewriterOblique.ttf._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742182_1358{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:27,935 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742182_1358{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:27,939 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/oblique-fonts/LucidaTypewriterOblique.ttf._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:27,961 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/oblique-fonts/fonts.dir._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742183_1359{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:27,964 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742183_1359{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:27,970 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/oblique-fonts/fonts.dir._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:28,002 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/plugin.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742184_1360{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:28,016 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742184_1360{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:28,031 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/plugin.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:28,062 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/psfont.properties.ja._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742185_1361{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:28,065 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742185_1361{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:28,082 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/psfont.properties.ja._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:28,116 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/psfontj2d.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742186_1362{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:28,119 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742186_1362{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:28,132 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/psfontj2d.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:28,168 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/resources.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742187_1363{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:28,222 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742187_1363{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:28,234 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/resources.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:28,256 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/rt.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742188_1364{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:29,081 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742188_1364{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:29,591 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/rt.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:29,671 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/security/US_export_policy.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742189_1365{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:29,679 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742189_1365{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:29,689 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/security/US_export_policy.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:29,720 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/security/blacklist._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742190_1366{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:29,723 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742190_1366{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:29,729 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/security/blacklist._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:29,751 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/security/blacklisted.certs._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742191_1367{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:29,755 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742191_1367{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:29,760 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/security/blacklisted.certs._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:29,783 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/security/cacerts._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742192_1368{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:29,787 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742192_1368{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:29,791 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/security/cacerts._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:29,826 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/security/java.policy._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742193_1369{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:29,828 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742193_1369{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:29,841 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/security/java.policy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:29,863 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/security/java.security._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742194_1370{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:29,865 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742194_1370{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:29,872 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/security/java.security._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:29,907 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/security/javaws.policy._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742195_1371{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:29,909 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742195_1371{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:29,923 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/security/javaws.policy._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:29,944 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/security/local_policy.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742196_1372{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:29,947 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742196_1372{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:29,953 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/security/local_policy.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:29,984 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/security/trusted.libraries._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:30,006 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/sound.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742197_1373{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:30,008 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742197_1373{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:30,014 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/sound.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:30,040 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/lib/tzdb.dat._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742198_1374{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:30,049 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742198_1374{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:30,059 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/lib/tzdb.dat._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:30,115 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/plugin/desktop/sun_java.desktop._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742199_1375{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:30,121 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742199_1375{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:30,131 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:02:30,132 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:02:30,136 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/plugin/desktop/sun_java.desktop._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:30,138 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:02:30,138 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:02:30,291 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/jre/plugin/desktop/sun_java.png._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742200_1376{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:30,295 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742200_1376{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:30,433 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/jre/plugin/desktop/sun_java.png._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:30,554 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/ant-javafx.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742201_1377{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:30,572 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742201_1377{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:30,584 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/ant-javafx.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:30,612 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/ct.sym._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742202_1378{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:31,320 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742202_1378{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:31,452 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/ct.sym._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:31,480 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/dt.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742203_1379{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:31,484 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742203_1379{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:31,489 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/dt.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:31,532 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/i386/jli/libjli.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742204_1380{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:31,537 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742204_1380{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:31,540 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/i386/jli/libjli.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:31,573 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/i386/libjawt.so._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742205_1381{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:31,579 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742205_1381{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:31,579 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/i386/libjawt.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:31,579 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742205_1381{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 4986
2015-07-15 11:02:31,988 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/i386/libjawt.so._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:32,020 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/ir.idl._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742206_1382{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:32,026 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742206_1382{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:32,026 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/ir.idl._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:32,028 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742206_1382{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 18432
2015-07-15 11:02:32,435 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/ir.idl._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:32,470 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/javafx-mx.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742207_1383{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:32,474 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742207_1383{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:32,486 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/javafx-mx.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:32,509 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/jconsole.jar._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742208_1384{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:32,522 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742208_1384{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:32,527 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/jconsole.jar._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:32,558 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/jexec._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742209_1385{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:32,562 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742209_1385{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:32,578 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/jexec._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:32,616 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/.eclipseproduct._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742210_1386{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:32,618 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742210_1386{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:32,629 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/.eclipseproduct._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:32,657 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/THIRDPARTYLICENSEREADME.txt._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742211_1387{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:32,659 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742211_1387{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:32,669 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/THIRDPARTYLICENSEREADME.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:32,692 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/artifacts.xml._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742212_1388{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:32,695 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742212_1388{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:32,700 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/artifacts.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:32,737 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/configuration/config.ini._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742213_1389{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:32,740 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742213_1389{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:32,751 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/configuration/config.ini._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:32,804 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/configuration/org.eclipse.equinox.simpleconfigurator/bundles.info._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742214_1390{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:32,808 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742214_1390{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:32,832 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/configuration/org.eclipse.equinox.simpleconfigurator/bundles.info._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:32,895 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/configuration/org.eclipse.update/platform.xml._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742215_1391{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:32,897 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742215_1391{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:32,903 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/configuration/org.eclipse.update/platform.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:32,942 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/dropins/README.TXT._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742216_1392{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:32,945 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742216_1392{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:32,954 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/dropins/README.TXT._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:33,001 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/com.jrockit.mc.feature.console_5.5.0.165303/feature.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742217_1393{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:33,004 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742217_1393{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:33,015 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/com.jrockit.mc.feature.console_5.5.0.165303/feature.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:33,037 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/com.jrockit.mc.feature.console_5.5.0.165303/feature.xml._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742218_1394{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:33,050 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742218_1394{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:33,050 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/com.jrockit.mc.feature.console_5.5.0.165303/feature.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:33,050 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742218_1394{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 1472
2015-07-15 11:02:33,463 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/com.jrockit.mc.feature.console_5.5.0.165303/feature.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:33,516 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/com.jrockit.mc.feature.core_5.5.0.165303/feature.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742219_1395{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:33,519 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742219_1395{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:33,534 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/com.jrockit.mc.feature.core_5.5.0.165303/feature.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:33,556 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/com.jrockit.mc.feature.core_5.5.0.165303/feature.xml._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742220_1396{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:33,558 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742220_1396{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:33,565 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/com.jrockit.mc.feature.core_5.5.0.165303/feature.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:33,603 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/com.jrockit.mc.feature.flightrecorder_5.5.0.165303/feature.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742221_1397{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:33,606 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742221_1397{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:33,615 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/com.jrockit.mc.feature.flightrecorder_5.5.0.165303/feature.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:33,643 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/com.jrockit.mc.feature.flightrecorder_5.5.0.165303/feature.xml._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742222_1398{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:33,645 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742222_1398{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:33,656 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/com.jrockit.mc.feature.flightrecorder_5.5.0.165303/feature.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:33,688 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/com.jrockit.mc.feature.rcp.ja_5.5.0.165303/feature.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742223_1399{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:33,691 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742223_1399{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:33,697 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/com.jrockit.mc.feature.rcp.ja_5.5.0.165303/feature.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:33,719 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/com.jrockit.mc.feature.rcp.ja_5.5.0.165303/feature.xml._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742224_1400{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:33,722 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742224_1400{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:33,722 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/com.jrockit.mc.feature.rcp.ja_5.5.0.165303/feature.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:33,724 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742224_1400{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 4161
2015-07-15 11:02:34,134 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/com.jrockit.mc.feature.rcp.ja_5.5.0.165303/feature.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:34,167 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/com.jrockit.mc.feature.rcp.zh_CN_5.5.0.165303/feature.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742225_1401{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:34,169 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742225_1401{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:34,175 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/com.jrockit.mc.feature.rcp.zh_CN_5.5.0.165303/feature.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:34,197 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/com.jrockit.mc.feature.rcp.zh_CN_5.5.0.165303/feature.xml._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742226_1402{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:34,199 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742226_1402{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:34,206 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/com.jrockit.mc.feature.rcp.zh_CN_5.5.0.165303/feature.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:34,248 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/com.jrockit.mc.feature.rcp_5.5.0.165303/feature.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742227_1403{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:34,251 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742227_1403{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:34,256 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/com.jrockit.mc.feature.rcp_5.5.0.165303/feature.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:34,278 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/com.jrockit.mc.feature.rcp_5.5.0.165303/feature.xml._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742228_1404{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:34,281 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742228_1404{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:34,287 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/com.jrockit.mc.feature.rcp_5.5.0.165303/feature.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:34,332 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/com.jrockit.mc.rcp.product_5.5.0.165303/feature.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742229_1405{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:34,335 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742229_1405{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:34,359 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/com.jrockit.mc.rcp.product_5.5.0.165303/feature.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:34,392 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/com.jrockit.mc.rcp.product_5.5.0.165303/feature.xml._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742230_1406{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:34,394 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742230_1406{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:34,409 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/com.jrockit.mc.rcp.product_5.5.0.165303/feature.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:34,441 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.babel.nls_eclipse_ja_4.4.0.v20140623020002/about.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742231_1407{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:34,443 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742231_1407{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:34,450 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.babel.nls_eclipse_ja_4.4.0.v20140623020002/about.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:34,477 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.babel.nls_eclipse_ja_4.4.0.v20140623020002/eclipse_update_120.jpg._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742232_1408{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:34,480 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742232_1408{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:34,480 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.babel.nls_eclipse_ja_4.4.0.v20140623020002/eclipse_update_120.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:34,480 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742232_1408{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 21695
2015-07-15 11:02:34,887 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.babel.nls_eclipse_ja_4.4.0.v20140623020002/eclipse_update_120.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:34,914 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.babel.nls_eclipse_ja_4.4.0.v20140623020002/epl-v10.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742233_1409{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:34,917 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742233_1409{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:34,928 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.babel.nls_eclipse_ja_4.4.0.v20140623020002/epl-v10.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:34,949 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.babel.nls_eclipse_ja_4.4.0.v20140623020002/feature.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742234_1410{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:34,955 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742234_1410{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:34,958 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.babel.nls_eclipse_ja_4.4.0.v20140623020002/feature.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:34,981 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.babel.nls_eclipse_ja_4.4.0.v20140623020002/feature.xml._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742235_1411{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:34,983 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742235_1411{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:34,989 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.babel.nls_eclipse_ja_4.4.0.v20140623020002/feature.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:35,011 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.babel.nls_eclipse_ja_4.4.0.v20140623020002/license.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742236_1412{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:35,013 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742236_1412{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:35,019 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.babel.nls_eclipse_ja_4.4.0.v20140623020002/license.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:35,051 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.babel.nls_eclipse_zh_4.4.0.v20140623020002/about.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742237_1413{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:35,053 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742237_1413{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:35,060 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.babel.nls_eclipse_zh_4.4.0.v20140623020002/about.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:35,082 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.babel.nls_eclipse_zh_4.4.0.v20140623020002/eclipse_update_120.jpg._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742238_1414{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:35,085 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742238_1414{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:35,091 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.babel.nls_eclipse_zh_4.4.0.v20140623020002/eclipse_update_120.jpg._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:35,113 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.babel.nls_eclipse_zh_4.4.0.v20140623020002/epl-v10.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742239_1415{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:35,115 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742239_1415{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:35,121 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.babel.nls_eclipse_zh_4.4.0.v20140623020002/epl-v10.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:35,143 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.babel.nls_eclipse_zh_4.4.0.v20140623020002/feature.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742240_1416{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:35,145 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742240_1416{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:35,152 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.babel.nls_eclipse_zh_4.4.0.v20140623020002/feature.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:35,174 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.babel.nls_eclipse_zh_4.4.0.v20140623020002/feature.xml._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742241_1417{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:35,177 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742241_1417{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:35,182 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.babel.nls_eclipse_zh_4.4.0.v20140623020002/feature.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:35,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.babel.nls_eclipse_zh_4.4.0.v20140623020002/license.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742242_1418{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:35,207 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742242_1418{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:35,213 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.babel.nls_eclipse_zh_4.4.0.v20140623020002/license.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:35,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.e4.rcp_1.3.100.v20141007-2033/META-INF/MANIFEST.MF._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742243_1419{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:35,276 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742243_1419{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:35,294 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.e4.rcp_1.3.100.v20141007-2033/META-INF/MANIFEST.MF._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:35,325 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.e4.rcp_1.3.100.v20141007-2033/epl-v10.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742244_1420{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:35,327 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742244_1420{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:35,335 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.e4.rcp_1.3.100.v20141007-2033/epl-v10.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:35,360 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.e4.rcp_1.3.100.v20141007-2033/feature.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742245_1421{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:35,363 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742245_1421{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:35,376 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.e4.rcp_1.3.100.v20141007-2033/feature.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:35,397 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.e4.rcp_1.3.100.v20141007-2033/feature.xml._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742246_1422{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:35,399 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742246_1422{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:35,406 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.e4.rcp_1.3.100.v20141007-2033/feature.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:35,438 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.e4.rcp_1.3.100.v20141007-2033/license.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742247_1423{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:35,440 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742247_1423{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:35,457 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.e4.rcp_1.3.100.v20141007-2033/license.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:35,499 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.feature_1.1.0.v20140827-1444/META-INF/ECLIPSE_.RSA._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742248_1424{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:35,501 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742248_1424{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:35,508 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.feature_1.1.0.v20140827-1444/META-INF/ECLIPSE_.RSA._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:35,529 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.feature_1.1.0.v20140827-1444/META-INF/ECLIPSE_.SF._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742249_1425{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:35,532 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742249_1425{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:35,538 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.feature_1.1.0.v20140827-1444/META-INF/ECLIPSE_.SF._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:35,560 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.feature_1.1.0.v20140827-1444/META-INF/MANIFEST.MF._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742250_1426{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:35,562 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742250_1426{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:35,569 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.feature_1.1.0.v20140827-1444/META-INF/MANIFEST.MF._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:35,590 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.feature_1.1.0.v20140827-1444/META-INF/eclipse.inf._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742251_1427{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:35,593 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742251_1427{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:35,599 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.feature_1.1.0.v20140827-1444/META-INF/eclipse.inf._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:35,621 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.feature_1.1.0.v20140827-1444/about.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742252_1428{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:35,623 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742252_1428{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:35,630 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.feature_1.1.0.v20140827-1444/about.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:35,655 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.feature_1.1.0.v20140827-1444/epl-v10.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742253_1429{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:35,660 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742253_1429{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:35,671 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.feature_1.1.0.v20140827-1444/epl-v10.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:35,692 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.feature_1.1.0.v20140827-1444/feature.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742254_1430{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:35,695 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742254_1430{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:35,695 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.feature_1.1.0.v20140827-1444/feature.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:35,696 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742254_1430{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 8776
2015-07-15 11:02:36,108 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.feature_1.1.0.v20140827-1444/feature.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:36,130 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.feature_1.1.0.v20140827-1444/feature.xml._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742255_1431{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:36,133 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742255_1431{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:36,139 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.feature_1.1.0.v20140827-1444/feature.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:36,161 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.feature_1.1.0.v20140827-1444/license.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742256_1432{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:36,163 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742256_1432{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:36,169 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.feature_1.1.0.v20140827-1444/license.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:36,231 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.ssl.feature_1.0.0.v20140827-1444/META-INF/ECLIPSE_.RSA._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742257_1433{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:36,233 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742257_1433{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:36,261 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.ssl.feature_1.0.0.v20140827-1444/META-INF/ECLIPSE_.RSA._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:36,283 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.ssl.feature_1.0.0.v20140827-1444/META-INF/ECLIPSE_.SF._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742258_1434{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:36,285 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742258_1434{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:36,291 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.ssl.feature_1.0.0.v20140827-1444/META-INF/ECLIPSE_.SF._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:36,324 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.ssl.feature_1.0.0.v20140827-1444/META-INF/MANIFEST.MF._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742259_1435{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:36,327 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742259_1435{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:36,342 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.ssl.feature_1.0.0.v20140827-1444/META-INF/MANIFEST.MF._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:36,375 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.ssl.feature_1.0.0.v20140827-1444/META-INF/eclipse.inf._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742260_1436{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:36,378 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742260_1436{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:36,378 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.ssl.feature_1.0.0.v20140827-1444/META-INF/eclipse.inf._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:36,378 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742260_1436{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 57
2015-07-15 11:02:36,790 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.ssl.feature_1.0.0.v20140827-1444/META-INF/eclipse.inf._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:36,811 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.ssl.feature_1.0.0.v20140827-1444/about.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742261_1437{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:36,814 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742261_1437{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:36,820 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.ssl.feature_1.0.0.v20140827-1444/about.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:36,842 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.ssl.feature_1.0.0.v20140827-1444/epl-v10.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742262_1438{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:36,844 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742262_1438{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:36,851 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.ssl.feature_1.0.0.v20140827-1444/epl-v10.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:36,883 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.ssl.feature_1.0.0.v20140827-1444/feature.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742263_1439{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:36,885 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742263_1439{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:36,902 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.ssl.feature_1.0.0.v20140827-1444/feature.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:36,923 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.ssl.feature_1.0.0.v20140827-1444/feature.xml._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742264_1440{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:36,926 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742264_1440{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:36,932 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.ssl.feature_1.0.0.v20140827-1444/feature.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:36,954 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.ssl.feature_1.0.0.v20140827-1444/license.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742265_1441{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:36,956 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742265_1441{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:36,963 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.core.ssl.feature_1.0.0.v20140827-1444/license.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:37,008 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.feature_3.9.0.v20140827-1444/META-INF/ECLIPSE_.RSA._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742266_1442{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:37,011 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742266_1442{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:37,024 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.feature_3.9.0.v20140827-1444/META-INF/ECLIPSE_.RSA._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:37,053 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.feature_3.9.0.v20140827-1444/META-INF/ECLIPSE_.SF._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742267_1443{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:37,056 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742267_1443{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:37,056 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.feature_3.9.0.v20140827-1444/META-INF/ECLIPSE_.SF._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:37,056 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742267_1443{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 648
2015-07-15 11:02:37,471 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.feature_3.9.0.v20140827-1444/META-INF/ECLIPSE_.SF._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:37,506 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.feature_3.9.0.v20140827-1444/META-INF/MANIFEST.MF._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742268_1444{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:37,509 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742268_1444{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:37,522 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.feature_3.9.0.v20140827-1444/META-INF/MANIFEST.MF._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:37,553 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.feature_3.9.0.v20140827-1444/META-INF/eclipse.inf._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742269_1445{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:37,556 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742269_1445{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:37,573 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.feature_3.9.0.v20140827-1444/META-INF/eclipse.inf._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:37,606 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.feature_3.9.0.v20140827-1444/about.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742270_1446{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:37,609 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742270_1446{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:37,624 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.feature_3.9.0.v20140827-1444/about.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:37,646 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.feature_3.9.0.v20140827-1444/asl-v20.txt._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742271_1447{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:37,648 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742271_1447{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:37,654 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.feature_3.9.0.v20140827-1444/asl-v20.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:37,676 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.feature_3.9.0.v20140827-1444/epl-v10.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742272_1448{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:37,679 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742272_1448{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:37,685 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.feature_3.9.0.v20140827-1444/epl-v10.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:37,707 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.feature_3.9.0.v20140827-1444/feature.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742273_1449{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:37,709 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742273_1449{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:37,710 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.feature_3.9.0.v20140827-1444/feature.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:37,710 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742273_1449{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 8790
2015-07-15 11:02:38,122 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.feature_3.9.0.v20140827-1444/feature.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:38,150 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.feature_3.9.0.v20140827-1444/feature.xml._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742274_1450{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:38,152 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742274_1450{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:38,163 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.feature_3.9.0.v20140827-1444/feature.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:38,185 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.feature_3.9.0.v20140827-1444/license.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742275_1451{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:38,187 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742275_1451{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:38,194 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.feature_3.9.0.v20140827-1444/license.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:38,271 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.feature_3.9.1.v20140827-1444/META-INF/ECLIPSE_.RSA._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742276_1452{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:38,274 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742276_1452{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:38,285 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.feature_3.9.1.v20140827-1444/META-INF/ECLIPSE_.RSA._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:38,310 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.feature_3.9.1.v20140827-1444/META-INF/ECLIPSE_.SF._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742277_1453{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:38,313 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742277_1453{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:38,326 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.feature_3.9.1.v20140827-1444/META-INF/ECLIPSE_.SF._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:38,347 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.feature_3.9.1.v20140827-1444/META-INF/MANIFEST.MF._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742278_1454{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:38,350 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742278_1454{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:38,356 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.feature_3.9.1.v20140827-1444/META-INF/MANIFEST.MF._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:38,378 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.feature_3.9.1.v20140827-1444/META-INF/eclipse.inf._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742279_1455{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:38,380 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742279_1455{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:38,387 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.feature_3.9.1.v20140827-1444/META-INF/eclipse.inf._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:38,420 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.feature_3.9.1.v20140827-1444/about.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742280_1456{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:38,422 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742280_1456{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:38,428 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.feature_3.9.1.v20140827-1444/about.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:38,449 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.feature_3.9.1.v20140827-1444/asl-v20.txt._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742281_1457{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:38,451 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742281_1457{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:38,458 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.feature_3.9.1.v20140827-1444/asl-v20.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:38,480 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.feature_3.9.1.v20140827-1444/epl-v10.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742282_1458{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:38,482 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742282_1458{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:38,489 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.feature_3.9.1.v20140827-1444/epl-v10.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:38,510 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.feature_3.9.1.v20140827-1444/feature.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742283_1459{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:38,513 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742283_1459{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:38,519 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.feature_3.9.1.v20140827-1444/feature.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:38,541 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.feature_3.9.1.v20140827-1444/feature.xml._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742284_1460{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:38,543 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742284_1460{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:38,550 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.feature_3.9.1.v20140827-1444/feature.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:38,572 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.feature_3.9.1.v20140827-1444/license.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742285_1461{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:38,574 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742285_1461{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:38,580 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.feature_3.9.1.v20140827-1444/license.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:38,622 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.ssl.feature_1.0.0.v20140827-1444/META-INF/ECLIPSE_.RSA._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742286_1462{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:38,624 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742286_1462{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:38,631 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.ssl.feature_1.0.0.v20140827-1444/META-INF/ECLIPSE_.RSA._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:38,653 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.ssl.feature_1.0.0.v20140827-1444/META-INF/ECLIPSE_.SF._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742287_1463{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:38,655 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742287_1463{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:38,655 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.ssl.feature_1.0.0.v20140827-1444/META-INF/ECLIPSE_.SF._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:38,656 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742287_1463{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 648
2015-07-15 11:02:39,058 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.ssl.feature_1.0.0.v20140827-1444/META-INF/ECLIPSE_.SF._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:39,080 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.ssl.feature_1.0.0.v20140827-1444/META-INF/MANIFEST.MF._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742288_1464{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:39,083 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742288_1464{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:39,089 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.ssl.feature_1.0.0.v20140827-1444/META-INF/MANIFEST.MF._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:39,111 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.ssl.feature_1.0.0.v20140827-1444/META-INF/eclipse.inf._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742289_1465{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:39,113 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742289_1465{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:39,119 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.ssl.feature_1.0.0.v20140827-1444/META-INF/eclipse.inf._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:39,141 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.ssl.feature_1.0.0.v20140827-1444/about.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742290_1466{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:39,143 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742290_1466{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:39,150 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.ssl.feature_1.0.0.v20140827-1444/about.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:39,172 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.ssl.feature_1.0.0.v20140827-1444/asl-v20.txt._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742291_1467{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:39,174 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742291_1467{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:39,181 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.ssl.feature_1.0.0.v20140827-1444/asl-v20.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:39,202 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.ssl.feature_1.0.0.v20140827-1444/epl-v10.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742292_1468{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:39,204 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742292_1468{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:39,211 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.ssl.feature_1.0.0.v20140827-1444/epl-v10.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:39,233 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.ssl.feature_1.0.0.v20140827-1444/feature.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742293_1469{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:39,235 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742293_1469{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:39,242 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.ssl.feature_1.0.0.v20140827-1444/feature.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:39,263 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.ssl.feature_1.0.0.v20140827-1444/feature.xml._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742294_1470{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:39,268 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742294_1470{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:39,272 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.ssl.feature_1.0.0.v20140827-1444/feature.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:39,294 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.ssl.feature_1.0.0.v20140827-1444/license.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742295_1471{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:39,296 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742295_1471{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:39,303 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.httpclient4.ssl.feature_1.0.0.v20140827-1444/license.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:39,359 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.ssl.feature_1.0.0.v20140827-1444/META-INF/ECLIPSE_.RSA._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742296_1472{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:39,361 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742296_1472{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:39,374 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.ssl.feature_1.0.0.v20140827-1444/META-INF/ECLIPSE_.RSA._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:39,406 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.ssl.feature_1.0.0.v20140827-1444/META-INF/ECLIPSE_.SF._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742297_1473{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:39,408 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742297_1473{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:39,415 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.ssl.feature_1.0.0.v20140827-1444/META-INF/ECLIPSE_.SF._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:39,436 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.ssl.feature_1.0.0.v20140827-1444/META-INF/MANIFEST.MF._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742298_1474{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:39,439 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742298_1474{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:39,445 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.ssl.feature_1.0.0.v20140827-1444/META-INF/MANIFEST.MF._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:39,467 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.ssl.feature_1.0.0.v20140827-1444/META-INF/eclipse.inf._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742299_1475{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:39,472 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742299_1475{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:39,476 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.ssl.feature_1.0.0.v20140827-1444/META-INF/eclipse.inf._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:39,505 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.ssl.feature_1.0.0.v20140827-1444/about.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742300_1476{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:39,507 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742300_1476{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:39,527 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.ssl.feature_1.0.0.v20140827-1444/about.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:39,573 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.ssl.feature_1.0.0.v20140827-1444/epl-v10.html._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742301_1477{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:39,575 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742301_1477{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:39,588 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.ssl.feature_1.0.0.v20140827-1444/epl-v10.html._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:39,609 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.ssl.feature_1.0.0.v20140827-1444/feature.properties._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742302_1478{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:39,611 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742302_1478{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:02:39,618 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.ssl.feature_1.0.0.v20140827-1444/feature.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:39,640 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.ssl.feature_1.0.0.v20140827-1444/feature.xml._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742303_1479{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:02:39,642 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742303_1479{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 11:02:39,642 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.ssl.feature_1.0.0.v20140827-1444/feature.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:02:39,648 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742303_1479{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 1343
2015-07-15 11:02:40,056 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /jdk/lib/missioncontrol/features/org.eclipse.ecf.filetransfer.ssl.feature_1.0.0.v20140827-1444/feature.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_-47902698_1
2015-07-15 11:03:22,965 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3000 Total time for transactions(ms): 63 Number of transactions batched in Syncs: 33 Number of syncs: 1563 SyncTimes(ms): 16835 
2015-07-15 11:03:23,001 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /matrix._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742304_1480{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 11:03:23,108 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742304_1480{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 11:03:23,124 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /matrix._COPYING_ is closed by DFSClient_NONMAPREDUCE_300542059_1
2015-07-15 11:03:32,325 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 11:03:32,335 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:03:32,336 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:03:32,341 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:03:32,341 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:03:33,269 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:03:33,269 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:03:33,283 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:03:33,284 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:03:33,353 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:03:33,353 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:03:33,359 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:03:33,360 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:03:33,370 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:03:33,371 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:03:33,409 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:03:33,410 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:08:02,800 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:liyaohui (auth:SIMPLE) cause:java.io.FileNotFoundException: Path is not a file: /jdk
2015-07-15 11:08:02,801 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 9000, call org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations from 127.0.0.1:51493 Call#0 Retry#0: error: java.io.FileNotFoundException: Path is not a file: /jdk
2015-07-15 11:09:52,005 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 11:09:52,020 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:09:52,020 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:09:52,026 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:09:52,027 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:20:29,253 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 11:20:29,263 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:20:29,263 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:20:29,271 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:20:29,272 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:20:34,173 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 11:20:34,182 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:20:34,183 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:20:34,189 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:20:34,189 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:22:19,457 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 11:22:19,468 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:22:19,468 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:22:19,476 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:22:19,476 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:22:20,726 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:22:20,727 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:22:20,736 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:22:20,736 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:22:20,763 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:22:20,764 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:22:20,773 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:22:20,773 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:22:20,788 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:22:20,788 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:22:20,799 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:22:20,799 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:22:23,499 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:22:23,499 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:22:23,505 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:22:23,505 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:25:18,455 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 11:25:18,466 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:25:18,466 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:25:18,472 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:25:18,472 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:28:07,540 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 11:28:07,551 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:28:07,552 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:28:07,557 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:28:07,557 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:28:13,590 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 11:28:13,605 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:28:13,605 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:28:13,611 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:28:13,611 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:28:15,260 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:28:15,260 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:28:15,265 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:28:15,265 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:28:15,286 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:28:15,286 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:28:15,296 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:28:15,296 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:28:15,301 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:28:15,302 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:28:15,314 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:28:15,314 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:28:19,772 INFO logs: Aliases are enabled
2015-07-15 11:28:48,637 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 11:28:48,648 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:28:48,648 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:28:48,653 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:28:48,654 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:28:50,781 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 11:28:50,800 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:28:50,800 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:28:50,809 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:28:50,809 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:29:41,935 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 11:29:41,946 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:29:41,946 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:29:41,951 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:29:41,952 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:32:37,853 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 11:32:37,864 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:32:37,864 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:32:37,869 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:32:37,870 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:33:35,101 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 11:33:35,111 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:33:35,111 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:33:35,118 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:33:35,118 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:33:38,398 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:33:38,399 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:33:38,405 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:33:38,405 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:33:40,470 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:33:40,470 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:33:40,475 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:33:40,476 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:33:43,490 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:33:43,491 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:33:43,496 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:33:43,496 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:33:44,440 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:33:44,441 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:33:44,446 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:33:44,446 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:34:13,524 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 11:34:13,533 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:34:13,533 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 11:34:13,538 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 11:34:13,539 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 12:00:49,900 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-07-15 12:00:49,900 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-07-15 12:00:49,900 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 4
2015-07-15 12:00:49,900 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3006 Total time for transactions(ms): 63 Number of transactions batched in Syncs: 33 Number of syncs: 1566 SyncTimes(ms): 16858 
2015-07-15 12:00:49,915 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3006 Total time for transactions(ms): 63 Number of transactions batched in Syncs: 33 Number of syncs: 1567 SyncTimes(ms): 16873 
2015-07-15 12:00:49,916 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000000004 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000000004-0000000000000003009
2015-07-15 12:00:49,916 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3010
2015-07-15 12:00:50,336 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=3009&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 12:00:50,392 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.06s at 1125.00 KB/s
2015-07-15 12:00:50,392 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000003009 size 64940 bytes.
2015-07-15 12:00:50,423 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3
2015-07-15 12:00:50,423 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000000001, cpktTxId=0000000000000000001)
2015-07-15 13:00:50,731 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-07-15 13:00:50,731 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-07-15 13:00:50,731 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 3010
2015-07-15 13:00:50,732 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 77 
2015-07-15 13:00:50,747 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 92 
2015-07-15 13:00:50,748 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000003010 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000003010-0000000000000003011
2015-07-15 13:00:50,748 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3012
2015-07-15 13:00:50,958 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=3011&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 13:00:51,000 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 1465.12 KB/s
2015-07-15 13:00:51,001 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000003011 size 64940 bytes.
2015-07-15 13:00:51,033 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3009
2015-07-15 13:00:51,033 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000000003, cpktTxId=0000000000000000003)
2015-07-15 14:00:51,323 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-07-15 14:00:51,323 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-07-15 14:00:51,323 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 3012
2015-07-15 14:00:51,323 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 61 
2015-07-15 14:00:51,329 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 67 
2015-07-15 14:00:51,330 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000003012 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000003012-0000000000000003013
2015-07-15 14:00:51,330 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3014
2015-07-15 14:00:51,539 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=3013&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 14:00:51,574 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 1800.00 KB/s
2015-07-15 14:00:51,574 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000003013 size 64940 bytes.
2015-07-15 14:00:51,605 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3011
2015-07-15 14:00:51,605 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000003009, cpktTxId=0000000000000003009)
2015-07-15 14:05:35,129 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 14:05:35,140 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 14:05:35,140 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 14:05:35,145 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 14:05:35,145 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 14:05:36,809 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 14:05:36,809 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 14:05:36,814 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 14:05:36,815 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 14:22:25,691 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2015-07-15 14:22:25,693 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ubuntu01/127.0.1.1
************************************************************/
2015-07-15 14:27:47,953 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-07-15 14:27:47,960 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-07-15 14:27:48,162 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-07-15 14:27:48,248 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-07-15 14:27:48,248 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2015-07-15 14:27:48,346 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-07-15 14:27:48,482 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-07-15 14:27:48,531 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-07-15 14:27:48,533 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2015-07-15 14:27:48,533 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-07-15 14:27:48,533 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-07-15 14:27:48,545 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2015-07-15 14:27:48,557 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2015-07-15 14:27:48,557 INFO org.mortbay.log: jetty-6.1.26
2015-07-15 14:27:48,848 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2015-07-15 14:27:48,848 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2015-07-15 14:27:48,874 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2015-07-15 14:27:48,875 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2015-07-15 14:27:48,935 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2015-07-15 14:27:48,935 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2015-07-15 14:27:48,937 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-07-15 14:27:48,940 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-07-15 14:27:48,940 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-07-15 14:27:48,940 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2015-07-15 14:27:48,941 INFO org.apache.hadoop.util.GSet: capacity      = 2^22 = 4194304 entries
2015-07-15 14:27:48,952 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-07-15 14:27:48,953 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-07-15 14:27:48,953 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-07-15 14:27:48,953 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-07-15 14:27:48,953 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-07-15 14:27:48,953 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-07-15 14:27:48,953 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-07-15 14:27:48,953 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-07-15 14:27:48,959 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = liyaohui (auth:SIMPLE)
2015-07-15 14:27:48,959 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-07-15 14:27:48,959 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-07-15 14:27:48,959 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-07-15 14:27:48,961 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-07-15 14:27:49,216 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-07-15 14:27:49,216 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-07-15 14:27:49,216 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2015-07-15 14:27:49,216 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-07-15 14:27:49,220 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-07-15 14:27:49,224 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-07-15 14:27:49,224 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-07-15 14:27:49,224 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-07-15 14:27:49,225 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2015-07-15 14:27:49,225 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2015-07-15 14:27:49,227 INFO org.apache.hadoop.util.GSet: Computing capacity for map Namenode Retry Cache
2015-07-15 14:27:49,227 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-07-15 14:27:49,227 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory = 889 MB
2015-07-15 14:27:49,227 INFO org.apache.hadoop.util.GSet: capacity      = 2^16 = 65536 entries
2015-07-15 14:27:49,276 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/liyaohui/hadoop/tmp/dfs/name/in_use.lock acquired by nodename 9919@ubuntu01
2015-07-15 14:27:49,313 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/liyaohui/hadoop/tmp/dfs/name/current
2015-07-15 14:27:49,360 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000003014 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000003014-0000000000000003014
2015-07-15 14:27:49,372 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000003013 using no compression
2015-07-15 14:27:49,373 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 604
2015-07-15 14:27:49,412 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2015-07-15 14:27:49,412 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000003013 of size 64940 bytes loaded in 0 seconds.
2015-07-15 14:27:49,412 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 3013 from /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000003013
2015-07-15 14:27:49,413 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@669da8 expecting start txid #3014
2015-07-15 14:27:49,413 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000003014-0000000000000003014
2015-07-15 14:27:49,415 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000003014-0000000000000003014' to transaction ID 3014
2015-07-15 14:27:49,419 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000003014-0000000000000003014 of size 1048576 edits # 1 loaded in 0 seconds
2015-07-15 14:27:49,422 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3015
2015-07-15 14:27:49,715 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 3 entries 45 lookups
2015-07-15 14:27:49,715 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 487 msecs
2015-07-15 14:27:49,898 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ubuntu01:9000
2015-07-15 14:27:49,917 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2015-07-15 14:27:49,939 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2015-07-15 14:27:49,953 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2015-07-15 14:27:49,953 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2015-07-15 14:27:49,954 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 480 blocks to reach the threshold 0.9990 of total blocks 480.
Safe mode will be turned off automatically
2015-07-15 14:27:49,975 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-07-15 14:27:49,975 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2015-07-15 14:27:49,978 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ubuntu01/127.0.1.1:9000
2015-07-15 14:27:49,978 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2015-07-15 14:27:54,087 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1, storageID=DS-1927886287-127.0.1.1-50010-1436049057919, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62;nsid=783537164;c=0) storage DS-1927886287-127.0.1.1-50010-1436049057919
2015-07-15 14:27:54,089 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2015-07-15 14:27:54,201 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 479 has reached the threshold 0.9990 of total blocks 480. The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically in 29 seconds.
2015-07-15 14:27:54,201 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2015-07-15 14:27:54,219 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 480
2015-07-15 14:27:54,219 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2015-07-15 14:27:54,219 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 1
2015-07-15 14:27:54,219 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2015-07-15 14:27:54,219 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2015-07-15 14:27:54,219 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 18 msec
2015-07-15 14:27:54,219 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 127.0.0.1:50010 after starting up or becoming active. Its block contents are no longer considered stale
2015-07-15 14:27:54,219 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(127.0.0.1, storageID=DS-1927886287-127.0.1.1-50010-1436049057919, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62;nsid=783537164;c=0), blocks: 480, processing time: 30 msecs
2015-07-15 14:28:14,222 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 480 has reached the threshold 0.9990 of total blocks 480. The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically in 9 seconds.
2015-07-15 14:28:24,223 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 35 secs
2015-07-15 14:28:24,223 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2015-07-15 14:28:24,223 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2015-07-15 14:28:24,223 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2015-07-15 14:28:58,832 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-07-15 14:28:58,832 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-07-15 14:28:58,832 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 3015
2015-07-15 14:28:58,832 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 65 
2015-07-15 14:28:58,846 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 79 
2015-07-15 14:28:58,847 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000003015 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000003015-0000000000000003016
2015-07-15 14:28:58,847 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3017
2015-07-15 14:28:59,506 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=3016&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 14:28:59,647 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.14s at 450.00 KB/s
2015-07-15 14:28:59,648 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000003016 size 64940 bytes.
2015-07-15 14:28:59,681 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3013
2015-07-15 14:28:59,681 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000003011, cpktTxId=0000000000000003011)
2015-07-15 14:39:49,913 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 14:39:49,915 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 14:39:49,934 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 14:39:49,934 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 14:39:52,368 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 14:39:52,388 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 14:39:52,389 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 14:39:52,397 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 14:39:52,398 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 14:39:56,429 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 14:39:56,441 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 14:39:56,442 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 14:39:56,450 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 14:39:56,450 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 15:29:00,109 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-07-15 15:29:00,110 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-07-15 15:29:00,110 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 3017
2015-07-15 15:29:00,110 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 70 
2015-07-15 15:29:00,119 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 79 
2015-07-15 15:29:00,120 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000003017 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000003017-0000000000000003019
2015-07-15 15:29:00,120 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3020
2015-07-15 15:29:00,351 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=3019&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 15:29:00,403 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 1235.29 KB/s
2015-07-15 15:29:00,403 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000003019 size 64940 bytes.
2015-07-15 15:29:00,434 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3016
2015-07-15 15:29:00,434 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000003013, cpktTxId=0000000000000003013)
2015-07-15 15:46:14,308 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 67 
2015-07-15 15:46:14,362 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /a.txt. BP-1159783791-127.0.1.1-1436048545002 blk_1073742305_1481{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 15:46:14,500 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742305_1481{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 15:46:14,503 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /a.txt is closed by DFSClient_NONMAPREDUCE_317743306_37
2015-07-15 15:46:14,507 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742305_1481{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 59
2015-07-15 15:46:14,920 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /a.txt is closed by DFSClient_NONMAPREDUCE_317743306_37
2015-07-15 15:46:14,932 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /b.txt. BP-1159783791-127.0.1.1-1436048545002 blk_1073742306_1482{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 15:46:14,942 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742306_1482{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 15:46:14,951 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /b.txt is closed by DFSClient_NONMAPREDUCE_317743306_37
2015-07-15 15:46:28,519 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 15:46:28,537 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 15:46:28,537 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 15:46:28,549 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 15:46:28,549 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 15:46:30,629 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 15:46:30,629 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 15:46:30,637 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 15:46:30,637 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 15:46:30,661 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 15:46:30,661 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 15:46:30,670 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 15:46:30,670 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 15:46:30,680 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 15:46:30,680 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 15:46:30,714 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 15:46:30,715 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 15:46:33,496 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 15:46:33,496 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 15:46:33,505 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 15:46:33,505 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 15:46:33,521 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 15:46:33,522 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 15:46:33,528 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 15:46:33,528 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 15:46:33,535 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 15:46:33,535 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 15:46:33,557 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 15:46:33,557 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 15:48:49,064 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 15:48:49,065 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 15:48:49,069 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 15:48:49,070 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 15:48:49,112 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 15:48:49,112 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 15:48:49,118 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 15:48:49,118 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 15:48:49,123 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 15:48:49,123 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 15:48:49,135 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 15:48:49,135 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 15:48:52,371 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 15:48:52,371 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 15:48:52,377 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 15:48:52,377 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 15:50:21,774 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 15:50:21,784 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 15:50:21,785 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 15:50:21,790 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 15:50:21,790 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 15:58:02,213 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 15:58:02,224 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 15:58:02,225 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 15:58:02,230 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 15:58:02,230 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:10:20,796 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 16 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 7 SyncTimes(ms): 103 
2015-07-15 16:10:21,188 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0001/job.jar. BP-1159783791-127.0.1.1-1436048545002 blk_1073742307_1483{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:10:21,529 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742307_1483{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:10:21,847 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0001/job.jar is closed by DFSClient_NONMAPREDUCE_595912454_1
2015-07-15 16:10:21,869 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0001/job.jar
2015-07-15 16:10:22,026 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0001/job.split
2015-07-15 16:10:22,062 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0001/job.split. BP-1159783791-127.0.1.1-1436048545002 blk_1073742308_1484{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:10:22,068 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742308_1484{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:10:22,086 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0001/job.split is closed by DFSClient_NONMAPREDUCE_595912454_1
2015-07-15 16:10:22,109 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0001/job.splitmetainfo. BP-1159783791-127.0.1.1-1436048545002 blk_1073742309_1485{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:10:22,113 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742309_1485{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:10:22,117 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0001/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_595912454_1
2015-07-15 16:10:22,230 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0001/job.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742310_1486{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:10:22,238 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742310_1486{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:10:22,259 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0001/job.xml is closed by DFSClient_NONMAPREDUCE_595912454_1
2015-07-15 16:10:29,910 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0001/job_1436941682764_0001_1_conf.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742311_1487{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:10:29,973 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742311_1487{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:10:29,980 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0001/job_1436941682764_0001_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-200758874_1
2015-07-15 16:10:34,530 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0001/job_1436941682764_0001_1.jhist. BP-1159783791-127.0.1.1-1436048545002 blk_1073742312_1488{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:10:34,555 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0001/job_1436941682764_0001_1.jhist for DFSClient_NONMAPREDUCE_-200758874_1
2015-07-15 16:10:39,338 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /wcout/_temporary/1/_temporary/attempt_1436941682764_0001_r_000000_0/part-r-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742313_1489{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:10:39,430 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742313_1489{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:10:39,450 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /wcout/_temporary/1/_temporary/attempt_1436941682764_0001_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1436941682764_0001_r_000000_0_-2076600413_1
2015-07-15 16:10:39,613 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0001/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-200758874_1
2015-07-15 16:10:39,694 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /wcout/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-200758874_1
2015-07-15 16:10:39,724 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0001/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-200758874_1
2015-07-15 16:10:39,740 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742312_1488{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:10:39,755 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0001/job_1436941682764_0001_1.jhist is closed by DFSClient_NONMAPREDUCE_-200758874_1
2015-07-15 16:10:39,768 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0001.summary_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742314_1490{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:10:39,785 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742314_1490{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:10:39,796 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0001.summary_tmp is closed by DFSClient_NONMAPREDUCE_-200758874_1
2015-07-15 16:10:39,844 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0001-1436947822533-liyaohui-wc.jar-1436947839725-1-1-SUCCEEDED-default.jhist_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742315_1491{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:10:39,850 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742315_1491{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:10:39,857 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0001-1436947822533-liyaohui-wc.jar-1436947839725-1-1-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-200758874_1
2015-07-15 16:10:39,882 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0001_conf.xml_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742316_1492{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:10:39,893 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742316_1492{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:10:39,897 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0001_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-200758874_1
2015-07-15 16:10:39,969 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742307_1483 127.0.0.1:50010 
2015-07-15 16:10:39,969 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742308_1484 127.0.0.1:50010 
2015-07-15 16:10:39,969 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742309_1485 127.0.0.1:50010 
2015-07-15 16:10:39,969 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742310_1486 127.0.0.1:50010 
2015-07-15 16:10:39,969 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742312_1488 127.0.0.1:50010 
2015-07-15 16:10:39,969 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742311_1487 127.0.0.1:50010 
2015-07-15 16:10:41,214 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742307_1483, blk_1073742308_1484, blk_1073742309_1485, blk_1073742310_1486, blk_1073742311_1487, blk_1073742312_1488]
2015-07-15 16:10:47,174 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 16:10:47,245 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:10:47,245 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:10:47,250 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:10:47,251 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:10:49,487 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:10:49,488 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:10:49,496 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:10:49,496 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:10:50,881 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:10:50,882 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:10:50,888 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:10:50,888 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:10:50,936 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:10:50,936 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:10:50,942 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:10:50,943 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:10:50,950 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:10:50,950 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:10:50,964 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:10:50,965 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:23:47,200 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 102 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 58 SyncTimes(ms): 931 
2015-07-15 16:23:47,243 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /synthetic_control.data.txt._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742317_1493{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:23:47,348 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742317_1493{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:23:47,360 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /synthetic_control.data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1938948383_1
2015-07-15 16:24:10,193 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 16:24:10,204 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:24:10,204 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:24:10,210 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:24:10,210 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:24:11,364 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:24:11,365 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:24:11,369 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:24:11,369 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:24:11,380 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:24:11,381 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:24:11,386 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:24:11,387 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:24:11,408 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:24:11,408 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:24:17,361 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:24:17,361 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:24:17,367 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:24:17,368 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:29:00,729 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-07-15 16:29:00,729 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-07-15 16:29:00,729 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 3020
2015-07-15 16:29:00,729 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 108 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 0 Number of syncs: 61 SyncTimes(ms): 949 
2015-07-15 16:29:00,738 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 108 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 0 Number of syncs: 62 SyncTimes(ms): 958 
2015-07-15 16:29:00,739 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000003020 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000003020-0000000000000003127
2015-07-15 16:29:00,739 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3128
2015-07-15 16:29:00,973 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=3127&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 16:29:01,013 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 1666.67 KB/s
2015-07-15 16:29:01,013 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000003127 size 66857 bytes.
2015-07-15 16:29:01,044 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3019
2015-07-15 16:29:01,045 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000003016, cpktTxId=0000000000000003016)
2015-07-15 16:33:48,789 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 58 
2015-07-15 16:33:48,884 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0002/job.jar. BP-1159783791-127.0.1.1-1436048545002 blk_1073742318_1494{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:33:49,469 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742318_1494{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:33:49,691 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0002/job.jar is closed by DFSClient_NONMAPREDUCE_646447379_1
2015-07-15 16:33:49,697 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0002/job.jar
2015-07-15 16:33:49,945 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742318_1494 127.0.0.1:50010 
2015-07-15 16:33:50,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742318_1494]
2015-07-15 16:34:04,333 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 16:34:04,347 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:34:04,348 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:34:04,353 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:34:04,353 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:34:12,253 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:34:12,253 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:34:12,259 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:34:12,260 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:34:12,260 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:dr.who (auth:SIMPLE) cause:org.apache.hadoop.security.AccessControlException: Permission denied: user=dr.who, access=READ_EXECUTE, inode="/tmp":liyaohui:supergroup:drwx------
2015-07-15 16:34:12,261 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9000, call org.apache.hadoop.hdfs.protocol.ClientProtocol.getListing from 127.0.0.1:53678 Call#2616 Retry#0: error: org.apache.hadoop.security.AccessControlException: Permission denied: user=dr.who, access=READ_EXECUTE, inode="/tmp":liyaohui:supergroup:drwx------
2015-07-15 16:34:14,700 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:34:14,700 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:34:14,705 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:34:14,705 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:36:52,258 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 16:36:52,269 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:36:52,269 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:36:52,278 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:36:52,279 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:38:41,690 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 12 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 9 SyncTimes(ms): 526 
2015-07-15 16:38:48,542 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 16:38:48,556 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:38:48,556 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:38:48,562 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:38:48,563 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:38:50,193 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:38:50,193 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:38:50,198 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:38:50,198 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:39:42,472 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 13 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 10 SyncTimes(ms): 533 
2015-07-15 16:39:42,520 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /testdata/synthetic_control.data.txt._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742319_1495{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:39:42,628 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742319_1495{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:39:42,638 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /testdata/synthetic_control.data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_760755751_1
2015-07-15 16:39:47,407 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:39:47,407 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:39:47,412 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:39:47,412 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:40:00,859 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0003/job.jar. BP-1159783791-127.0.1.1-1436048545002 blk_1073742320_1496{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:40:01,156 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742320_1496{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:40:01,430 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0003/job.jar is closed by DFSClient_NONMAPREDUCE_-1483906918_1
2015-07-15 16:40:01,436 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0003/job.jar
2015-07-15 16:40:01,568 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742320_1496 127.0.0.1:50010 
2015-07-15 16:40:02,288 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742320_1496]
2015-07-15 16:41:09,923 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:41:09,923 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:41:09,929 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:41:09,930 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:41:11,780 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:41:11,780 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:41:11,785 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:41:11,785 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:41:11,820 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:41:11,821 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:41:11,827 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:41:11,828 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:41:11,845 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:41:11,845 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:41:18,369 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:41:18,370 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:41:18,375 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:41:18,375 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:41:20,251 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:41:20,251 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:41:20,256 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:41:20,257 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:41:22,003 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:41:22,003 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:41:22,008 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:41:22,010 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:41:22,052 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:41:22,052 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:41:22,060 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:41:22,060 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:41:22,073 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:41:22,076 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:43:59,424 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 16:43:59,433 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:43:59,434 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:43:59,438 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:43:59,439 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:44:04,135 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:44:04,136 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:44:04,140 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:44:04,141 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:46:06,972 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 16:46:06,982 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:46:06,982 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:46:06,988 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:46:06,988 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:46:36,437 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 16:46:36,450 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:46:36,451 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:46:36,460 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:46:36,460 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:46:39,455 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:46:39,455 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:46:39,461 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:46:39,461 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:46:42,365 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 16:46:42,377 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:46:42,377 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:46:42,382 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:46:42,382 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:47:15,490 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 29 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 0 Number of syncs: 20 SyncTimes(ms): 968 
2015-07-15 16:47:47,160 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 16:47:47,169 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:47:47,169 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:47:47,174 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:47:47,174 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:47:49,174 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:47:49,175 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:47:49,180 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:47:49,180 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:47:50,541 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:47:50,541 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:47:50,548 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:47:50,549 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:47:51,711 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:47:51,711 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:47:51,716 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:47:51,717 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:48:26,393 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 32 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 23 SyncTimes(ms): 1002 
2015-07-15 16:48:26,438 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/testdata/synthetic_control.data.txt._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742321_1497{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:48:26,544 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742321_1497{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:48:26,555 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/testdata/synthetic_control.data.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1639626261_1
2015-07-15 16:48:29,584 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:48:29,584 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:48:29,589 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:48:29,589 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:48:30,988 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:48:30,988 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:48:30,993 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:48:30,994 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:48:31,715 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:48:31,716 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:48:31,721 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:48:31,721 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:48:44,954 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0004/job.jar. BP-1159783791-127.0.1.1-1436048545002 blk_1073742322_1498{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:48:45,581 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742322_1498{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:48:45,918 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0004/job.jar is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:48:45,923 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0004/job.jar
2015-07-15 16:48:46,452 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0004/job.split
2015-07-15 16:48:46,468 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0004/job.split. BP-1159783791-127.0.1.1-1436048545002 blk_1073742323_1499{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:48:46,475 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742323_1499{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:48:46,482 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0004/job.split is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:48:46,505 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0004/job.splitmetainfo. BP-1159783791-127.0.1.1-1436048545002 blk_1073742324_1500{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:48:46,509 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742324_1500{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:48:46,512 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0004/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:48:46,621 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0004/job.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742325_1501{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:48:46,629 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742325_1501{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:48:46,634 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0004/job.xml is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:48:51,533 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0004/job_1436941682764_0004_1_conf.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742326_1502{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:48:51,581 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742326_1502{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:48:51,588 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0004/job_1436941682764_0004_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-315098551_1
2015-07-15 16:48:55,867 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1436941682764_0004_m_000000_0/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742327_1503{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:48:55,976 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742327_1503{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:48:55,983 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1436941682764_0004_m_000000_0/part-m-00000 is closed by DFSClient_attempt_1436941682764_0004_m_000000_0_-1382743616_1
2015-07-15 16:48:56,115 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0004/job_1436941682764_0004_1.jhist. BP-1159783791-127.0.1.1-1436048545002 blk_1073742328_1504{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:48:56,125 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0004/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-315098551_1
2015-07-15 16:48:56,126 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0004/job_1436941682764_0004_1.jhist for DFSClient_NONMAPREDUCE_-315098551_1
2015-07-15 16:48:56,196 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-315098551_1
2015-07-15 16:48:56,227 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0004/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-315098551_1
2015-07-15 16:48:56,242 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742328_1504{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:48:56,247 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0004/job_1436941682764_0004_1.jhist is closed by DFSClient_NONMAPREDUCE_-315098551_1
2015-07-15 16:48:56,260 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0004.summary_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742329_1505{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:48:56,273 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742329_1505{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:48:56,288 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0004.summary_tmp is closed by DFSClient_NONMAPREDUCE_-315098551_1
2015-07-15 16:48:56,337 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0004-1436950126803-liyaohui-Input+Driver+running+over+input%3A+testdata-1436950136228-1-0-SUCCEEDED-default.jhist_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742330_1506{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:48:56,342 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742330_1506{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:48:56,349 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0004-1436950126803-liyaohui-Input+Driver+running+over+input%3A+testdata-1436950136228-1-0-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-315098551_1
2015-07-15 16:48:56,372 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0004_conf.xml_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742331_1507{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:48:56,379 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742331_1507{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:48:56,389 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0004_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-315098551_1
2015-07-15 16:48:57,458 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742322_1498 127.0.0.1:50010 
2015-07-15 16:48:57,458 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742323_1499 127.0.0.1:50010 
2015-07-15 16:48:57,458 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742324_1500 127.0.0.1:50010 
2015-07-15 16:48:57,458 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742325_1501 127.0.0.1:50010 
2015-07-15 16:48:57,458 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742328_1504 127.0.0.1:50010 
2015-07-15 16:48:57,458 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742326_1502 127.0.0.1:50010 
2015-07-15 16:48:58,281 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/random-seeds/part-randomSeed is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:48:58,512 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/random-seeds/part-randomSeed. BP-1159783791-127.0.1.1-1436048545002 blk_1073742332_1508{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:48:58,518 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742332_1508{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:48:58,526 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/random-seeds/part-randomSeed is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:48:58,588 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/clusters-0/_policy. BP-1159783791-127.0.1.1-1436048545002 blk_1073742333_1509{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:48:58,593 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742333_1509{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:48:58,597 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-0/_policy is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:48:58,629 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/clusters-0/part-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742334_1510{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:48:58,635 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742334_1510{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:48:58,648 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-0/part-00000 is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:48:58,660 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/clusters-0/part-00001. BP-1159783791-127.0.1.1-1436048545002 blk_1073742335_1511{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:48:58,665 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742335_1511{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:48:58,678 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-0/part-00001 is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:48:58,690 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/clusters-0/part-00002. BP-1159783791-127.0.1.1-1436048545002 blk_1073742336_1512{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:48:58,693 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742336_1512{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:48:58,699 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-0/part-00002 is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:48:58,710 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/clusters-0/part-00003. BP-1159783791-127.0.1.1-1436048545002 blk_1073742337_1513{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:48:58,717 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742337_1513{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:48:58,729 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-0/part-00003 is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:48:58,741 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/clusters-0/part-00004. BP-1159783791-127.0.1.1-1436048545002 blk_1073742338_1514{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:48:58,744 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742338_1514{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:48:58,749 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-0/part-00004 is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:48:58,761 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/clusters-0/part-00005. BP-1159783791-127.0.1.1-1436048545002 blk_1073742339_1515{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:48:58,765 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742339_1515{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:48:58,770 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-0/part-00005 is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:48:58,853 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0005/job.jar. BP-1159783791-127.0.1.1-1436048545002 blk_1073742340_1516{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:48:59,054 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742340_1516{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:48:59,309 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742322_1498, blk_1073742323_1499, blk_1073742324_1500, blk_1073742325_1501, blk_1073742326_1502, blk_1073742328_1504]
2015-07-15 16:48:59,520 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0005/job.jar is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:48:59,521 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0005/job.jar
2015-07-15 16:48:59,574 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0005/job.split
2015-07-15 16:48:59,584 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0005/job.split. BP-1159783791-127.0.1.1-1436048545002 blk_1073742341_1517{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:48:59,588 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742341_1517{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:48:59,594 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0005/job.split is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:48:59,615 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0005/job.splitmetainfo. BP-1159783791-127.0.1.1-1436048545002 blk_1073742342_1518{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:48:59,619 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742342_1518{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:48:59,624 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0005/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:48:59,656 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0005/job.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742343_1519{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:48:59,662 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742343_1519{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:48:59,675 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0005/job.xml is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:49:08,208 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0005/job_1436941682764_0005_1_conf.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742344_1520{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:49:08,260 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742344_1520{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:49:08,270 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0005/job_1436941682764_0005_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-529778682_1
2015-07-15 16:49:13,020 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0005/job_1436941682764_0005_1.jhist. BP-1159783791-127.0.1.1-1436048545002 blk_1073742345_1521{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:49:13,031 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0005/job_1436941682764_0005_1.jhist for DFSClient_NONMAPREDUCE_-529778682_1
2015-07-15 16:49:17,794 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/clusters-1/_temporary/1/_temporary/attempt_1436941682764_0005_r_000000_0/part-r-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742346_1522{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:49:17,837 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742346_1522{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:49:17,852 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-1/_temporary/1/_temporary/attempt_1436941682764_0005_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1436941682764_0005_r_000000_0_-2142135030_1
2015-07-15 16:49:18,982 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0005/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-529778682_1
2015-07-15 16:49:19,032 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-1/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-529778682_1
2015-07-15 16:49:19,053 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0005/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-529778682_1
2015-07-15 16:49:19,069 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742345_1521{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:49:19,085 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0005/job_1436941682764_0005_1.jhist is closed by DFSClient_NONMAPREDUCE_-529778682_1
2015-07-15 16:49:19,096 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0005.summary_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742347_1523{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:49:19,100 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742347_1523{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:49:19,114 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0005.summary_tmp is closed by DFSClient_NONMAPREDUCE_-529778682_1
2015-07-15 16:49:19,156 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0005-1436950139682-liyaohui-Cluster+Iterator+running+iteration+1+over+priorPat-1436950159054-1-1-SUCCEEDED-default.jhist_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742348_1524{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:49:19,161 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742348_1524{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:49:19,165 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0005-1436950139682-liyaohui-Cluster+Iterator+running+iteration+1+over+priorPat-1436950159054-1-1-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-529778682_1
2015-07-15 16:49:19,189 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0005_conf.xml_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742349_1525{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:49:19,193 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742349_1525{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:49:19,205 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0005_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-529778682_1
2015-07-15 16:49:20,263 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742340_1516 127.0.0.1:50010 
2015-07-15 16:49:20,264 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742341_1517 127.0.0.1:50010 
2015-07-15 16:49:20,264 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742342_1518 127.0.0.1:50010 
2015-07-15 16:49:20,264 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742343_1519 127.0.0.1:50010 
2015-07-15 16:49:20,264 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742345_1521 127.0.0.1:50010 
2015-07-15 16:49:20,264 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742344_1520 127.0.0.1:50010 
2015-07-15 16:49:20,310 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742340_1516, blk_1073742341_1517, blk_1073742342_1518, blk_1073742343_1519, blk_1073742344_1520, blk_1073742345_1521]
2015-07-15 16:49:20,997 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/clusters-1/_policy. BP-1159783791-127.0.1.1-1436048545002 blk_1073742350_1526{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:49:21,001 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742350_1526{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:49:21,006 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-1/_policy is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:49:21,080 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0006/job.jar. BP-1159783791-127.0.1.1-1436048545002 blk_1073742351_1527{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:49:21,293 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742351_1527{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:49:21,746 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0006/job.jar is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:49:21,748 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0006/job.jar
2015-07-15 16:49:21,790 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0006/job.split
2015-07-15 16:49:21,801 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0006/job.split. BP-1159783791-127.0.1.1-1436048545002 blk_1073742352_1528{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:49:21,804 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742352_1528{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:49:21,809 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0006/job.split is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:49:21,831 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0006/job.splitmetainfo. BP-1159783791-127.0.1.1-1436048545002 blk_1073742353_1529{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:49:21,835 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742353_1529{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 16:49:21,835 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0006/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:49:21,835 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742353_1529{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 25
2015-07-15 16:49:22,247 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0006/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:49:22,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0006/job.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742354_1530{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:49:22,280 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742354_1530{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:49:22,288 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0006/job.xml is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:49:31,011 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 277 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 1 Number of syncs: 155 SyncTimes(ms): 3512 
2015-07-15 16:49:31,202 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0006/job_1436941682764_0006_1_conf.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742355_1531{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:49:31,252 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742355_1531{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:49:31,259 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0006/job_1436941682764_0006_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1235071340_1
2015-07-15 16:49:36,060 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0006/job_1436941682764_0006_1.jhist. BP-1159783791-127.0.1.1-1436048545002 blk_1073742356_1532{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:49:36,072 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0006/job_1436941682764_0006_1.jhist for DFSClient_NONMAPREDUCE_1235071340_1
2015-07-15 16:49:41,634 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/clusters-2/_temporary/1/_temporary/attempt_1436941682764_0006_r_000000_0/part-r-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742357_1533{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:49:41,674 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742357_1533{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:49:41,686 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-2/_temporary/1/_temporary/attempt_1436941682764_0006_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1436941682764_0006_r_000000_0_-654911357_1
2015-07-15 16:49:42,815 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0006/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_1235071340_1
2015-07-15 16:49:42,865 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-2/_SUCCESS is closed by DFSClient_NONMAPREDUCE_1235071340_1
2015-07-15 16:49:42,886 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0006/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_1235071340_1
2015-07-15 16:49:42,901 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742356_1532{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:49:42,915 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0006/job_1436941682764_0006_1.jhist is closed by DFSClient_NONMAPREDUCE_1235071340_1
2015-07-15 16:49:42,929 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0006.summary_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742358_1534{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:49:42,933 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742358_1534{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:49:42,947 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0006.summary_tmp is closed by DFSClient_NONMAPREDUCE_1235071340_1
2015-07-15 16:49:42,987 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0006-1436950162295-liyaohui-Cluster+Iterator+running+iteration+2+over+priorPat-1436950182887-1-1-SUCCEEDED-default.jhist_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742359_1535{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:49:42,993 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742359_1535{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:49:42,998 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0006-1436950162295-liyaohui-Cluster+Iterator+running+iteration+2+over+priorPat-1436950182887-1-1-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_1235071340_1
2015-07-15 16:49:43,022 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0006_conf.xml_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742360_1536{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:49:43,027 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742360_1536{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:49:43,038 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0006_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_1235071340_1
2015-07-15 16:49:44,096 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742351_1527 127.0.0.1:50010 
2015-07-15 16:49:44,096 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742352_1528 127.0.0.1:50010 
2015-07-15 16:49:44,097 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742353_1529 127.0.0.1:50010 
2015-07-15 16:49:44,097 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742354_1530 127.0.0.1:50010 
2015-07-15 16:49:44,097 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742356_1532 127.0.0.1:50010 
2015-07-15 16:49:44,097 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742355_1531 127.0.0.1:50010 
2015-07-15 16:49:44,312 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742352_1528, blk_1073742353_1529, blk_1073742354_1530, blk_1073742355_1531, blk_1073742356_1532, blk_1073742351_1527]
2015-07-15 16:49:44,596 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/clusters-2/_policy. BP-1159783791-127.0.1.1-1436048545002 blk_1073742361_1537{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:49:44,600 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742361_1537{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:49:44,605 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-2/_policy is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:49:44,668 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0007/job.jar. BP-1159783791-127.0.1.1-1436048545002 blk_1073742362_1538{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:49:44,885 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742362_1538{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 16:49:44,885 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0007/job.jar is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:49:44,885 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742362_1538{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 24178445
2015-07-15 16:49:45,297 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0007/job.jar is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:49:45,298 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0007/job.jar
2015-07-15 16:49:45,338 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0007/job.split
2015-07-15 16:49:45,348 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0007/job.split. BP-1159783791-127.0.1.1-1436048545002 blk_1073742363_1539{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:49:45,353 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742363_1539{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:49:45,358 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0007/job.split is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:49:45,379 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0007/job.splitmetainfo. BP-1159783791-127.0.1.1-1436048545002 blk_1073742364_1540{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:49:45,384 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742364_1540{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:49:45,388 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0007/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:49:45,415 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0007/job.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742365_1541{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:49:45,424 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742365_1541{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:49:45,429 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0007/job.xml is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:49:54,829 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0007/job_1436941682764_0007_1_conf.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742366_1542{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:49:54,875 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742366_1542{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:49:54,889 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0007/job_1436941682764_0007_1_conf.xml is closed by DFSClient_NONMAPREDUCE_15848918_1
2015-07-15 16:49:59,520 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0007/job_1436941682764_0007_1.jhist. BP-1159783791-127.0.1.1-1436048545002 blk_1073742367_1543{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:49:59,528 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0007/job_1436941682764_0007_1.jhist for DFSClient_NONMAPREDUCE_15848918_1
2015-07-15 16:50:04,234 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/clusters-3/_temporary/1/_temporary/attempt_1436941682764_0007_r_000000_0/part-r-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742368_1544{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:04,277 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742368_1544{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:04,288 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-3/_temporary/1/_temporary/attempt_1436941682764_0007_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1436941682764_0007_r_000000_0_-1418461165_1
2015-07-15 16:50:04,410 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0007/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_15848918_1
2015-07-15 16:50:04,461 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-3/_SUCCESS is closed by DFSClient_NONMAPREDUCE_15848918_1
2015-07-15 16:50:04,481 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0007/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_15848918_1
2015-07-15 16:50:04,496 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742367_1543{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:04,513 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0007/job_1436941682764_0007_1.jhist is closed by DFSClient_NONMAPREDUCE_15848918_1
2015-07-15 16:50:04,524 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0007.summary_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742369_1545{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:04,530 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742369_1545{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:04,542 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0007.summary_tmp is closed by DFSClient_NONMAPREDUCE_15848918_1
2015-07-15 16:50:04,580 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0007-1436950185441-liyaohui-Cluster+Iterator+running+iteration+3+over+priorPat-1436950204482-1-1-SUCCEEDED-default.jhist_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742370_1546{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:04,587 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742370_1546{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:04,603 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0007-1436950185441-liyaohui-Cluster+Iterator+running+iteration+3+over+priorPat-1436950204482-1-1-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_15848918_1
2015-07-15 16:50:04,627 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0007_conf.xml_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742371_1547{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:04,632 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742371_1547{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:04,644 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0007_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_15848918_1
2015-07-15 16:50:05,702 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742362_1538 127.0.0.1:50010 
2015-07-15 16:50:05,702 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742363_1539 127.0.0.1:50010 
2015-07-15 16:50:05,702 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742364_1540 127.0.0.1:50010 
2015-07-15 16:50:05,702 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742365_1541 127.0.0.1:50010 
2015-07-15 16:50:05,702 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742367_1543 127.0.0.1:50010 
2015-07-15 16:50:05,702 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742366_1542 127.0.0.1:50010 
2015-07-15 16:50:06,732 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/clusters-3/_policy. BP-1159783791-127.0.1.1-1436048545002 blk_1073742372_1548{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:06,743 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742372_1548{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:06,750 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-3/_policy is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:50:06,802 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0008/job.jar. BP-1159783791-127.0.1.1-1436048545002 blk_1073742373_1549{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:07,005 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742373_1549{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:07,358 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0008/job.jar is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:50:07,359 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0008/job.jar
2015-07-15 16:50:07,432 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0008/job.split
2015-07-15 16:50:07,442 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0008/job.split. BP-1159783791-127.0.1.1-1436048545002 blk_1073742374_1550{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:07,448 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742374_1550{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:07,451 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0008/job.split is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:50:07,472 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0008/job.splitmetainfo. BP-1159783791-127.0.1.1-1436048545002 blk_1073742375_1551{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:07,476 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742375_1551{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:07,482 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0008/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:50:07,508 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0008/job.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742376_1552{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:07,514 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742376_1552{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:07,523 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0008/job.xml is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:50:08,313 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742362_1538, blk_1073742363_1539, blk_1073742364_1540, blk_1073742365_1541, blk_1073742366_1542, blk_1073742367_1543]
2015-07-15 16:50:16,420 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0008/job_1436941682764_0008_1_conf.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742377_1553{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:16,488 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742377_1553{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:16,494 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0008/job_1436941682764_0008_1_conf.xml is closed by DFSClient_NONMAPREDUCE_829151038_1
2015-07-15 16:50:21,104 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0008/job_1436941682764_0008_1.jhist. BP-1159783791-127.0.1.1-1436048545002 blk_1073742378_1554{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:21,114 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0008/job_1436941682764_0008_1.jhist for DFSClient_NONMAPREDUCE_829151038_1
2015-07-15 16:50:25,804 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/clusters-4/_temporary/1/_temporary/attempt_1436941682764_0008_r_000000_0/part-r-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742379_1555{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:25,845 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742379_1555{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:25,853 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-4/_temporary/1/_temporary/attempt_1436941682764_0008_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1436941682764_0008_r_000000_0_-582154774_1
2015-07-15 16:50:25,985 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0008/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_829151038_1
2015-07-15 16:50:26,036 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-4/_SUCCESS is closed by DFSClient_NONMAPREDUCE_829151038_1
2015-07-15 16:50:26,056 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0008/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_829151038_1
2015-07-15 16:50:26,069 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742378_1554{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:26,076 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0008/job_1436941682764_0008_1.jhist is closed by DFSClient_NONMAPREDUCE_829151038_1
2015-07-15 16:50:26,089 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0008.summary_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742380_1556{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:26,092 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742380_1556{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:26,097 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0008.summary_tmp is closed by DFSClient_NONMAPREDUCE_829151038_1
2015-07-15 16:50:26,136 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0008-1436950207529-liyaohui-Cluster+Iterator+running+iteration+4+over+priorPat-1436950226057-1-1-SUCCEEDED-default.jhist_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742381_1557{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:26,140 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742381_1557{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:26,148 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0008-1436950207529-liyaohui-Cluster+Iterator+running+iteration+4+over+priorPat-1436950226057-1-1-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_829151038_1
2015-07-15 16:50:26,171 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0008_conf.xml_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742382_1558{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:26,180 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742382_1558{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:26,188 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0008_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_829151038_1
2015-07-15 16:50:27,246 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742373_1549 127.0.0.1:50010 
2015-07-15 16:50:27,246 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742374_1550 127.0.0.1:50010 
2015-07-15 16:50:27,246 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742375_1551 127.0.0.1:50010 
2015-07-15 16:50:27,246 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742376_1552 127.0.0.1:50010 
2015-07-15 16:50:27,246 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742378_1554 127.0.0.1:50010 
2015-07-15 16:50:27,246 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742377_1553 127.0.0.1:50010 
2015-07-15 16:50:27,817 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/clusters-4/_policy. BP-1159783791-127.0.1.1-1436048545002 blk_1073742383_1559{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:27,824 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742383_1559{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:27,836 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-4/_policy is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:50:27,898 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0009/job.jar. BP-1159783791-127.0.1.1-1436048545002 blk_1073742384_1560{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:28,126 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742384_1560{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:28,495 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0009/job.jar is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:50:28,496 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0009/job.jar
2015-07-15 16:50:28,539 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0009/job.split
2015-07-15 16:50:28,549 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0009/job.split. BP-1159783791-127.0.1.1-1436048545002 blk_1073742385_1561{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:28,558 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742385_1561{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:28,569 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0009/job.split is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:50:28,589 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0009/job.splitmetainfo. BP-1159783791-127.0.1.1-1436048545002 blk_1073742386_1562{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:28,595 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742386_1562{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:28,599 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0009/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:50:28,625 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0009/job.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742387_1563{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:28,630 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742387_1563{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:28,640 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0009/job.xml is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:50:29,314 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742373_1549, blk_1073742374_1550, blk_1073742375_1551, blk_1073742376_1552, blk_1073742377_1553, blk_1073742378_1554]
2015-07-15 16:50:37,766 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 534 Total time for transactions(ms): 23 Number of transactions batched in Syncs: 2 Number of syncs: 299 SyncTimes(ms): 5449 
2015-07-15 16:50:37,967 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0009/job_1436941682764_0009_1_conf.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742388_1564{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:38,013 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742388_1564{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:38,029 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0009/job_1436941682764_0009_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1878295990_1
2015-07-15 16:50:42,667 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0009/job_1436941682764_0009_1.jhist. BP-1159783791-127.0.1.1-1436048545002 blk_1073742389_1565{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:42,675 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0009/job_1436941682764_0009_1.jhist for DFSClient_NONMAPREDUCE_1878295990_1
2015-07-15 16:50:47,349 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/clusters-5/_temporary/1/_temporary/attempt_1436941682764_0009_r_000000_0/part-r-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742390_1566{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:47,395 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742390_1566{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:47,407 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-5/_temporary/1/_temporary/attempt_1436941682764_0009_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1436941682764_0009_r_000000_0_-1624694773_1
2015-07-15 16:50:47,550 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0009/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_1878295990_1
2015-07-15 16:50:47,600 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-5/_SUCCESS is closed by DFSClient_NONMAPREDUCE_1878295990_1
2015-07-15 16:50:47,621 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0009/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_1878295990_1
2015-07-15 16:50:47,635 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742389_1565{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:47,641 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0009/job_1436941682764_0009_1.jhist is closed by DFSClient_NONMAPREDUCE_1878295990_1
2015-07-15 16:50:47,653 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0009.summary_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742391_1567{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:47,659 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742391_1567{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:47,672 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0009.summary_tmp is closed by DFSClient_NONMAPREDUCE_1878295990_1
2015-07-15 16:50:47,711 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0009-1436950228655-liyaohui-Cluster+Iterator+running+iteration+5+over+priorPat-1436950247622-1-1-SUCCEEDED-default.jhist_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742392_1568{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:47,717 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742392_1568{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:47,722 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0009-1436950228655-liyaohui-Cluster+Iterator+running+iteration+5+over+priorPat-1436950247622-1-1-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_1878295990_1
2015-07-15 16:50:47,746 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0009_conf.xml_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742393_1569{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:47,753 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742393_1569{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:47,763 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0009_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_1878295990_1
2015-07-15 16:50:48,821 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742384_1560 127.0.0.1:50010 
2015-07-15 16:50:48,821 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742385_1561 127.0.0.1:50010 
2015-07-15 16:50:48,821 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742386_1562 127.0.0.1:50010 
2015-07-15 16:50:48,821 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742387_1563 127.0.0.1:50010 
2015-07-15 16:50:48,821 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742389_1565 127.0.0.1:50010 
2015-07-15 16:50:48,821 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742388_1564 127.0.0.1:50010 
2015-07-15 16:50:48,987 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/clusters-5/_policy. BP-1159783791-127.0.1.1-1436048545002 blk_1073742394_1570{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:48,994 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742394_1570{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:49,004 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-5/_policy is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:50:49,056 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0010/job.jar. BP-1159783791-127.0.1.1-1436048545002 blk_1073742395_1571{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:49,294 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742395_1571{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 16:50:49,294 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0010/job.jar is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:50:49,295 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742395_1571{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 24178445
2015-07-15 16:50:49,716 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0010/job.jar is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:50:49,717 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0010/job.jar
2015-07-15 16:50:49,768 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0010/job.split
2015-07-15 16:50:49,778 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0010/job.split. BP-1159783791-127.0.1.1-1436048545002 blk_1073742396_1572{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:49,781 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742396_1572{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:49,787 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0010/job.split is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:50:49,808 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0010/job.splitmetainfo. BP-1159783791-127.0.1.1-1436048545002 blk_1073742397_1573{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:49,811 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742397_1573{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:49,818 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0010/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:50:49,844 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0010/job.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742398_1574{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:49,852 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742398_1574{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:49,859 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0010/job.xml is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:50:50,316 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742384_1560, blk_1073742385_1561, blk_1073742386_1562, blk_1073742387_1563, blk_1073742388_1564, blk_1073742389_1565]
2015-07-15 16:50:59,549 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0010/job_1436941682764_0010_1_conf.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742399_1575{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:50:59,596 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742399_1575{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:50:59,603 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0010/job_1436941682764_0010_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-100869044_1
2015-07-15 16:51:04,356 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0010/job_1436941682764_0010_1.jhist. BP-1159783791-127.0.1.1-1436048545002 blk_1073742400_1576{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:04,362 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0010/job_1436941682764_0010_1.jhist for DFSClient_NONMAPREDUCE_-100869044_1
2015-07-15 16:51:08,959 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/clusters-6/_temporary/1/_temporary/attempt_1436941682764_0010_r_000000_0/part-r-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742401_1577{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:09,004 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742401_1577{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:09,013 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-6/_temporary/1/_temporary/attempt_1436941682764_0010_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1436941682764_0010_r_000000_0_2072519237_1
2015-07-15 16:51:09,135 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0010/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-100869044_1
2015-07-15 16:51:09,185 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-6/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-100869044_1
2015-07-15 16:51:09,206 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0010/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-100869044_1
2015-07-15 16:51:09,219 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742400_1576{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:09,226 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0010/job_1436941682764_0010_1.jhist is closed by DFSClient_NONMAPREDUCE_-100869044_1
2015-07-15 16:51:09,250 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0010.summary_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742402_1578{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:09,257 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742402_1578{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:09,267 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0010.summary_tmp is closed by DFSClient_NONMAPREDUCE_-100869044_1
2015-07-15 16:51:09,306 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0010-1436950249865-liyaohui-Cluster+Iterator+running+iteration+6+over+priorPat-1436950269207-1-1-SUCCEEDED-default.jhist_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742403_1579{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:09,310 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742403_1579{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:09,318 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0010-1436950249865-liyaohui-Cluster+Iterator+running+iteration+6+over+priorPat-1436950269207-1-1-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-100869044_1
2015-07-15 16:51:09,341 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0010_conf.xml_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742404_1580{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:09,349 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742404_1580{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 16:51:09,349 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0010_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-100869044_1
2015-07-15 16:51:09,352 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742404_1580{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 77730
2015-07-15 16:51:09,755 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0010_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-100869044_1
2015-07-15 16:51:10,844 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742395_1571 127.0.0.1:50010 
2015-07-15 16:51:10,844 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742396_1572 127.0.0.1:50010 
2015-07-15 16:51:10,844 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742397_1573 127.0.0.1:50010 
2015-07-15 16:51:10,844 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742398_1574 127.0.0.1:50010 
2015-07-15 16:51:10,844 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742400_1576 127.0.0.1:50010 
2015-07-15 16:51:10,844 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742399_1575 127.0.0.1:50010 
2015-07-15 16:51:11,140 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/clusters-6/_policy. BP-1159783791-127.0.1.1-1436048545002 blk_1073742405_1581{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:11,147 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742405_1581{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:11,159 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-6/_policy is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:51:11,221 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0011/job.jar. BP-1159783791-127.0.1.1-1436048545002 blk_1073742406_1582{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:11,317 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742400_1576, blk_1073742395_1571, blk_1073742396_1572, blk_1073742397_1573, blk_1073742398_1574, blk_1073742399_1575]
2015-07-15 16:51:11,458 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742406_1582{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:11,868 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0011/job.jar is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:51:11,869 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0011/job.jar
2015-07-15 16:51:11,913 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0011/job.split
2015-07-15 16:51:11,922 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0011/job.split. BP-1159783791-127.0.1.1-1436048545002 blk_1073742407_1583{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:11,926 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742407_1583{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:11,932 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0011/job.split is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:51:11,953 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0011/job.splitmetainfo. BP-1159783791-127.0.1.1-1436048545002 blk_1073742408_1584{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:11,956 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742408_1584{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:11,963 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0011/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:51:11,989 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0011/job.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742409_1585{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:11,993 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742409_1585{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:12,003 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0011/job.xml is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:51:21,175 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0011/job_1436941682764_0011_1_conf.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742410_1586{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:21,227 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742410_1586{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:21,239 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0011/job_1436941682764_0011_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1258274043_1
2015-07-15 16:51:25,824 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0011/job_1436941682764_0011_1.jhist. BP-1159783791-127.0.1.1-1436048545002 blk_1073742411_1587{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:25,830 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0011/job_1436941682764_0011_1.jhist for DFSClient_NONMAPREDUCE_1258274043_1
2015-07-15 16:51:30,501 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/clusters-7/_temporary/1/_temporary/attempt_1436941682764_0011_r_000000_0/part-r-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742412_1588{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:30,546 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742412_1588{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:30,557 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-7/_temporary/1/_temporary/attempt_1436941682764_0011_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1436941682764_0011_r_000000_0_124935017_1
2015-07-15 16:51:30,679 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0011/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_1258274043_1
2015-07-15 16:51:30,740 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-7/_SUCCESS is closed by DFSClient_NONMAPREDUCE_1258274043_1
2015-07-15 16:51:30,760 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0011/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_1258274043_1
2015-07-15 16:51:30,773 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742411_1587{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:30,781 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0011/job_1436941682764_0011_1.jhist is closed by DFSClient_NONMAPREDUCE_1258274043_1
2015-07-15 16:51:30,793 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0011.summary_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742413_1589{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:30,797 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742413_1589{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:30,801 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0011.summary_tmp is closed by DFSClient_NONMAPREDUCE_1258274043_1
2015-07-15 16:51:30,840 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0011-1436950272009-liyaohui-Cluster+Iterator+running+iteration+7+over+priorPat-1436950290761-1-1-SUCCEEDED-default.jhist_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742414_1590{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:30,843 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742414_1590{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:30,852 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0011-1436950272009-liyaohui-Cluster+Iterator+running+iteration+7+over+priorPat-1436950290761-1-1-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_1258274043_1
2015-07-15 16:51:30,887 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0011_conf.xml_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742415_1591{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:30,893 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742415_1591{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:30,903 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0011_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_1258274043_1
2015-07-15 16:51:31,981 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742406_1582 127.0.0.1:50010 
2015-07-15 16:51:31,981 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742407_1583 127.0.0.1:50010 
2015-07-15 16:51:31,981 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742408_1584 127.0.0.1:50010 
2015-07-15 16:51:31,981 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742409_1585 127.0.0.1:50010 
2015-07-15 16:51:31,981 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742411_1587 127.0.0.1:50010 
2015-07-15 16:51:31,981 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742410_1586 127.0.0.1:50010 
2015-07-15 16:51:32,318 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742406_1582, blk_1073742407_1583, blk_1073742408_1584, blk_1073742409_1585, blk_1073742410_1586, blk_1073742411_1587]
2015-07-15 16:51:32,348 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/clusters-7/_policy. BP-1159783791-127.0.1.1-1436048545002 blk_1073742416_1592{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:32,353 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742416_1592{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:32,357 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-7/_policy is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:51:32,410 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0012/job.jar. BP-1159783791-127.0.1.1-1436048545002 blk_1073742417_1593{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:32,662 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742417_1593{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:33,056 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0012/job.jar is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:51:33,057 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0012/job.jar
2015-07-15 16:51:33,100 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0012/job.split
2015-07-15 16:51:33,112 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0012/job.split. BP-1159783791-127.0.1.1-1436048545002 blk_1073742418_1594{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:33,116 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742418_1594{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:33,130 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0012/job.split is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:51:33,151 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0012/job.splitmetainfo. BP-1159783791-127.0.1.1-1436048545002 blk_1073742419_1595{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:33,155 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742419_1595{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:33,161 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0012/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:51:33,187 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0012/job.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742420_1596{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:33,193 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742420_1596{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:33,202 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0012/job.xml is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:51:42,528 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 787 Total time for transactions(ms): 29 Number of transactions batched in Syncs: 4 Number of syncs: 443 SyncTimes(ms): 7535 
2015-07-15 16:51:42,720 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0012/job_1436941682764_0012_1_conf.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742421_1597{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:42,768 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742421_1597{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:42,784 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0012/job_1436941682764_0012_1_conf.xml is closed by DFSClient_NONMAPREDUCE_682002344_1
2015-07-15 16:51:47,415 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0012/job_1436941682764_0012_1.jhist. BP-1159783791-127.0.1.1-1436048545002 blk_1073742422_1598{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:47,437 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0012/job_1436941682764_0012_1.jhist for DFSClient_NONMAPREDUCE_682002344_1
2015-07-15 16:51:52,188 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/clusters-8/_temporary/1/_temporary/attempt_1436941682764_0012_r_000000_0/part-r-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742423_1599{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:52,233 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742423_1599{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:52,244 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-8/_temporary/1/_temporary/attempt_1436941682764_0012_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1436941682764_0012_r_000000_0_829177320_1
2015-07-15 16:51:52,356 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0012/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_682002344_1
2015-07-15 16:51:52,406 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-8/_SUCCESS is closed by DFSClient_NONMAPREDUCE_682002344_1
2015-07-15 16:51:52,427 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0012/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_682002344_1
2015-07-15 16:51:52,440 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742422_1598{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:52,447 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0012/job_1436941682764_0012_1.jhist is closed by DFSClient_NONMAPREDUCE_682002344_1
2015-07-15 16:51:52,471 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0012.summary_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742424_1600{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:52,475 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742424_1600{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:52,488 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0012.summary_tmp is closed by DFSClient_NONMAPREDUCE_682002344_1
2015-07-15 16:51:52,526 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0012-1436950293208-liyaohui-Cluster+Iterator+running+iteration+8+over+priorPat-1436950312428-1-1-SUCCEEDED-default.jhist_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742425_1601{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:52,532 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742425_1601{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:52,539 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0012-1436950293208-liyaohui-Cluster+Iterator+running+iteration+8+over+priorPat-1436950312428-1-1-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_682002344_1
2015-07-15 16:51:52,562 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0012_conf.xml_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742426_1602{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:52,568 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742426_1602{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:52,579 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0012_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_682002344_1
2015-07-15 16:51:53,672 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742417_1593 127.0.0.1:50010 
2015-07-15 16:51:53,672 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742418_1594 127.0.0.1:50010 
2015-07-15 16:51:53,672 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742419_1595 127.0.0.1:50010 
2015-07-15 16:51:53,673 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742420_1596 127.0.0.1:50010 
2015-07-15 16:51:53,673 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742422_1598 127.0.0.1:50010 
2015-07-15 16:51:53,673 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742421_1597 127.0.0.1:50010 
2015-07-15 16:51:54,476 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/clusters-8/_policy. BP-1159783791-127.0.1.1-1436048545002 blk_1073742427_1603{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:54,479 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742427_1603{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:54,492 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-8/_policy is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:51:54,544 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0013/job.jar. BP-1159783791-127.0.1.1-1436048545002 blk_1073742428_1604{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:54,762 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742428_1604{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:55,139 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0013/job.jar is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:51:55,140 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0013/job.jar
2015-07-15 16:51:55,174 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0013/job.split
2015-07-15 16:51:55,184 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0013/job.split. BP-1159783791-127.0.1.1-1436048545002 blk_1073742429_1605{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:55,188 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742429_1605{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:55,194 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0013/job.split is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:51:55,215 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0013/job.splitmetainfo. BP-1159783791-127.0.1.1-1436048545002 blk_1073742430_1606{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:55,218 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742430_1606{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:55,224 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0013/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:51:55,250 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0013/job.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742431_1607{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:51:55,257 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742431_1607{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:51:55,265 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0013/job.xml is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:51:56,320 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742417_1593, blk_1073742418_1594, blk_1073742419_1595, blk_1073742420_1596, blk_1073742421_1597, blk_1073742422_1598]
2015-07-15 16:52:04,337 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0013/job_1436941682764_0013_1_conf.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742432_1608{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:04,424 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742432_1608{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 16:52:04,424 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0013/job_1436941682764_0013_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1136783286_1
2015-07-15 16:52:04,424 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742432_1608{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 77730
2015-07-15 16:52:04,837 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0013/job_1436941682764_0013_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1136783286_1
2015-07-15 16:52:09,001 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0013/job_1436941682764_0013_1.jhist. BP-1159783791-127.0.1.1-1436048545002 blk_1073742433_1609{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:09,010 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0013/job_1436941682764_0013_1.jhist for DFSClient_NONMAPREDUCE_1136783286_1
2015-07-15 16:52:13,694 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/clusters-9/_temporary/1/_temporary/attempt_1436941682764_0013_r_000000_0/part-r-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742434_1610{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:13,738 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742434_1610{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:52:13,747 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-9/_temporary/1/_temporary/attempt_1436941682764_0013_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1436941682764_0013_r_000000_0_-1110897773_1
2015-07-15 16:52:13,880 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0013/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_1136783286_1
2015-07-15 16:52:13,931 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-9/_SUCCESS is closed by DFSClient_NONMAPREDUCE_1136783286_1
2015-07-15 16:52:13,951 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0013/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_1136783286_1
2015-07-15 16:52:13,964 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742433_1609{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:52:13,971 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0013/job_1436941682764_0013_1.jhist is closed by DFSClient_NONMAPREDUCE_1136783286_1
2015-07-15 16:52:13,983 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0013.summary_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742435_1611{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:13,988 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742435_1611{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:52:14,022 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0013.summary_tmp is closed by DFSClient_NONMAPREDUCE_1136783286_1
2015-07-15 16:52:14,060 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0013-1436950315271-liyaohui-Cluster+Iterator+running+iteration+9+over+priorPat-1436950333952-1-1-SUCCEEDED-default.jhist_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742436_1612{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:14,064 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742436_1612{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:52:14,073 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0013-1436950315271-liyaohui-Cluster+Iterator+running+iteration+9+over+priorPat-1436950333952-1-1-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_1136783286_1
2015-07-15 16:52:14,096 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0013_conf.xml_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742437_1613{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:14,101 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742437_1613{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:52:14,114 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0013_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_1136783286_1
2015-07-15 16:52:15,172 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742428_1604 127.0.0.1:50010 
2015-07-15 16:52:15,172 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742429_1605 127.0.0.1:50010 
2015-07-15 16:52:15,172 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742430_1606 127.0.0.1:50010 
2015-07-15 16:52:15,172 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742431_1607 127.0.0.1:50010 
2015-07-15 16:52:15,172 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742433_1609 127.0.0.1:50010 
2015-07-15 16:52:15,172 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742432_1608 127.0.0.1:50010 
2015-07-15 16:52:15,590 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/clusters-9/_policy. BP-1159783791-127.0.1.1-1436048545002 blk_1073742438_1614{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:15,593 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742438_1614{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:52:15,599 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-9/_policy is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:52:15,661 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0014/job.jar. BP-1159783791-127.0.1.1-1436048545002 blk_1073742439_1615{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:15,897 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742439_1615{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-15 16:52:15,897 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0014/job.jar is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:52:15,897 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742439_1615{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 24178445
2015-07-15 16:52:16,311 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0014/job.jar is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:52:16,311 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0014/job.jar
2015-07-15 16:52:16,352 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0014/job.split
2015-07-15 16:52:16,363 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0014/job.split. BP-1159783791-127.0.1.1-1436048545002 blk_1073742440_1616{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:16,368 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742440_1616{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:52:16,372 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0014/job.split is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:52:16,393 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0014/job.splitmetainfo. BP-1159783791-127.0.1.1-1436048545002 blk_1073742441_1617{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:16,396 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742441_1617{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:52:16,402 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0014/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:52:16,428 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0014/job.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742442_1618{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:16,432 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742442_1618{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:52:16,443 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0014/job.xml is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:52:17,321 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742432_1608, blk_1073742433_1609, blk_1073742428_1604, blk_1073742429_1605, blk_1073742430_1606, blk_1073742431_1607]
2015-07-15 16:52:25,869 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0014/job_1436941682764_0014_1_conf.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742443_1619{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:25,919 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742443_1619{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:52:25,934 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0014/job_1436941682764_0014_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-1729382030_1
2015-07-15 16:52:30,606 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0014/job_1436941682764_0014_1.jhist. BP-1159783791-127.0.1.1-1436048545002 blk_1073742444_1620{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:30,614 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0014/job_1436941682764_0014_1.jhist for DFSClient_NONMAPREDUCE_-1729382030_1
2015-07-15 16:52:35,353 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/clusters-10/_temporary/1/_temporary/attempt_1436941682764_0014_r_000000_0/part-r-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742445_1621{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:35,394 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742445_1621{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:52:35,404 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-10/_temporary/1/_temporary/attempt_1436941682764_0014_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1436941682764_0014_r_000000_0_-1558397311_1
2015-07-15 16:52:35,546 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0014/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-1729382030_1
2015-07-15 16:52:35,597 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-10/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1729382030_1
2015-07-15 16:52:35,617 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0014/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1729382030_1
2015-07-15 16:52:35,631 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742444_1620{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:52:35,648 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0014/job_1436941682764_0014_1.jhist is closed by DFSClient_NONMAPREDUCE_-1729382030_1
2015-07-15 16:52:35,660 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0014.summary_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742446_1622{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:35,664 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742446_1622{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:52:35,668 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0014.summary_tmp is closed by DFSClient_NONMAPREDUCE_-1729382030_1
2015-07-15 16:52:35,709 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0014-1436950336452-liyaohui-Cluster+Iterator+running+iteration+10+over+priorPa-1436950355618-1-1-SUCCEEDED-default.jhist_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742447_1623{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:35,713 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742447_1623{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:52:35,719 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0014-1436950336452-liyaohui-Cluster+Iterator+running+iteration+10+over+priorPa-1436950355618-1-1-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-1729382030_1
2015-07-15 16:52:35,743 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0014_conf.xml_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742448_1624{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:35,749 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742448_1624{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:52:35,760 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0014_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-1729382030_1
2015-07-15 16:52:36,818 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742439_1615 127.0.0.1:50010 
2015-07-15 16:52:36,818 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742440_1616 127.0.0.1:50010 
2015-07-15 16:52:36,818 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742441_1617 127.0.0.1:50010 
2015-07-15 16:52:36,818 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742442_1618 127.0.0.1:50010 
2015-07-15 16:52:36,818 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742444_1620 127.0.0.1:50010 
2015-07-15 16:52:36,818 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742443_1619 127.0.0.1:50010 
2015-07-15 16:52:37,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/clusters-10/_policy. BP-1159783791-127.0.1.1-1436048545002 blk_1073742449_1625{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:37,732 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742449_1625{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:52:37,743 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusters-10/_policy is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:52:37,775 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/_policy. BP-1159783791-127.0.1.1-1436048545002 blk_1073742450_1626{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:37,778 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742450_1626{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:52:37,784 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/_policy is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:52:37,836 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0015/job.jar. BP-1159783791-127.0.1.1-1436048545002 blk_1073742451_1627{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:38,058 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742451_1627{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:52:38,322 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742439_1615, blk_1073742440_1616, blk_1073742441_1617, blk_1073742442_1618, blk_1073742443_1619, blk_1073742444_1620]
2015-07-15 16:52:38,371 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0015/job.jar is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:52:38,371 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0015/job.jar
2015-07-15 16:52:38,456 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0015/job.split
2015-07-15 16:52:38,467 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0015/job.split. BP-1159783791-127.0.1.1-1436048545002 blk_1073742452_1628{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:38,471 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742452_1628{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:52:38,476 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0015/job.split is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:52:38,497 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0015/job.splitmetainfo. BP-1159783791-127.0.1.1-1436048545002 blk_1073742453_1629{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:38,501 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742453_1629{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:52:38,506 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0015/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:52:38,532 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0015/job.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742454_1630{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:38,538 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742454_1630{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:52:38,547 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0015/job.xml is closed by DFSClient_NONMAPREDUCE_1302199824_1
2015-07-15 16:52:47,332 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1050 Total time for transactions(ms): 33 Number of transactions batched in Syncs: 6 Number of syncs: 590 SyncTimes(ms): 9568 
2015-07-15 16:52:47,521 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0015/job_1436941682764_0015_1_conf.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742455_1631{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:47,565 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742455_1631{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:52:47,580 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0015/job_1436941682764_0015_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1659948326_1
2015-07-15 16:52:51,878 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/clusteredPoints/_temporary/1/_temporary/attempt_1436941682764_0015_m_000000_0/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742456_1632{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:51,981 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742456_1632{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:52:51,994 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusteredPoints/_temporary/1/_temporary/attempt_1436941682764_0015_m_000000_0/part-m-00000 is closed by DFSClient_attempt_1436941682764_0015_m_000000_0_2144510325_1
2015-07-15 16:52:52,116 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0015/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_1659948326_1
2015-07-15 16:52:52,117 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0015/job_1436941682764_0015_1.jhist. BP-1159783791-127.0.1.1-1436048545002 blk_1073742457_1633{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:52,122 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0015/job_1436941682764_0015_1.jhist for DFSClient_NONMAPREDUCE_1659948326_1
2015-07-15 16:52:52,167 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/clusteredPoints/_SUCCESS is closed by DFSClient_NONMAPREDUCE_1659948326_1
2015-07-15 16:52:52,188 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0015/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_1659948326_1
2015-07-15 16:52:52,205 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742457_1633{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:52:52,228 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1436941682764_0015/job_1436941682764_0015_1.jhist is closed by DFSClient_NONMAPREDUCE_1659948326_1
2015-07-15 16:52:52,241 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0015.summary_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742458_1634{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:52,246 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742458_1634{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:52:52,259 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0015.summary_tmp is closed by DFSClient_NONMAPREDUCE_1659948326_1
2015-07-15 16:52:52,296 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0015-1436950358552-liyaohui-Cluster+Classification+Driver+running+over+input%3A+-1436950372189-1-0-SUCCEEDED-default.jhist_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742459_1635{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:52,299 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742459_1635{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:52:52,310 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0015-1436950358552-liyaohui-Cluster+Classification+Driver+running+over+input%3A+-1436950372189-1-0-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_1659948326_1
2015-07-15 16:52:52,345 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0015_conf.xml_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742460_1636{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-15 16:52:52,352 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742460_1636{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-15 16:52:52,372 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1436941682764_0015_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_1659948326_1
2015-07-15 16:52:53,481 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742451_1627 127.0.0.1:50010 
2015-07-15 16:52:53,481 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742452_1628 127.0.0.1:50010 
2015-07-15 16:52:53,481 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742453_1629 127.0.0.1:50010 
2015-07-15 16:52:53,481 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742454_1630 127.0.0.1:50010 
2015-07-15 16:52:53,481 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742457_1633 127.0.0.1:50010 
2015-07-15 16:52:53,481 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742455_1631 127.0.0.1:50010 
2015-07-15 16:52:56,323 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742451_1627, blk_1073742452_1628, blk_1073742453_1629, blk_1073742454_1630, blk_1073742455_1631, blk_1073742457_1633]
2015-07-15 16:56:19,704 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 16:56:19,718 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:19,718 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:56:19,723 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:19,723 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:56:23,143 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:23,143 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:56:23,148 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:23,148 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:56:26,807 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:26,808 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:56:26,812 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:26,813 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:56:29,372 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:29,372 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:56:29,378 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:29,378 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:56:33,328 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:33,328 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:56:33,333 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:33,333 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:56:35,117 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:35,117 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:56:35,122 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:35,122 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:56:35,150 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:35,150 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:56:35,159 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:35,159 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:56:35,185 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:35,185 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:56:40,136 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:40,137 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:56:40,142 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:40,142 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:56:41,415 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:41,416 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:56:41,420 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:41,421 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:56:41,445 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:41,446 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:56:41,451 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:41,451 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:56:41,456 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:41,456 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:56:41,478 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:41,478 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:56:47,177 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:47,178 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:56:47,182 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:47,183 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:56:47,241 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:47,242 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:56:47,247 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:47,247 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:56:47,253 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:47,253 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 16:56:47,262 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 16:56:47,262 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 17:29:01,360 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-07-15 17:29:01,360 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-07-15 17:29:01,360 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 3128
2015-07-15 17:29:01,360 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1100 Total time for transactions(ms): 35 Number of transactions batched in Syncs: 6 Number of syncs: 620 SyncTimes(ms): 9904 
2015-07-15 17:29:01,381 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1100 Total time for transactions(ms): 35 Number of transactions batched in Syncs: 6 Number of syncs: 621 SyncTimes(ms): 9925 
2015-07-15 17:29:01,382 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000003128 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000003128-0000000000000004227
2015-07-15 17:29:01,382 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4228
2015-07-15 17:29:01,667 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=4227&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 17:29:01,708 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 1833.33 KB/s
2015-07-15 17:29:01,708 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000004227 size 78851 bytes.
2015-07-15 17:29:01,740 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 3127
2015-07-15 17:29:01,740 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000003019, cpktTxId=0000000000000003019)
2015-07-15 18:29:02,030 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-07-15 18:29:02,030 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-07-15 18:29:02,030 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 4228
2015-07-15 18:29:02,031 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 76 
2015-07-15 18:29:02,039 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 84 
2015-07-15 18:29:02,040 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000004228 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004228-0000000000000004229
2015-07-15 18:29:02,040 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4230
2015-07-15 18:29:02,258 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=4229&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 18:29:02,304 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 1711.11 KB/s
2015-07-15 18:29:02,304 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000004229 size 78851 bytes.
2015-07-15 18:29:02,335 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4227
2015-07-15 18:29:02,335 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000003127, cpktTxId=0000000000000003127)
2015-07-15 18:49:06,646 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-15 18:49:06,655 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:06,655 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:06,662 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:06,662 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:07,996 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:07,996 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:08,006 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:08,007 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:09,252 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:09,252 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:09,256 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:09,257 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:10,830 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:10,831 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:10,835 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:10,835 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:13,589 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:13,589 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:13,594 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:13,594 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:14,780 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:14,780 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:14,785 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:14,785 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:14,816 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:14,816 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:14,821 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:14,822 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:14,843 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:14,843 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:21,746 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:21,746 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:21,751 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:21,752 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:23,436 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:23,436 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:23,443 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:23,443 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:23,454 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:23,454 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:23,459 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:23,459 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:23,471 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:23,471 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:26,842 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:26,842 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:26,847 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:26,847 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:28,636 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:28,637 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:28,641 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:28,642 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:28,661 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:28,662 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:28,666 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:28,667 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:28,671 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:28,671 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:49:28,686 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-15 18:49:28,686 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-15 18:56:51,485 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(127.0.0.1, storageID=DS-1927886287-127.0.1.1-50010-1436049057919, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62;nsid=783537164;c=0), blocks: 556, processing time: 9 msecs
2015-07-15 19:29:02,583 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-07-15 19:29:02,583 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-07-15 19:29:02,583 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 4230
2015-07-15 19:29:02,583 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 5 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 56 
2015-07-15 19:29:02,597 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 5 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 70 
2015-07-15 19:29:02,597 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000004230 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004230-0000000000000004234
2015-07-15 19:29:02,597 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4235
2015-07-15 19:29:02,820 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=4234&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 19:29:02,866 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 1673.91 KB/s
2015-07-15 19:29:02,866 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000004234 size 78851 bytes.
2015-07-15 19:29:02,897 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4229
2015-07-15 19:29:02,897 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004227, cpktTxId=0000000000000004227)
2015-07-15 20:29:03,160 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-07-15 20:29:03,160 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-07-15 20:29:03,160 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 4235
2015-07-15 20:29:03,160 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 57 
2015-07-15 20:29:03,166 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 63 
2015-07-15 20:29:03,166 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000004235 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004235-0000000000000004236
2015-07-15 20:29:03,166 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4237
2015-07-15 20:29:03,371 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=4236&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 20:29:03,416 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 1711.11 KB/s
2015-07-15 20:29:03,416 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000004236 size 78851 bytes.
2015-07-15 20:29:03,448 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4234
2015-07-15 20:29:03,448 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004229, cpktTxId=0000000000000004229)
2015-07-15 21:29:03,696 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-07-15 21:29:03,696 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-07-15 21:29:03,696 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 4237
2015-07-15 21:29:03,696 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 66 
2015-07-15 21:29:03,703 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 73 
2015-07-15 21:29:03,703 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000004237 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004237-0000000000000004238
2015-07-15 21:29:03,703 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4239
2015-07-15 21:29:03,953 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=4238&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 21:29:03,990 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 2081.08 KB/s
2015-07-15 21:29:03,990 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000004238 size 78851 bytes.
2015-07-15 21:29:04,021 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4236
2015-07-15 21:29:04,021 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004234, cpktTxId=0000000000000004234)
2015-07-15 22:29:04,290 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-07-15 22:29:04,290 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-07-15 22:29:04,290 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 4239
2015-07-15 22:29:04,290 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 71 
2015-07-15 22:29:04,296 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 77 
2015-07-15 22:29:04,297 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000004239 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004239-0000000000000004240
2015-07-15 22:29:04,297 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4241
2015-07-15 22:29:04,494 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=4240&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-15 22:29:04,546 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 1480.77 KB/s
2015-07-15 22:29:04,546 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000004240 size 78851 bytes.
2015-07-15 22:29:04,577 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4238
2015-07-15 22:29:04,577 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004236, cpktTxId=0000000000000004236)
2015-07-15 22:31:41,975 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2015-07-15 22:31:41,978 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ubuntu01/127.0.1.1
************************************************************/
2015-07-17 21:56:23,062 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-07-17 21:56:23,081 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-07-17 21:56:23,438 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-07-17 21:56:23,719 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-07-17 21:56:23,719 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2015-07-17 21:56:24,016 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-07-17 21:56:24,215 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-07-17 21:56:24,269 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-07-17 21:56:24,271 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2015-07-17 21:56:24,271 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-07-17 21:56:24,271 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-07-17 21:56:24,315 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2015-07-17 21:56:24,365 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2015-07-17 21:56:24,365 INFO org.mortbay.log: jetty-6.1.26
2015-07-17 21:56:24,838 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2015-07-17 21:56:24,839 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2015-07-17 21:56:24,922 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2015-07-17 21:56:24,922 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2015-07-17 21:56:25,008 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2015-07-17 21:56:25,008 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2015-07-17 21:56:25,010 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-07-17 21:56:25,012 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-07-17 21:56:25,012 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-07-17 21:56:25,013 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2015-07-17 21:56:25,013 INFO org.apache.hadoop.util.GSet: capacity      = 2^22 = 4194304 entries
2015-07-17 21:56:25,025 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-07-17 21:56:25,025 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-07-17 21:56:25,025 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-07-17 21:56:25,025 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-07-17 21:56:25,025 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-07-17 21:56:25,025 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-07-17 21:56:25,025 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-07-17 21:56:25,025 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-07-17 21:56:25,031 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = liyaohui (auth:SIMPLE)
2015-07-17 21:56:25,031 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-07-17 21:56:25,031 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-07-17 21:56:25,031 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-07-17 21:56:25,033 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-07-17 21:56:25,613 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-07-17 21:56:25,614 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-07-17 21:56:25,614 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2015-07-17 21:56:25,614 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-07-17 21:56:25,617 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-07-17 21:56:25,621 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-07-17 21:56:25,621 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-07-17 21:56:25,622 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-07-17 21:56:25,623 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2015-07-17 21:56:25,623 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2015-07-17 21:56:25,634 INFO org.apache.hadoop.util.GSet: Computing capacity for map Namenode Retry Cache
2015-07-17 21:56:25,634 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-07-17 21:56:25,634 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory = 889 MB
2015-07-17 21:56:25,634 INFO org.apache.hadoop.util.GSet: capacity      = 2^16 = 65536 entries
2015-07-17 21:56:25,691 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/liyaohui/hadoop/tmp/dfs/name/in_use.lock acquired by nodename 6298@ubuntu01
2015-07-17 21:56:25,764 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/liyaohui/hadoop/tmp/dfs/name/current
2015-07-17 21:56:25,844 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000004241 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004241-0000000000000004241
2015-07-17 21:56:25,895 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004240 using no compression
2015-07-17 21:56:25,896 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 721
2015-07-17 21:56:25,950 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2015-07-17 21:56:25,951 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004240 of size 78851 bytes loaded in 0 seconds.
2015-07-17 21:56:25,951 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 4240 from /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004240
2015-07-17 21:56:25,951 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@669da8 expecting start txid #4241
2015-07-17 21:56:25,951 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004241-0000000000000004241
2015-07-17 21:56:25,953 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004241-0000000000000004241' to transaction ID 4241
2015-07-17 21:56:25,964 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004241-0000000000000004241 of size 1048576 edits # 1 loaded in 0 seconds
2015-07-17 21:56:25,971 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage.ckpt_0000000000000004241 using no compression
2015-07-17 21:56:26,027 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage.ckpt_0000000000000004241 of size 78851 bytes saved in 0 seconds.
2015-07-17 21:56:26,089 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4240
2015-07-17 21:56:26,089 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004238, cpktTxId=0000000000000004238)
2015-07-17 21:56:26,129 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4242
2015-07-17 21:56:26,416 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 6 entries 81 lookups
2015-07-17 21:56:26,416 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 780 msecs
2015-07-17 21:56:26,929 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ubuntu01:9000
2015-07-17 21:56:26,975 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2015-07-17 21:56:27,023 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2015-07-17 21:56:27,042 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2015-07-17 21:56:27,042 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2015-07-17 21:56:27,064 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 556 blocks to reach the threshold 0.9990 of total blocks 556.
Safe mode will be turned off automatically
2015-07-17 21:56:27,102 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-07-17 21:56:27,103 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2015-07-17 21:56:27,113 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ubuntu01/127.0.1.1:9000
2015-07-17 21:56:27,113 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2015-07-17 21:56:29,506 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1, storageID=DS-1927886287-127.0.1.1-50010-1436049057919, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62;nsid=783537164;c=0) storage DS-1927886287-127.0.1.1-50010-1436049057919
2015-07-17 21:56:29,509 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2015-07-17 21:56:29,641 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 555 has reached the threshold 0.9990 of total blocks 556. The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically in 29 seconds.
2015-07-17 21:56:29,641 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2015-07-17 21:56:29,657 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 556
2015-07-17 21:56:29,657 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2015-07-17 21:56:29,657 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 3
2015-07-17 21:56:29,657 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2015-07-17 21:56:29,657 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2015-07-17 21:56:29,657 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 16 msec
2015-07-17 21:56:29,658 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 127.0.0.1:50010 after starting up or becoming active. Its block contents are no longer considered stale
2015-07-17 21:56:29,658 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(127.0.0.1, storageID=DS-1927886287-127.0.1.1-50010-1436049057919, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62;nsid=783537164;c=0), blocks: 556, processing time: 34 msecs
2015-07-17 21:56:49,660 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 556 has reached the threshold 0.9990 of total blocks 556. The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically in 9 seconds.
2015-07-17 21:56:59,661 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 34 secs
2015-07-17 21:56:59,661 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2015-07-17 21:56:59,661 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2015-07-17 21:56:59,661 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 2 blocks
2015-07-17 21:57:33,828 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-07-17 21:57:33,828 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-07-17 21:57:33,828 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 4242
2015-07-17 21:57:33,829 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 71 
2015-07-17 21:57:33,836 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 78 
2015-07-17 21:57:33,837 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000004242 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004242-0000000000000004243
2015-07-17 21:57:33,837 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4244
2015-07-17 21:57:34,506 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=4243&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-17 21:57:34,643 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.14s at 566.18 KB/s
2015-07-17 21:57:34,643 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000004243 size 78851 bytes.
2015-07-17 21:57:34,674 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4241
2015-07-17 21:57:34,674 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004240, cpktTxId=0000000000000004240)
2015-07-17 22:15:54,999 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2015-07-17 22:15:55,003 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ubuntu01/127.0.1.1
************************************************************/
2015-07-27 15:30:47,248 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-07-27 15:30:47,270 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-07-27 15:30:47,589 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-07-27 15:30:47,756 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-07-27 15:30:47,757 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2015-07-27 15:30:47,878 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-07-27 15:30:48,078 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-07-27 15:30:48,130 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-07-27 15:30:48,132 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2015-07-27 15:30:48,132 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-07-27 15:30:48,132 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-07-27 15:30:48,178 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2015-07-27 15:30:48,225 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2015-07-27 15:30:48,225 INFO org.mortbay.log: jetty-6.1.26
2015-07-27 15:30:48,565 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2015-07-27 15:30:48,566 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2015-07-27 15:30:48,652 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2015-07-27 15:30:48,652 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2015-07-27 15:30:48,751 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2015-07-27 15:30:48,751 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2015-07-27 15:30:48,754 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-07-27 15:30:48,757 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-07-27 15:30:48,757 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-07-27 15:30:48,757 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2015-07-27 15:30:48,757 INFO org.apache.hadoop.util.GSet: capacity      = 2^22 = 4194304 entries
2015-07-27 15:30:48,769 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-07-27 15:30:48,770 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-07-27 15:30:48,770 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-07-27 15:30:48,770 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-07-27 15:30:48,770 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-07-27 15:30:48,770 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-07-27 15:30:48,770 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-07-27 15:30:48,770 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-07-27 15:30:48,776 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = liyaohui (auth:SIMPLE)
2015-07-27 15:30:48,776 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-07-27 15:30:48,776 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-07-27 15:30:48,776 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-07-27 15:30:48,778 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-07-27 15:30:49,089 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-07-27 15:30:49,089 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-07-27 15:30:49,089 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2015-07-27 15:30:49,089 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-07-27 15:30:49,092 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-07-27 15:30:49,097 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-07-27 15:30:49,097 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-07-27 15:30:49,097 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-07-27 15:30:49,098 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2015-07-27 15:30:49,098 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2015-07-27 15:30:49,110 INFO org.apache.hadoop.util.GSet: Computing capacity for map Namenode Retry Cache
2015-07-27 15:30:49,110 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-07-27 15:30:49,110 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory = 889 MB
2015-07-27 15:30:49,110 INFO org.apache.hadoop.util.GSet: capacity      = 2^16 = 65536 entries
2015-07-27 15:30:49,159 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/liyaohui/hadoop/tmp/dfs/name/in_use.lock acquired by nodename 2829@ubuntu01
2015-07-27 15:30:49,240 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/liyaohui/hadoop/tmp/dfs/name/current
2015-07-27 15:30:49,295 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000004244 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004244-0000000000000004244
2015-07-27 15:30:49,332 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004243 using no compression
2015-07-27 15:30:49,332 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 721
2015-07-27 15:30:49,387 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2015-07-27 15:30:49,387 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004243 of size 78851 bytes loaded in 0 seconds.
2015-07-27 15:30:49,387 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 4243 from /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004243
2015-07-27 15:30:49,387 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@669da8 expecting start txid #4244
2015-07-27 15:30:49,387 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004244-0000000000000004244
2015-07-27 15:30:49,390 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004244-0000000000000004244' to transaction ID 4244
2015-07-27 15:30:49,399 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004244-0000000000000004244 of size 1048576 edits # 1 loaded in 0 seconds
2015-07-27 15:30:49,406 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage.ckpt_0000000000000004244 using no compression
2015-07-27 15:30:49,465 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage.ckpt_0000000000000004244 of size 78851 bytes saved in 0 seconds.
2015-07-27 15:30:49,524 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4243
2015-07-27 15:30:49,525 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004241, cpktTxId=0000000000000004241)
2015-07-27 15:30:49,565 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4245
2015-07-27 15:30:49,874 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 6 entries 81 lookups
2015-07-27 15:30:49,874 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 762 msecs
2015-07-27 15:30:50,343 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ubuntu01:9000
2015-07-27 15:30:50,376 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2015-07-27 15:30:50,416 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2015-07-27 15:30:50,446 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2015-07-27 15:30:50,447 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2015-07-27 15:30:50,458 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 556 blocks to reach the threshold 0.9990 of total blocks 556.
Safe mode will be turned off automatically
2015-07-27 15:30:50,479 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-07-27 15:30:50,479 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2015-07-27 15:30:50,482 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ubuntu01/127.0.1.1:9000
2015-07-27 15:30:50,482 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2015-07-27 15:30:53,633 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1, storageID=DS-1927886287-127.0.1.1-50010-1436049057919, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62;nsid=783537164;c=0) storage DS-1927886287-127.0.1.1-50010-1436049057919
2015-07-27 15:30:53,635 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2015-07-27 15:30:53,771 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 555 has reached the threshold 0.9990 of total blocks 556. The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically in 29 seconds.
2015-07-27 15:30:53,771 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2015-07-27 15:30:53,788 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 556
2015-07-27 15:30:53,788 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2015-07-27 15:30:53,788 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 3
2015-07-27 15:30:53,788 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2015-07-27 15:30:53,788 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2015-07-27 15:30:53,788 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 17 msec
2015-07-27 15:30:53,788 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 127.0.0.1:50010 after starting up or becoming active. Its block contents are no longer considered stale
2015-07-27 15:30:53,788 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(127.0.0.1, storageID=DS-1927886287-127.0.1.1-50010-1436049057919, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62;nsid=783537164;c=0), blocks: 556, processing time: 29 msecs
2015-07-27 15:31:13,791 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 556 has reached the threshold 0.9990 of total blocks 556. The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically in 9 seconds.
2015-07-27 15:31:23,792 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 35 secs
2015-07-27 15:31:23,792 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2015-07-27 15:31:23,792 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2015-07-27 15:31:23,792 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 2 blocks
2015-07-27 15:31:58,071 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-07-27 15:31:58,072 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-07-27 15:31:58,072 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 4245
2015-07-27 15:31:58,072 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 75 
2015-07-27 15:31:58,086 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 89 
2015-07-27 15:31:58,087 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000004245 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004245-0000000000000004246
2015-07-27 15:31:58,088 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4247
2015-07-27 15:31:58,765 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=4246&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-27 15:31:58,908 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.14s at 542.25 KB/s
2015-07-27 15:31:58,908 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000004246 size 78851 bytes.
2015-07-27 15:31:58,939 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4244
2015-07-27 15:31:58,940 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004243, cpktTxId=0000000000000004243)
2015-07-27 16:31:59,401 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-07-27 16:31:59,401 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-07-27 16:31:59,401 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 4247
2015-07-27 16:31:59,401 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 73 
2015-07-27 16:31:59,413 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 85 
2015-07-27 16:31:59,414 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000004247 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004247-0000000000000004249
2015-07-27 16:31:59,414 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4250
2015-07-27 16:31:59,620 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=4249&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-27 16:31:59,658 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 2081.08 KB/s
2015-07-27 16:31:59,658 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000004249 size 78851 bytes.
2015-07-27 16:31:59,689 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4246
2015-07-27 16:31:59,689 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004244, cpktTxId=0000000000000004244)
2015-07-27 16:51:02,772 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(127.0.0.1, storageID=DS-1927886287-127.0.1.1-50010-1436049057919, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62;nsid=783537164;c=0), blocks: 556, processing time: 3 msecs
2015-07-27 16:58:09,359 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 56 
2015-07-27 16:58:09,421 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /shuju._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742461_1637{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-27 16:58:09,566 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742461_1637{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-07-27 16:58:09,566 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742461_1637{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 109
2015-07-27 16:58:09,574 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /shuju._COPYING_ is closed by DFSClient_NONMAPREDUCE_523359162_1
2015-07-27 16:58:09,991 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /shuju._COPYING_ is closed by DFSClient_NONMAPREDUCE_523359162_1
2015-07-27 16:58:32,782 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-07-27 16:58:33,174 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 16:58:33,176 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 16:58:33,198 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 16:58:33,198 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 16:58:35,351 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 16:58:35,351 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 16:58:35,360 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 16:58:35,360 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 16:58:35,411 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 16:58:35,411 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 16:58:35,418 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 16:58:35,418 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 16:58:35,424 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 16:58:35,425 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 16:58:35,460 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 16:58:35,460 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:05:23,450 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:05:23,450 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:05:23,460 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:05:23,460 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:05:23,522 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:05:23,523 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:05:23,528 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:05:23,529 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:05:23,534 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:05:23,535 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:05:23,556 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:05:23,556 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:05:27,352 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:05:27,352 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:05:27,361 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:05:27,361 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:07:00,827 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:07:00,828 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:07:00,833 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:07:00,833 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:07:02,357 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:07:02,357 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:07:02,364 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:07:02,365 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:07:02,388 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:07:02,389 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:07:02,394 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:07:02,395 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:07:02,462 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:07:02,463 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:10:09,333 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:10:09,334 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:10:09,339 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:10:09,339 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:10:11,300 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:10:11,300 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:10:11,308 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:10:11,308 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:13:34,249 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:13:34,249 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:13:34,255 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:13:34,255 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:13:34,274 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:13:34,274 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:13:34,283 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:13:34,283 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:13:34,291 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:13:34,291 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:13:34,303 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:13:34,303 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:14:00,389 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:14:00,389 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:14:00,395 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:14:00,395 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:14:03,525 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:14:03,525 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:14:03,531 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:14:03,531 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:14:03,544 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:14:03,544 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:14:03,550 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:14:03,550 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:14:03,555 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:14:03,556 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:14:03,567 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:14:03,568 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:17:20,547 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 10 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 6 SyncTimes(ms): 98 
2015-07-27 17:17:27,241 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:17:27,241 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:17:27,247 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:17:27,248 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:17:28,859 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:17:28,860 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:17:28,865 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:17:28,867 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:18:25,538 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 11 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 7 SyncTimes(ms): 103 
2015-07-27 17:18:25,582 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /input/shuju._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742462_1638{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-27 17:18:25,688 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742462_1638{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-27 17:18:25,704 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /input/shuju._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1445173370_1
2015-07-27 17:18:30,569 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:18:30,570 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:18:30,575 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:18:30,575 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:18:32,112 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:18:32,113 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:18:32,118 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:18:32,118 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:25:07,182 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 19 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 10 SyncTimes(ms): 127 
2015-07-27 17:25:07,547 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /output/_temporary/0/_temporary/attempt_local1735814906_0001_r_000000_0/part-r-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742463_1639{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-07-27 17:25:07,592 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742463_1639{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-07-27 17:25:07,598 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /output/_temporary/0/_temporary/attempt_local1735814906_0001_r_000000_0/part-r-00000 is closed by DFSClient_NONMAPREDUCE_881102406_1
2015-07-27 17:25:07,689 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /output/_SUCCESS is closed by DFSClient_NONMAPREDUCE_881102406_1
2015-07-27 17:25:19,143 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:25:19,144 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:25:19,150 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:25:19,150 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:25:27,761 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:25:27,761 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:25:27,769 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:25:27,769 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:25:29,928 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:25:29,929 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:25:29,935 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:25:29,935 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:25:31,510 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:25:31,510 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:25:31,515 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:25:31,516 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:25:31,579 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:25:31,580 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:25:31,586 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:25:31,586 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:25:31,592 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:25:31,592 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:25:31,603 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:25:31,603 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:27:09,122 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:27:09,123 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:27:09,133 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-07-27 17:27:09,134 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-07-27 17:32:00,014 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-07-27 17:32:00,014 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-07-27 17:32:00,014 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 4250
2015-07-27 17:32:00,014 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 32 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 18 SyncTimes(ms): 196 
2015-07-27 17:32:00,020 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 32 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 19 SyncTimes(ms): 202 
2015-07-27 17:32:00,021 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000004250 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004250-0000000000000004281
2015-07-27 17:32:00,021 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4282
2015-07-27 17:32:00,262 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=4281&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-27 17:32:00,309 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 1638.30 KB/s
2015-07-27 17:32:00,309 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000004281 size 79436 bytes.
2015-07-27 17:32:00,340 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4249
2015-07-27 17:32:00,340 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004246, cpktTxId=0000000000000004246)
2015-07-27 18:32:00,655 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-07-27 18:32:00,656 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-07-27 18:32:00,656 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 4282
2015-07-27 18:32:00,656 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 78 
2015-07-27 18:32:00,680 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 101 
2015-07-27 18:32:00,680 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000004282 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004282-0000000000000004284
2015-07-27 18:32:00,680 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4285
2015-07-27 18:32:00,883 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=4284&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-27 18:32:00,925 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 1878.05 KB/s
2015-07-27 18:32:00,925 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000004284 size 79436 bytes.
2015-07-27 18:32:00,956 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4281
2015-07-27 18:32:00,956 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004249, cpktTxId=0000000000000004249)
2015-07-27 19:32:01,269 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-07-27 19:32:01,269 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-07-27 19:32:01,269 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 4285
2015-07-27 19:32:01,269 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 66 
2015-07-27 19:32:01,277 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 74 
2015-07-27 19:32:01,278 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000004285 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004285-0000000000000004286
2015-07-27 19:32:01,278 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4287
2015-07-27 19:32:01,485 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=4286&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-27 19:32:01,514 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.03s at 2655.17 KB/s
2015-07-27 19:32:01,514 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000004286 size 79436 bytes.
2015-07-27 19:32:01,545 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4284
2015-07-27 19:32:01,545 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004281, cpktTxId=0000000000000004281)
2015-07-27 20:32:01,811 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-07-27 20:32:01,811 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-07-27 20:32:01,811 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 4287
2015-07-27 20:32:01,811 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 64 
2015-07-27 20:32:01,822 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 75 
2015-07-27 20:32:01,822 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000004287 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004287-0000000000000004288
2015-07-27 20:32:01,822 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4289
2015-07-27 20:32:02,015 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=4288&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-27 20:32:02,056 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 1833.33 KB/s
2015-07-27 20:32:02,056 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000004288 size 79436 bytes.
2015-07-27 20:32:02,088 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4286
2015-07-27 20:32:02,088 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004284, cpktTxId=0000000000000004284)
2015-07-27 21:32:02,347 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-07-27 21:32:02,347 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-07-27 21:32:02,347 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 4289
2015-07-27 21:32:02,348 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 56 
2015-07-27 21:32:02,358 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 66 
2015-07-27 21:32:02,359 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000004289 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004289-0000000000000004290
2015-07-27 21:32:02,359 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4291
2015-07-27 21:32:02,575 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=4290&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-07-27 21:32:02,618 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 1833.33 KB/s
2015-07-27 21:32:02,618 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000004290 size 79436 bytes.
2015-07-27 21:32:02,650 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4288
2015-07-27 21:32:02,650 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004286, cpktTxId=0000000000000004286)
2015-07-27 21:50:55,726 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2015-07-27 21:50:55,732 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ubuntu01/127.0.1.1
************************************************************/
2015-08-25 16:42:40,871 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-08-25 16:42:40,894 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-08-25 16:42:41,280 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-08-25 16:42:41,774 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-08-25 16:42:41,774 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2015-08-25 16:42:41,984 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-08-25 16:42:42,284 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-08-25 16:42:42,378 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-08-25 16:42:42,380 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2015-08-25 16:42:42,380 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-08-25 16:42:42,380 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-08-25 16:42:42,499 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2015-08-25 16:42:42,627 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2015-08-25 16:42:42,628 INFO org.mortbay.log: jetty-6.1.26
2015-08-25 16:42:43,401 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2015-08-25 16:42:43,402 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2015-08-25 16:42:43,555 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2015-08-25 16:42:43,555 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2015-08-25 16:42:43,767 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2015-08-25 16:42:43,767 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2015-08-25 16:42:43,769 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-08-25 16:42:43,772 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-08-25 16:42:43,772 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-08-25 16:42:43,773 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2015-08-25 16:42:43,773 INFO org.apache.hadoop.util.GSet: capacity      = 2^22 = 4194304 entries
2015-08-25 16:42:43,787 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-08-25 16:42:43,787 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-08-25 16:42:43,787 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-08-25 16:42:43,788 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-08-25 16:42:43,788 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-08-25 16:42:43,788 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-08-25 16:42:43,788 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-08-25 16:42:43,788 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-08-25 16:42:43,794 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = liyaohui (auth:SIMPLE)
2015-08-25 16:42:43,794 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-08-25 16:42:43,794 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-08-25 16:42:43,794 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-08-25 16:42:43,796 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-08-25 16:42:44,735 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-08-25 16:42:44,735 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-08-25 16:42:44,736 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2015-08-25 16:42:44,736 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-08-25 16:42:44,739 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-08-25 16:42:44,743 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-08-25 16:42:44,743 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-08-25 16:42:44,743 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-08-25 16:42:44,744 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2015-08-25 16:42:44,744 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2015-08-25 16:42:44,777 INFO org.apache.hadoop.util.GSet: Computing capacity for map Namenode Retry Cache
2015-08-25 16:42:44,777 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-08-25 16:42:44,777 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory = 889 MB
2015-08-25 16:42:44,777 INFO org.apache.hadoop.util.GSet: capacity      = 2^16 = 65536 entries
2015-08-25 16:42:44,902 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/liyaohui/hadoop/tmp/dfs/name/in_use.lock acquired by nodename 2456@ubuntu01
2015-08-25 16:42:45,052 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/liyaohui/hadoop/tmp/dfs/name/current
2015-08-25 16:42:45,224 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000004291 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004291-0000000000000004291
2015-08-25 16:42:45,271 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004290 using no compression
2015-08-25 16:42:45,272 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 727
2015-08-25 16:42:45,334 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2015-08-25 16:42:45,334 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004290 of size 79436 bytes loaded in 0 seconds.
2015-08-25 16:42:45,334 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 4290 from /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004290
2015-08-25 16:42:45,335 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@669da8 expecting start txid #4291
2015-08-25 16:42:45,335 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004291-0000000000000004291
2015-08-25 16:42:45,337 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004291-0000000000000004291' to transaction ID 4291
2015-08-25 16:42:45,360 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004291-0000000000000004291 of size 1048576 edits # 1 loaded in 0 seconds
2015-08-25 16:42:45,371 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage.ckpt_0000000000000004291 using no compression
2015-08-25 16:42:45,488 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage.ckpt_0000000000000004291 of size 79436 bytes saved in 0 seconds.
2015-08-25 16:42:45,587 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4290
2015-08-25 16:42:45,588 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004288, cpktTxId=0000000000000004288)
2015-08-25 16:42:45,751 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4292
2015-08-25 16:42:46,123 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 6 entries 83 lookups
2015-08-25 16:42:46,123 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 1345 msecs
2015-08-25 16:42:46,839 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ubuntu01:9000
2015-08-25 16:42:46,892 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2015-08-25 16:42:46,930 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2015-08-25 16:42:46,968 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2015-08-25 16:42:46,968 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2015-08-25 16:42:46,985 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 559 blocks to reach the threshold 0.9990 of total blocks 559.
Safe mode will be turned off automatically
2015-08-25 16:42:47,012 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2015-08-25 16:42:47,007 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-08-25 16:42:47,021 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ubuntu01/127.0.1.1:9000
2015-08-25 16:42:47,021 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2015-08-25 16:42:48,209 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1, storageID=DS-1927886287-127.0.1.1-50010-1436049057919, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62;nsid=783537164;c=0) storage DS-1927886287-127.0.1.1-50010-1436049057919
2015-08-25 16:42:48,211 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2015-08-25 16:42:48,330 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 558 has reached the threshold 0.9990 of total blocks 559. The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically in 29 seconds.
2015-08-25 16:42:48,330 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2015-08-25 16:42:48,346 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 559
2015-08-25 16:42:48,346 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2015-08-25 16:42:48,346 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 3
2015-08-25 16:42:48,346 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2015-08-25 16:42:48,346 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2015-08-25 16:42:48,346 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 16 msec
2015-08-25 16:42:48,346 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 127.0.0.1:50010 after starting up or becoming active. Its block contents are no longer considered stale
2015-08-25 16:42:48,347 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(127.0.0.1, storageID=DS-1927886287-127.0.1.1-50010-1436049057919, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62;nsid=783537164;c=0), blocks: 559, processing time: 28 msecs
2015-08-25 16:43:08,349 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 559 has reached the threshold 0.9990 of total blocks 559. The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically in 9 seconds.
2015-08-25 16:43:15,158 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:dr.who (auth:SIMPLE) cause:org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot issue delegation token. Name node is in safe mode.
The reported blocks 559 has reached the threshold 0.9990 of total blocks 559. The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically in 3 seconds.
2015-08-25 16:43:15,158 WARN org.mortbay.log: /nn_browsedfscontent.jsp: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot issue delegation token. Name node is in safe mode.
The reported blocks 559 has reached the threshold 0.9990 of total blocks 559. The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically in 3 seconds.
2015-08-25 16:43:18,350 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 34 secs
2015-08-25 16:43:18,350 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2015-08-25 16:43:18,351 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2015-08-25 16:43:18,351 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 3 blocks
2015-08-25 16:43:20,366 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-08-25 16:43:20,824 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:20,825 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:20,854 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:20,854 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:25,764 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:25,765 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:25,772 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:25,772 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:29,129 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:29,129 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:29,147 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:29,148 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:29,249 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:29,250 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:29,257 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:29,257 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:29,455 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:29,456 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:36,717 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:36,718 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:36,723 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:36,724 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:38,236 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:38,236 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:38,243 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:38,243 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:40,226 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:40,226 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:40,231 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:40,231 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:44,342 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:44,342 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:44,349 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:44,350 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:46,823 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:46,823 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:46,830 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:46,830 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:46,850 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:46,850 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:46,856 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:46,856 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:46,870 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:46,870 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:46,919 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:46,920 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:51,583 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-08-25 16:43:51,583 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-08-25 16:43:51,583 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 4292
2015-08-25 16:43:51,583 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 128 
2015-08-25 16:43:51,595 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 140 
2015-08-25 16:43:51,597 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000004292 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004292-0000000000000004295
2015-08-25 16:43:51,597 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4296
2015-08-25 16:43:52,194 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=4295&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-08-25 16:43:52,336 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.14s at 542.25 KB/s
2015-08-25 16:43:52,336 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000004295 size 79436 bytes.
2015-08-25 16:43:52,368 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4291
2015-08-25 16:43:52,368 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004290, cpktTxId=0000000000000004290)
2015-08-25 16:43:57,755 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:57,756 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:57,760 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:57,761 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:59,295 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:59,296 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:59,301 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:59,301 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:59,317 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:59,317 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:59,327 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:59,327 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:59,333 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:59,333 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 16:43:59,404 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 16:43:59,404 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:02:39,068 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-08-25 17:02:39,078 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:02:39,078 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:02:39,083 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:02:39,083 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:02:41,854 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:02:41,854 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:02:41,859 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:02:41,860 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:02:43,717 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:02:43,717 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:02:43,722 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:02:43,723 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:02:49,086 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:02:49,087 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:02:49,092 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:02:49,092 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:02:50,352 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:02:50,352 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:02:50,358 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:02:50,358 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:07:10,604 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:07:10,604 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:07:10,610 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:07:10,610 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:07:11,661 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:07:11,661 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:07:11,668 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:07:11,668 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:07:12,540 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:07:12,541 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:07:12,546 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:07:12,546 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:07:13,332 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:07:13,332 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:07:13,338 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:07:13,339 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:07:16,262 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:07:16,263 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:07:16,271 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:07:16,272 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:07:35,686 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 58 
2015-08-25 17:07:35,754 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/testdata/test1.csv._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742464_1640{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:07:35,878 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742464_1640{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:07:35,894 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/testdata/test1.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1380219266_1
2015-08-25 17:07:40,309 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:07:40,309 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:07:40,315 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:07:40,316 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:07:42,230 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:07:42,230 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:07:42,235 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:07:42,236 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:07:42,248 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:07:42,249 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:07:42,255 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:07:42,255 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:07:42,277 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:07:42,278 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:11:51,427 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 9 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 95 
2015-08-25 17:11:51,727 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742450_1626 127.0.0.1:50010 
2015-08-25 17:11:51,727 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742456_1632 127.0.0.1:50010 
2015-08-25 17:11:51,727 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742333_1509 127.0.0.1:50010 
2015-08-25 17:11:51,727 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742334_1510 127.0.0.1:50010 
2015-08-25 17:11:51,727 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742335_1511 127.0.0.1:50010 
2015-08-25 17:11:51,727 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742336_1512 127.0.0.1:50010 
2015-08-25 17:11:51,727 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742337_1513 127.0.0.1:50010 
2015-08-25 17:11:51,727 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742338_1514 127.0.0.1:50010 
2015-08-25 17:11:51,727 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742339_1515 127.0.0.1:50010 
2015-08-25 17:11:51,727 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742350_1526 127.0.0.1:50010 
2015-08-25 17:11:51,727 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742346_1522 127.0.0.1:50010 
2015-08-25 17:11:51,727 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742449_1625 127.0.0.1:50010 
2015-08-25 17:11:51,728 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742445_1621 127.0.0.1:50010 
2015-08-25 17:11:51,728 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742361_1537 127.0.0.1:50010 
2015-08-25 17:11:51,728 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742357_1533 127.0.0.1:50010 
2015-08-25 17:11:51,728 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742372_1548 127.0.0.1:50010 
2015-08-25 17:11:51,728 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742368_1544 127.0.0.1:50010 
2015-08-25 17:11:51,728 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742383_1559 127.0.0.1:50010 
2015-08-25 17:11:51,728 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742379_1555 127.0.0.1:50010 
2015-08-25 17:11:51,728 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742394_1570 127.0.0.1:50010 
2015-08-25 17:11:51,728 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742390_1566 127.0.0.1:50010 
2015-08-25 17:11:51,728 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742405_1581 127.0.0.1:50010 
2015-08-25 17:11:51,728 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742401_1577 127.0.0.1:50010 
2015-08-25 17:11:51,728 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742416_1592 127.0.0.1:50010 
2015-08-25 17:11:51,728 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742412_1588 127.0.0.1:50010 
2015-08-25 17:11:51,728 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742427_1603 127.0.0.1:50010 
2015-08-25 17:11:51,728 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742423_1599 127.0.0.1:50010 
2015-08-25 17:11:51,728 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742438_1614 127.0.0.1:50010 
2015-08-25 17:11:51,728 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742434_1610 127.0.0.1:50010 
2015-08-25 17:11:51,728 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742327_1503 127.0.0.1:50010 
2015-08-25 17:11:51,728 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742332_1508 127.0.0.1:50010 
2015-08-25 17:11:52,322 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0001/job.jar. BP-1159783791-127.0.1.1-1436048545002 blk_1073742465_1641{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:11:52,574 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742465_1641{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:11:52,710 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0001/job.jar is closed by DFSClient_NONMAPREDUCE_869764471_1
2015-08-25 17:11:52,718 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0001/job.jar
2015-08-25 17:11:53,103 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0001/job.split
2015-08-25 17:11:53,114 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742336_1512, blk_1073742337_1513, blk_1073742401_1577, blk_1073742338_1514, blk_1073742339_1515, blk_1073742405_1581, blk_1073742346_1522, blk_1073742412_1588, blk_1073742350_1526, blk_1073742416_1592, blk_1073742357_1533, blk_1073742423_1599, blk_1073742361_1537, blk_1073742427_1603, blk_1073742368_1544, blk_1073742434_1610, blk_1073742372_1548, blk_1073742438_1614, blk_1073742379_1555, blk_1073742445_1621, blk_1073742383_1559, blk_1073742449_1625, blk_1073742450_1626, blk_1073742390_1566, blk_1073742327_1503, blk_1073742456_1632, blk_1073742394_1570, blk_1073742332_1508, blk_1073742333_1509, blk_1073742334_1510, blk_1073742335_1511]
2015-08-25 17:11:53,233 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0001/job.split. BP-1159783791-127.0.1.1-1436048545002 blk_1073742466_1642{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:11:53,240 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742466_1642{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-08-25 17:11:53,240 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0001/job.split is closed by DFSClient_NONMAPREDUCE_869764471_1
2015-08-25 17:11:53,240 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742466_1642{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 260
2015-08-25 17:11:53,651 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0001/job.split is closed by DFSClient_NONMAPREDUCE_869764471_1
2015-08-25 17:11:53,675 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0001/job.splitmetainfo. BP-1159783791-127.0.1.1-1436048545002 blk_1073742467_1643{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:11:53,680 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742467_1643{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:11:53,692 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0001/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_869764471_1
2015-08-25 17:11:53,810 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0001/job.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742468_1644{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:11:53,816 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742468_1644{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:11:53,824 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0001/job.xml is closed by DFSClient_NONMAPREDUCE_869764471_1
2015-08-25 17:12:00,095 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0001/job_1440492175555_0001_1_conf.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742469_1645{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:12:00,157 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742469_1645{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:12:00,172 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0001/job_1440492175555_0001_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-2080928413_1
2015-08-25 17:12:05,074 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0001_m_000000_0/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742470_1646{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:12:05,136 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742470_1646{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:12:05,146 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0001_m_000000_0/part-m-00000 is closed by DFSClient_attempt_1440492175555_0001_m_000000_0_867152584_1
2015-08-25 17:12:05,166 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742470_1646 127.0.0.1:50010 
2015-08-25 17:12:05,236 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0001/job_1440492175555_0001_1.jhist. BP-1159783791-127.0.1.1-1436048545002 blk_1073742471_1647{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:12:05,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0001/job_1440492175555_0001_1.jhist for DFSClient_NONMAPREDUCE_-2080928413_1
2015-08-25 17:12:05,322 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0001_m_000001_0/part-m-00001. BP-1159783791-127.0.1.1-1436048545002 blk_1073742472_1648{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:12:05,428 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742472_1648{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:12:05,451 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0001_m_000001_0/part-m-00001 is closed by DFSClient_attempt_1440492175555_0001_m_000001_0_-1763369799_1
2015-08-25 17:12:08,115 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742470_1646]
2015-08-25 17:12:09,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0001_m_000000_1/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742473_1649{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:12:09,308 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742473_1649{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:12:09,316 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0001_m_000000_1/part-m-00000 is closed by DFSClient_attempt_1440492175555_0001_m_000000_1_455189910_1
2015-08-25 17:12:09,337 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742473_1649 127.0.0.1:50010 
2015-08-25 17:12:11,115 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742473_1649]
2015-08-25 17:12:13,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0001_m_000000_2/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742474_1650{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:12:13,248 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742474_1650{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:12:13,253 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0001_m_000000_2/part-m-00000 is closed by DFSClient_attempt_1440492175555_0001_m_000000_2_-318202956_1
2015-08-25 17:12:13,273 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742474_1650 127.0.0.1:50010 
2015-08-25 17:12:14,116 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742474_1650]
2015-08-25 17:12:18,332 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0001_m_000000_3/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742475_1651{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:12:18,371 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742475_1651{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:12:18,379 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0001_m_000000_3/part-m-00000 is closed by DFSClient_attempt_1440492175555_0001_m_000000_3_-815318881_1
2015-08-25 17:12:18,400 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742475_1651 127.0.0.1:50010 
2015-08-25 17:12:18,430 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742472_1648 127.0.0.1:50010 
2015-08-25 17:12:18,441 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742471_1647{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:12:18,451 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0001/job_1440492175555_0001_1.jhist is closed by DFSClient_NONMAPREDUCE_-2080928413_1
2015-08-25 17:12:18,463 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0001.summary_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742476_1652{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:12:18,468 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742476_1652{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:12:18,481 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0001.summary_tmp is closed by DFSClient_NONMAPREDUCE_-2080928413_1
2015-08-25 17:12:18,533 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0001-1440493914017-liyaohui-Input+Driver+running+over+input%3A+testdata-1440493938420-1-0-FAILED-default.jhist_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742477_1653{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:12:18,538 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742477_1653{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:12:18,559 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0001-1440493914017-liyaohui-Input+Driver+running+over+input%3A+testdata-1440493938420-1-0-FAILED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-2080928413_1
2015-08-25 17:12:18,591 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0001_conf.xml_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742478_1654{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:12:18,598 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742478_1654{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:12:18,603 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0001_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-2080928413_1
2015-08-25 17:12:18,675 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742465_1641 127.0.0.1:50010 
2015-08-25 17:12:18,675 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742466_1642 127.0.0.1:50010 
2015-08-25 17:12:18,675 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742467_1643 127.0.0.1:50010 
2015-08-25 17:12:18,675 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742468_1644 127.0.0.1:50010 
2015-08-25 17:12:18,675 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742471_1647 127.0.0.1:50010 
2015-08-25 17:12:18,675 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742469_1645 127.0.0.1:50010 
2015-08-25 17:12:20,116 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742465_1641, blk_1073742466_1642, blk_1073742467_1643, blk_1073742468_1644, blk_1073742469_1645, blk_1073742471_1647, blk_1073742472_1648, blk_1073742475_1651]
2015-08-25 17:13:05,832 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-08-25 17:13:05,842 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:05,842 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:05,870 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:05,871 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:07,535 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:07,535 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:07,541 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:07,541 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:08,736 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:08,736 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:08,741 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:08,741 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:10,113 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:10,114 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:10,119 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:10,119 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:11,357 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:11,357 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:11,362 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:11,362 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:17,890 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:17,890 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:17,895 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:17,895 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:25,648 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:25,648 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:25,655 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:25,655 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:28,639 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:28,640 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:28,645 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:28,645 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:32,320 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:32,320 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:32,326 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:32,326 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:40,008 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:40,009 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:40,013 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:40,014 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:48,000 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:48,000 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:48,008 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:48,008 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:49,481 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:49,481 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:49,487 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:49,487 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:49,498 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:49,499 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:49,504 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:49,504 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:49,511 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:49,512 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:49,522 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:49,523 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:57,929 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:57,929 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:13:57,934 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:13:57,934 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:14:00,066 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:14:00,066 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:14:00,071 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:14:00,071 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:14:07,633 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:14:07,634 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:14:07,639 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:14:07,639 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:14:08,937 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:14:08,937 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:14:08,942 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:14:08,943 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:14:13,426 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:14:13,426 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:14:13,431 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:14:13,431 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:14:21,842 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:14:21,842 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:14:21,851 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:14:21,852 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:14:21,901 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:14:21,902 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:14:21,908 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:14:21,908 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:14:21,924 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:14:21,924 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:15:58,897 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:15:58,898 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:15:58,903 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:15:58,903 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:16:02,084 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:16:02,084 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:16:02,091 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:16:02,092 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:16:05,789 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:16:05,789 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:16:05,794 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:16:05,794 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:16:05,818 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:16:05,819 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:16:05,824 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:16:05,825 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:16:05,838 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:16:05,838 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:16:53,412 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 114 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 1 Number of syncs: 57 SyncTimes(ms): 1266 
2015-08-25 17:16:53,419 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742321_1497 127.0.0.1:50010 
2015-08-25 17:16:56,133 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742321_1497]
2015-08-25 17:16:58,048 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:16:58,049 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:16:58,057 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:16:58,058 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:17:10,665 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0002/job.jar. BP-1159783791-127.0.1.1-1436048545002 blk_1073742479_1655{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:17:10,913 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742479_1655{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:17:11,295 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0002/job.jar is closed by DFSClient_NONMAPREDUCE_1383960419_1
2015-08-25 17:17:11,300 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0002/job.jar
2015-08-25 17:17:11,373 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0002/job.split
2015-08-25 17:17:11,390 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0002/job.split. BP-1159783791-127.0.1.1-1436048545002 blk_1073742480_1656{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:17:11,402 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742480_1656{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:17:11,413 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0002/job.split is closed by DFSClient_NONMAPREDUCE_1383960419_1
2015-08-25 17:17:11,436 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0002/job.splitmetainfo. BP-1159783791-127.0.1.1-1436048545002 blk_1073742481_1657{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:17:11,441 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742481_1657{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:17:11,454 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0002/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1383960419_1
2015-08-25 17:17:11,557 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0002/job.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742482_1658{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:17:11,680 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742482_1658{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:17:11,699 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0002/job.xml is closed by DFSClient_NONMAPREDUCE_1383960419_1
2015-08-25 17:17:16,919 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0002/job_1440492175555_0002_1_conf.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742483_1659{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:17:16,967 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742483_1659{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:17:16,978 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0002/job_1440492175555_0002_1_conf.xml is closed by DFSClient_NONMAPREDUCE_87909847_1
2015-08-25 17:17:20,988 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0002_m_000000_0/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742484_1660{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:17:21,037 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742484_1660{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:17:21,046 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0002_m_000000_0/part-m-00000 is closed by DFSClient_attempt_1440492175555_0002_m_000000_0_-373833535_1
2015-08-25 17:17:21,067 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742484_1660 127.0.0.1:50010 
2015-08-25 17:17:21,116 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0002/job_1440492175555_0002_1.jhist. BP-1159783791-127.0.1.1-1436048545002 blk_1073742485_1661{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:17:21,126 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0002/job_1440492175555_0002_1.jhist for DFSClient_NONMAPREDUCE_87909847_1
2015-08-25 17:17:23,135 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742484_1660]
2015-08-25 17:17:24,921 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0002_m_000000_1/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742486_1662{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:17:24,966 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742486_1662{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:17:24,973 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0002_m_000000_1/part-m-00000 is closed by DFSClient_attempt_1440492175555_0002_m_000000_1_-516889004_1
2015-08-25 17:17:24,993 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742486_1662 127.0.0.1:50010 
2015-08-25 17:17:26,135 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742486_1662]
2015-08-25 17:17:28,872 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0002_m_000000_2/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742487_1663{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:17:28,913 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742487_1663{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:17:28,920 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0002_m_000000_2/part-m-00000 is closed by DFSClient_attempt_1440492175555_0002_m_000000_2_72221779_1
2015-08-25 17:17:28,940 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742487_1663 127.0.0.1:50010 
2015-08-25 17:17:29,135 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742487_1663]
2015-08-25 17:17:34,078 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0002_m_000000_3/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742488_1664{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:17:34,121 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742488_1664{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:17:34,128 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0002_m_000000_3/part-m-00000 is closed by DFSClient_attempt_1440492175555_0002_m_000000_3_-1724081287_1
2015-08-25 17:17:34,148 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742488_1664 127.0.0.1:50010 
2015-08-25 17:17:34,185 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742485_1661{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:17:34,189 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0002/job_1440492175555_0002_1.jhist is closed by DFSClient_NONMAPREDUCE_87909847_1
2015-08-25 17:17:34,201 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0002.summary_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742489_1665{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:17:34,209 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742489_1665{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:17:34,219 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0002.summary_tmp is closed by DFSClient_NONMAPREDUCE_87909847_1
2015-08-25 17:17:34,257 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0002-1440494231857-liyaohui-Input+Driver+running+over+input%3A+testdata-1440494254170-0-0-FAILED-default.jhist_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742490_1666{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:17:34,268 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742490_1666{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:17:34,280 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0002-1440494231857-liyaohui-Input+Driver+running+over+input%3A+testdata-1440494254170-0-0-FAILED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_87909847_1
2015-08-25 17:17:34,315 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0002_conf.xml_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742491_1667{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:17:34,322 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742491_1667{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:17:34,331 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0002_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_87909847_1
2015-08-25 17:17:35,136 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742488_1664]
2015-08-25 17:17:35,389 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742479_1655 127.0.0.1:50010 
2015-08-25 17:17:35,389 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742480_1656 127.0.0.1:50010 
2015-08-25 17:17:35,389 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742481_1657 127.0.0.1:50010 
2015-08-25 17:17:35,389 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742482_1658 127.0.0.1:50010 
2015-08-25 17:17:35,389 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742485_1661 127.0.0.1:50010 
2015-08-25 17:17:35,389 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742483_1659 127.0.0.1:50010 
2015-08-25 17:17:38,136 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742480_1656, blk_1073742481_1657, blk_1073742482_1658, blk_1073742483_1659, blk_1073742485_1661, blk_1073742479_1655]
2015-08-25 17:17:47,187 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:17:47,187 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:17:47,192 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:17:47,193 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:17:48,153 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:17:48,228 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:17:48,233 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:17:48,233 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:19:04,651 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:19:04,652 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:19:04,657 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:19:04,657 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:19:05,757 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:19:05,758 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:19:05,764 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:19:05,764 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:19:06,769 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:19:06,770 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:19:06,775 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:19:06,775 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:19:07,891 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:19:07,891 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:19:07,896 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:19:07,897 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:19:07,964 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:19:07,964 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:19:07,969 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:19:07,970 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:19:07,981 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 17:19:07,982 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 17:21:37,198 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 211 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 1 Number of syncs: 107 SyncTimes(ms): 2659 
2015-08-25 17:21:37,928 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0003/job.jar. BP-1159783791-127.0.1.1-1436048545002 blk_1073742492_1668{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:21:38,296 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742492_1668{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:21:38,758 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0003/job.jar is closed by DFSClient_NONMAPREDUCE_-1291659274_1
2015-08-25 17:21:38,763 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0003/job.jar
2015-08-25 17:21:38,835 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0003/job.split
2015-08-25 17:21:38,854 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0003/job.split. BP-1159783791-127.0.1.1-1436048545002 blk_1073742493_1669{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:21:38,860 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742493_1669{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:21:38,865 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0003/job.split is closed by DFSClient_NONMAPREDUCE_-1291659274_1
2015-08-25 17:21:38,888 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0003/job.splitmetainfo. BP-1159783791-127.0.1.1-1436048545002 blk_1073742494_1670{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:21:38,892 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742494_1670{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:21:38,896 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0003/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-1291659274_1
2015-08-25 17:21:39,051 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0003/job.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742495_1671{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:21:39,071 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742495_1671{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:21:39,079 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0003/job.xml is closed by DFSClient_NONMAPREDUCE_-1291659274_1
2015-08-25 17:21:43,261 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0003/job_1440492175555_0003_1_conf.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742496_1672{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:21:43,312 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742496_1672{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:21:43,321 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0003/job_1440492175555_0003_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-375664465_1
2015-08-25 17:21:47,527 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0003_m_000000_0/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742497_1673{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:21:47,570 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742497_1673{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:21:47,583 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0003_m_000000_0/part-m-00000 is closed by DFSClient_attempt_1440492175555_0003_m_000000_0_-758434653_1
2015-08-25 17:21:47,603 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742497_1673 127.0.0.1:50010 
2015-08-25 17:21:47,656 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0003/job_1440492175555_0003_1.jhist. BP-1159783791-127.0.1.1-1436048545002 blk_1073742498_1674{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:21:47,664 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0003/job_1440492175555_0003_1.jhist for DFSClient_NONMAPREDUCE_-375664465_1
2015-08-25 17:21:50,151 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742497_1673]
2015-08-25 17:21:51,593 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0003_m_000000_1/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742499_1675{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:21:51,634 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742499_1675{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:21:51,641 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0003_m_000000_1/part-m-00000 is closed by DFSClient_attempt_1440492175555_0003_m_000000_1_-291862972_1
2015-08-25 17:21:51,662 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742499_1675 127.0.0.1:50010 
2015-08-25 17:21:53,151 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742499_1675]
2015-08-25 17:21:55,323 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0003_m_000000_2/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742500_1676{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:21:55,365 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742500_1676{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:21:55,374 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0003_m_000000_2/part-m-00000 is closed by DFSClient_attempt_1440492175555_0003_m_000000_2_38779135_1
2015-08-25 17:21:55,395 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742500_1676 127.0.0.1:50010 
2015-08-25 17:21:56,152 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742500_1676]
2015-08-25 17:22:00,338 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0003_m_000000_3/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742501_1677{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:22:00,381 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742501_1677{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:22:00,389 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0003_m_000000_3/part-m-00000 is closed by DFSClient_attempt_1440492175555_0003_m_000000_3_422909217_1
2015-08-25 17:22:00,410 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742501_1677 127.0.0.1:50010 
2015-08-25 17:22:00,448 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742498_1674{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:22:00,460 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0003/job_1440492175555_0003_1.jhist is closed by DFSClient_NONMAPREDUCE_-375664465_1
2015-08-25 17:22:00,473 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0003.summary_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742502_1678{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:22:00,482 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742502_1678{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:22:00,491 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0003.summary_tmp is closed by DFSClient_NONMAPREDUCE_-375664465_1
2015-08-25 17:22:00,529 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0003-1440494499251-liyaohui-Input+Driver+running+over+input%3A+testdata-1440494520426-0-0-FAILED-default.jhist_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742503_1679{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:22:00,534 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742503_1679{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:22:00,556 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0003-1440494499251-liyaohui-Input+Driver+running+over+input%3A+testdata-1440494520426-0-0-FAILED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-375664465_1
2015-08-25 17:22:00,575 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0003_conf.xml_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742504_1680{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 17:22:00,589 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742504_1680{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 17:22:00,603 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0003_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-375664465_1
2015-08-25 17:22:01,661 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742492_1668 127.0.0.1:50010 
2015-08-25 17:22:01,661 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742493_1669 127.0.0.1:50010 
2015-08-25 17:22:01,661 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742494_1670 127.0.0.1:50010 
2015-08-25 17:22:01,661 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742495_1671 127.0.0.1:50010 
2015-08-25 17:22:01,661 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742498_1674 127.0.0.1:50010 
2015-08-25 17:22:01,661 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742496_1672 127.0.0.1:50010 
2015-08-25 17:22:02,152 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742496_1672, blk_1073742498_1674, blk_1073742501_1677, blk_1073742492_1668, blk_1073742493_1669, blk_1073742494_1670, blk_1073742495_1671]
2015-08-25 17:43:52,708 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-08-25 17:43:52,709 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-08-25 17:43:52,709 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 4296
2015-08-25 17:43:52,709 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 307 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 1 Number of syncs: 156 SyncTimes(ms): 3765 
2015-08-25 17:43:52,715 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 307 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 1 Number of syncs: 157 SyncTimes(ms): 3771 
2015-08-25 17:43:52,716 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000004296 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004296-0000000000000004602
2015-08-25 17:43:52,716 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4603
2015-08-25 17:43:52,978 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=4602&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-08-25 17:43:53,015 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 1972.97 KB/s
2015-08-25 17:43:53,015 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000004602 size 75319 bytes.
2015-08-25 17:43:53,046 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4295
2015-08-25 17:43:53,046 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004291, cpktTxId=0000000000000004291)
2015-08-25 18:43:53,353 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-08-25 18:43:53,353 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-08-25 18:43:53,353 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 4603
2015-08-25 18:43:53,353 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 70 
2015-08-25 18:43:53,367 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 84 
2015-08-25 18:43:53,367 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000004603 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004603-0000000000000004604
2015-08-25 18:43:53,367 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4605
2015-08-25 18:43:53,569 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=4604&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-08-25 18:43:53,615 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 1586.96 KB/s
2015-08-25 18:43:53,615 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000004604 size 75319 bytes.
2015-08-25 18:43:53,656 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4602
2015-08-25 18:43:53,657 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004295, cpktTxId=0000000000000004295)
2015-08-25 18:47:03,164 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 58 
2015-08-25 18:47:03,650 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0004/job.jar. BP-1159783791-127.0.1.1-1436048545002 blk_1073742505_1681{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:47:03,907 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742505_1681{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:47:04,101 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0004/job.jar is closed by DFSClient_NONMAPREDUCE_1832883323_1
2015-08-25 18:47:04,106 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0004/job.jar
2015-08-25 18:47:04,446 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0004/job.split
2015-08-25 18:47:04,463 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0004/job.split. BP-1159783791-127.0.1.1-1436048545002 blk_1073742506_1682{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:47:04,469 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742506_1682{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:47:04,476 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0004/job.split is closed by DFSClient_NONMAPREDUCE_1832883323_1
2015-08-25 18:47:04,498 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0004/job.splitmetainfo. BP-1159783791-127.0.1.1-1436048545002 blk_1073742507_1683{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:47:04,612 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742507_1683{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:47:04,639 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0004/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1832883323_1
2015-08-25 18:47:04,738 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0004/job.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742508_1684{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:47:04,758 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742508_1684{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:47:04,771 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0004/job.xml is closed by DFSClient_NONMAPREDUCE_1832883323_1
2015-08-25 18:47:09,070 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0004/job_1440492175555_0004_1_conf.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742509_1685{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:47:09,161 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742509_1685{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:47:09,175 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0004/job_1440492175555_0004_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-1588160262_1
2015-08-25 18:47:13,338 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0004_m_000000_0/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742510_1686{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:47:13,377 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742510_1686{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:47:13,400 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0004_m_000000_0/part-m-00000 is closed by DFSClient_attempt_1440492175555_0004_m_000000_0_-1755347414_1
2015-08-25 18:47:13,427 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742510_1686 127.0.0.1:50010 
2015-08-25 18:47:13,473 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0004/job_1440492175555_0004_1.jhist. BP-1159783791-127.0.1.1-1436048545002 blk_1073742511_1687{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:47:13,478 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0004/job_1440492175555_0004_1.jhist for DFSClient_NONMAPREDUCE_-1588160262_1
2015-08-25 18:47:14,356 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742510_1686]
2015-08-25 18:47:17,194 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0004_m_000000_1/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742512_1688{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:47:17,234 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742512_1688{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:47:17,242 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0004_m_000000_1/part-m-00000 is closed by DFSClient_attempt_1440492175555_0004_m_000000_1_-1648378923_1
2015-08-25 18:47:17,262 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742512_1688 127.0.0.1:50010 
2015-08-25 18:47:17,357 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742512_1688]
2015-08-25 18:47:21,222 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0004_m_000000_2/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742513_1689{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:47:21,261 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742513_1689{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:47:21,270 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0004_m_000000_2/part-m-00000 is closed by DFSClient_attempt_1440492175555_0004_m_000000_2_761138596_1
2015-08-25 18:47:21,290 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742513_1689 127.0.0.1:50010 
2015-08-25 18:47:23,357 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742513_1689]
2015-08-25 18:47:26,038 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0004_m_000000_3/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742514_1690{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:47:26,077 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742514_1690{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:47:26,091 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0004_m_000000_3/part-m-00000 is closed by DFSClient_attempt_1440492175555_0004_m_000000_3_1762138951_1
2015-08-25 18:47:26,112 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742514_1690 127.0.0.1:50010 
2015-08-25 18:47:26,142 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742511_1687{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:47:26,152 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0004/job_1440492175555_0004_1.jhist is closed by DFSClient_NONMAPREDUCE_-1588160262_1
2015-08-25 18:47:26,176 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0004.summary_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742515_1691{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:47:26,184 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742515_1691{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:47:26,193 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0004.summary_tmp is closed by DFSClient_NONMAPREDUCE_-1588160262_1
2015-08-25 18:47:26,240 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0004-1440499624935-liyaohui-Input+Driver+running+over+input%3A+testdata-1440499646127-0-0-FAILED-default.jhist_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742516_1692{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:47:26,249 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742516_1692{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:47:26,254 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0004-1440499624935-liyaohui-Input+Driver+running+over+input%3A+testdata-1440499646127-0-0-FAILED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-1588160262_1
2015-08-25 18:47:26,278 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0004_conf.xml_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742517_1693{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:47:26,285 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742517_1693{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:47:26,295 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0004_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-1588160262_1
2015-08-25 18:47:26,357 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742514_1690]
2015-08-25 18:47:27,353 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742505_1681 127.0.0.1:50010 
2015-08-25 18:47:27,353 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742506_1682 127.0.0.1:50010 
2015-08-25 18:47:27,353 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742507_1683 127.0.0.1:50010 
2015-08-25 18:47:27,353 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742508_1684 127.0.0.1:50010 
2015-08-25 18:47:27,353 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742511_1687 127.0.0.1:50010 
2015-08-25 18:47:27,353 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742509_1685 127.0.0.1:50010 
2015-08-25 18:47:29,357 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742505_1681, blk_1073742506_1682, blk_1073742507_1683, blk_1073742508_1684, blk_1073742509_1685, blk_1073742511_1687]
2015-08-25 18:47:34,826 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:47:34,827 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:47:34,832 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:47:34,832 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:47:36,752 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:47:36,752 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:47:36,757 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:47:36,757 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:47:38,112 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:47:38,113 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:47:38,120 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:47:38,120 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:47:38,183 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:47:38,184 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:47:38,190 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:47:38,190 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:47:38,202 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:47:38,202 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:48:58,273 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:48:58,273 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:48:58,278 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:48:58,278 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:48:58,325 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:48:58,325 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:48:58,330 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:48:58,331 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:48:58,341 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:48:58,341 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:49:05,155 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:49:05,155 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:49:05,160 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:49:05,161 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:49:06,090 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:49:06,090 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:49:06,094 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:49:06,095 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:49:09,169 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:49:09,169 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:49:09,174 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:49:09,175 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:49:22,934 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 99 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 0 Number of syncs: 51 SyncTimes(ms): 962 
2015-08-25 18:49:22,947 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742464_1640 127.0.0.1:50010 
2015-08-25 18:49:23,362 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742464_1640]
2015-08-25 18:49:27,689 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:49:27,690 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:49:27,694 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:49:27,695 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:50:01,332 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/testdata/test1.csv._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742518_1694{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:50:01,452 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742518_1694{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:50:01,458 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/testdata/test1.csv._COPYING_ is closed by DFSClient_NONMAPREDUCE_1138662739_1
2015-08-25 18:50:05,312 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:50:05,313 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:50:05,318 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:50:05,318 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:50:06,582 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:50:06,583 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:50:06,588 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:50:06,588 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:50:07,697 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:50:07,697 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:50:07,704 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:50:07,704 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:50:07,721 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:50:07,721 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:50:07,726 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:50:07,726 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:50:07,736 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 18:50:07,737 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 18:50:32,215 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 106 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 0 Number of syncs: 55 SyncTimes(ms): 994 
2015-08-25 18:50:32,874 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0005/job.jar. BP-1159783791-127.0.1.1-1436048545002 blk_1073742519_1695{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:50:33,099 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742519_1695{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:50:33,439 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0005/job.jar is closed by DFSClient_NONMAPREDUCE_97613718_1
2015-08-25 18:50:33,445 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0005/job.jar
2015-08-25 18:50:33,765 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0005/job.split
2015-08-25 18:50:33,782 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0005/job.split. BP-1159783791-127.0.1.1-1436048545002 blk_1073742520_1696{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:50:33,790 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742520_1696{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:50:33,795 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0005/job.split is closed by DFSClient_NONMAPREDUCE_97613718_1
2015-08-25 18:50:33,817 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0005/job.splitmetainfo. BP-1159783791-127.0.1.1-1436048545002 blk_1073742521_1697{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:50:33,825 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742521_1697{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:50:33,835 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0005/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_97613718_1
2015-08-25 18:50:33,933 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0005/job.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742522_1698{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:50:33,944 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742522_1698{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:50:33,957 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0005/job.xml is closed by DFSClient_NONMAPREDUCE_97613718_1
2015-08-25 18:50:38,186 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0005/job_1440492175555_0005_1_conf.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742523_1699{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:50:38,233 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742523_1699{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:50:38,240 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0005/job_1440492175555_0005_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1337470046_1
2015-08-25 18:50:42,333 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0005_m_000000_0/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742524_1700{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:50:42,377 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742524_1700{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:50:42,390 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0005_m_000000_0/part-m-00000 is closed by DFSClient_attempt_1440492175555_0005_m_000000_0_-496299826_1
2015-08-25 18:50:42,410 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742524_1700 127.0.0.1:50010 
2015-08-25 18:50:42,450 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0005/job_1440492175555_0005_1.jhist. BP-1159783791-127.0.1.1-1436048545002 blk_1073742525_1701{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:50:42,458 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0005/job_1440492175555_0005_1.jhist for DFSClient_NONMAPREDUCE_1337470046_1
2015-08-25 18:50:44,366 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742524_1700]
2015-08-25 18:50:46,371 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0005_m_000000_1/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742526_1702{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:50:46,416 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742526_1702{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:50:46,428 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0005_m_000000_1/part-m-00000 is closed by DFSClient_attempt_1440492175555_0005_m_000000_1_1878102589_1
2015-08-25 18:50:46,449 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742526_1702 127.0.0.1:50010 
2015-08-25 18:50:47,366 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742526_1702]
2015-08-25 18:50:50,264 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0005_m_000000_2/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742527_1703{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:50:50,308 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742527_1703{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:50:50,314 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0005_m_000000_2/part-m-00000 is closed by DFSClient_attempt_1440492175555_0005_m_000000_2_-509935699_1
2015-08-25 18:50:50,334 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742527_1703 127.0.0.1:50010 
2015-08-25 18:50:50,366 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742527_1703]
2015-08-25 18:50:55,331 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0005_m_000000_3/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742528_1704{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:50:55,378 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742528_1704{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:50:55,401 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0005_m_000000_3/part-m-00000 is closed by DFSClient_attempt_1440492175555_0005_m_000000_3_310995311_1
2015-08-25 18:50:55,432 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742528_1704 127.0.0.1:50010 
2015-08-25 18:50:55,469 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742525_1701{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:50:55,493 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0005/job_1440492175555_0005_1.jhist is closed by DFSClient_NONMAPREDUCE_1337470046_1
2015-08-25 18:50:55,515 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0005.summary_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742529_1705{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:50:55,520 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742529_1705{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:50:55,544 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0005.summary_tmp is closed by DFSClient_NONMAPREDUCE_1337470046_1
2015-08-25 18:50:55,616 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0005-1440499834113-liyaohui-Input+Driver+running+over+input%3A+testdata-1440499855447-0-0-FAILED-default.jhist_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742530_1706{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:50:55,621 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742530_1706{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:50:55,645 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0005-1440499834113-liyaohui-Input+Driver+running+over+input%3A+testdata-1440499855447-0-0-FAILED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_1337470046_1
2015-08-25 18:50:55,689 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0005_conf.xml_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742531_1707{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:50:55,695 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742531_1707{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:50:55,717 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0005_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_1337470046_1
2015-08-25 18:50:56,367 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742528_1704]
2015-08-25 18:50:56,815 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742519_1695 127.0.0.1:50010 
2015-08-25 18:50:56,815 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742520_1696 127.0.0.1:50010 
2015-08-25 18:50:56,815 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742521_1697 127.0.0.1:50010 
2015-08-25 18:50:56,815 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742522_1698 127.0.0.1:50010 
2015-08-25 18:50:56,815 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742525_1701 127.0.0.1:50010 
2015-08-25 18:50:56,815 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742523_1699 127.0.0.1:50010 
2015-08-25 18:50:59,367 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742519_1695, blk_1073742520_1696, blk_1073742521_1697, blk_1073742522_1698, blk_1073742523_1699, blk_1073742525_1701]
2015-08-25 18:54:28,114 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 202 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 0 Number of syncs: 104 SyncTimes(ms): 2274 
2015-08-25 18:54:28,815 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0006/job.jar. BP-1159783791-127.0.1.1-1436048545002 blk_1073742532_1708{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:54:29,139 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742532_1708{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:54:29,497 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0006/job.jar is closed by DFSClient_NONMAPREDUCE_2123641477_1
2015-08-25 18:54:29,502 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0006/job.jar
2015-08-25 18:54:29,888 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0006/job.split
2015-08-25 18:54:29,905 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0006/job.split. BP-1159783791-127.0.1.1-1436048545002 blk_1073742533_1709{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:54:29,910 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742533_1709{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:54:29,918 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0006/job.split is closed by DFSClient_NONMAPREDUCE_2123641477_1
2015-08-25 18:54:29,941 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0006/job.splitmetainfo. BP-1159783791-127.0.1.1-1436048545002 blk_1073742534_1710{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:54:29,945 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742534_1710{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:54:29,948 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0006/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_2123641477_1
2015-08-25 18:54:30,112 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0006/job.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742535_1711{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:54:30,125 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742535_1711{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:54:30,132 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0006/job.xml is closed by DFSClient_NONMAPREDUCE_2123641477_1
2015-08-25 18:54:34,574 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0006/job_1440492175555_0006_1_conf.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742536_1712{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:54:34,629 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742536_1712{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:54:34,638 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0006/job_1440492175555_0006_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-899017898_1
2015-08-25 18:54:38,718 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0006_m_000000_0/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742537_1713{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:54:38,764 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742537_1713{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:54:38,778 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0006_m_000000_0/part-m-00000 is closed by DFSClient_attempt_1440492175555_0006_m_000000_0_1634004692_1
2015-08-25 18:54:38,798 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742537_1713 127.0.0.1:50010 
2015-08-25 18:54:38,847 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0006/job_1440492175555_0006_1.jhist. BP-1159783791-127.0.1.1-1436048545002 blk_1073742538_1714{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:54:38,855 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0006/job_1440492175555_0006_1.jhist for DFSClient_NONMAPREDUCE_-899017898_1
2015-08-25 18:54:41,376 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742537_1713]
2015-08-25 18:54:42,515 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0006_m_000000_1/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742539_1715{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:54:42,557 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742539_1715{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:54:42,572 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0006_m_000000_1/part-m-00000 is closed by DFSClient_attempt_1440492175555_0006_m_000000_1_-320661446_1
2015-08-25 18:54:42,592 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742539_1715 127.0.0.1:50010 
2015-08-25 18:54:44,376 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742539_1715]
2015-08-25 18:54:46,645 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0006_m_000000_2/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742540_1716{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:54:46,692 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742540_1716{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:54:46,702 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0006_m_000000_2/part-m-00000 is closed by DFSClient_attempt_1440492175555_0006_m_000000_2_1062674933_1
2015-08-25 18:54:46,722 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742540_1716 127.0.0.1:50010 
2015-08-25 18:54:47,377 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742540_1716]
2015-08-25 18:54:51,585 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0006_m_000000_3/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742541_1717{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:54:51,630 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742541_1717{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:54:51,645 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440492175555_0006_m_000000_3/part-m-00000 is closed by DFSClient_attempt_1440492175555_0006_m_000000_3_107731945_1
2015-08-25 18:54:51,666 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742541_1717 127.0.0.1:50010 
2015-08-25 18:54:51,715 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742538_1714{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:54:51,727 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0006/job_1440492175555_0006_1.jhist is closed by DFSClient_NONMAPREDUCE_-899017898_1
2015-08-25 18:54:51,739 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0006.summary_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742542_1718{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:54:51,747 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742542_1718{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:54:51,757 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0006.summary_tmp is closed by DFSClient_NONMAPREDUCE_-899017898_1
2015-08-25 18:54:51,796 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0006-1440500070290-liyaohui-Input+Driver+running+over+input%3A+testdata-1440500091690-0-0-FAILED-default.jhist_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742543_1719{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:54:51,805 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742543_1719{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:54:51,816 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0006-1440500070290-liyaohui-Input+Driver+running+over+input%3A+testdata-1440500091690-0-0-FAILED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-899017898_1
2015-08-25 18:54:51,842 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0006_conf.xml_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742544_1720{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 18:54:51,848 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742544_1720{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 18:54:51,859 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0006_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-899017898_1
2015-08-25 18:54:52,917 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742532_1708 127.0.0.1:50010 
2015-08-25 18:54:52,917 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742533_1709 127.0.0.1:50010 
2015-08-25 18:54:52,917 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742534_1710 127.0.0.1:50010 
2015-08-25 18:54:52,917 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742535_1711 127.0.0.1:50010 
2015-08-25 18:54:52,917 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742538_1714 127.0.0.1:50010 
2015-08-25 18:54:52,917 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742536_1712 127.0.0.1:50010 
2015-08-25 18:54:53,377 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742532_1708, blk_1073742533_1709, blk_1073742534_1710, blk_1073742535_1711, blk_1073742536_1712, blk_1073742538_1714, blk_1073742541_1717]
2015-08-25 19:37:46,818 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-08-25 19:37:46,865 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:37:46,865 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:37:46,873 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:37:46,873 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:43:53,958 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-08-25 19:43:53,958 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-08-25 19:43:53,958 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 4605
2015-08-25 19:43:53,958 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 298 Total time for transactions(ms): 15 Number of transactions batched in Syncs: 0 Number of syncs: 153 SyncTimes(ms): 3571 
2015-08-25 19:43:53,968 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 298 Total time for transactions(ms): 15 Number of transactions batched in Syncs: 0 Number of syncs: 154 SyncTimes(ms): 3581 
2015-08-25 19:43:53,969 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000004605 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004605-0000000000000004902
2015-08-25 19:43:53,969 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4903
2015-08-25 19:43:54,221 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=4902&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-08-25 19:43:54,257 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 2055.56 KB/s
2015-08-25 19:43:54,257 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000004902 size 76696 bytes.
2015-08-25 19:43:54,288 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4604
2015-08-25 19:43:54,288 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004602, cpktTxId=0000000000000004602)
2015-08-25 19:47:49,488 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 77 
2015-08-25 19:47:49,571 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0007/job.jar. BP-1159783791-127.0.1.1-1436048545002 blk_1073742545_1721{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 19:47:49,871 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742545_1721{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 19:47:50,029 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0007/job.jar is closed by DFSClient_NONMAPREDUCE_-160039671_1
2015-08-25 19:47:50,034 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0007/job.jar
2015-08-25 19:47:50,595 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0007/job.split
2015-08-25 19:47:50,615 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0007/job.split. BP-1159783791-127.0.1.1-1436048545002 blk_1073742546_1722{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 19:47:50,621 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742546_1722{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 19:47:50,625 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0007/job.split is closed by DFSClient_NONMAPREDUCE_-160039671_1
2015-08-25 19:47:50,648 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0007/job.splitmetainfo. BP-1159783791-127.0.1.1-1436048545002 blk_1073742547_1723{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 19:47:50,652 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742547_1723{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 19:47:50,666 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0007/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-160039671_1
2015-08-25 19:47:50,812 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0007/job.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742548_1724{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 19:47:50,817 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742548_1724{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 19:47:50,829 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0007/job.xml is closed by DFSClient_NONMAPREDUCE_-160039671_1
2015-08-25 19:47:56,567 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0007/job_1440492175555_0007_1_conf.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742549_1725{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 19:47:56,625 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742549_1725{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 19:47:56,637 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0007/job_1440492175555_0007_1_conf.xml is closed by DFSClient_NONMAPREDUCE_202151938_1
2015-08-25 19:48:00,747 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0007/job_1440492175555_0007_1.jhist. BP-1159783791-127.0.1.1-1436048545002 blk_1073742550_1726{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 19:48:00,753 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0007/job_1440492175555_0007_1.jhist for DFSClient_NONMAPREDUCE_202151938_1
2015-08-25 19:48:13,631 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742550_1726{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-08-25 19:48:13,631 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0007/job_1440492175555_0007_1.jhist is closed by DFSClient_NONMAPREDUCE_202151938_1
2015-08-25 19:48:13,631 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742550_1726{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 24119
2015-08-25 19:48:14,041 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440492175555_0007/job_1440492175555_0007_1.jhist is closed by DFSClient_NONMAPREDUCE_202151938_1
2015-08-25 19:48:14,054 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0007.summary_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742551_1727{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 19:48:14,059 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742551_1727{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-08-25 19:48:14,059 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0007.summary_tmp is closed by DFSClient_NONMAPREDUCE_202151938_1
2015-08-25 19:48:14,059 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742551_1727{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 349
2015-08-25 19:48:14,468 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0007.summary_tmp is closed by DFSClient_NONMAPREDUCE_202151938_1
2015-08-25 19:48:14,506 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0007-1440503271004-liyaohui-SequenceFilesFromDirectory-1440503293611-0-0-FAILED-default.jhist_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742552_1728{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 19:48:14,511 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742552_1728{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 19:48:14,519 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0007-1440503271004-liyaohui-SequenceFilesFromDirectory-1440503293611-0-0-FAILED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_202151938_1
2015-08-25 19:48:14,544 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0007_conf.xml_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742553_1729{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 19:48:14,549 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742553_1729{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 19:48:14,560 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440492175555_0007_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_202151938_1
2015-08-25 19:48:15,648 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742545_1721 127.0.0.1:50010 
2015-08-25 19:48:15,649 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742546_1722 127.0.0.1:50010 
2015-08-25 19:48:15,649 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742547_1723 127.0.0.1:50010 
2015-08-25 19:48:15,649 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742548_1724 127.0.0.1:50010 
2015-08-25 19:48:15,649 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742550_1726 127.0.0.1:50010 
2015-08-25 19:48:15,649 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742549_1725 127.0.0.1:50010 
2015-08-25 19:48:17,511 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742545_1721, blk_1073742546_1722, blk_1073742547_1723, blk_1073742548_1724, blk_1073742549_1725, blk_1073742550_1726]
2015-08-25 19:49:05,840 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-08-25 19:49:05,877 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:49:05,877 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:49:05,882 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:49:05,882 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:49:09,143 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:49:09,143 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:49:09,148 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:49:09,149 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:49:10,523 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:49:10,523 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:49:10,528 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:49:10,528 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:49:12,360 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:49:12,361 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:49:12,365 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:49:12,366 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:49:17,808 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:49:17,808 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:49:17,812 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:49:17,813 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:49:24,650 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:49:24,650 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:49:24,654 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:49:24,655 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:49:26,115 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:49:26,116 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:49:26,120 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:49:26,121 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:49:26,136 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:49:26,136 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:49:26,141 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:49:26,142 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:49:26,159 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:49:26,159 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:49:30,140 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:49:30,141 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:49:30,148 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:49:30,148 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:49:31,231 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:49:31,231 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:49:31,236 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:49:31,236 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:52:21,985 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:52:21,985 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:52:21,990 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:52:21,990 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:52:23,172 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:52:23,173 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:52:23,177 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:52:23,178 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:52:24,255 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:52:24,256 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:52:24,260 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:52:24,260 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:52:26,554 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:52:26,554 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:52:26,559 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:52:26,559 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:52:26,575 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:52:26,575 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:52:26,580 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:52:26,581 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:52:26,592 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:52:26,593 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:52:29,702 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:52:29,702 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:52:29,706 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:52:29,706 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:52:30,983 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:52:30,983 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:52:30,990 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:52:30,990 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:52:33,862 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:52:33,862 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:52:33,867 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:52:33,867 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:52:38,022 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:52:38,022 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:52:38,029 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:52:38,029 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:52:39,837 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:52:39,838 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:52:39,843 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:52:39,843 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:52:39,856 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:52:39,856 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:52:39,863 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:52:39,863 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:52:39,919 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:52:39,920 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:54:15,296 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:54:15,296 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:54:15,301 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:54:15,301 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:54:17,264 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:54:17,264 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:54:17,269 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:54:17,269 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:54:17,280 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:54:17,281 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:54:17,286 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:54:17,286 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:54:17,304 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-08-25 19:54:17,305 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-08-25 19:55:00,176 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2015-08-25 19:55:00,180 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ubuntu01/127.0.1.1
************************************************************/
2015-08-25 20:10:16,593 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-08-25 20:10:16,620 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-08-25 20:10:16,960 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-08-25 20:10:17,228 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-08-25 20:10:17,228 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2015-08-25 20:10:17,347 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-08-25 20:10:17,538 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-08-25 20:10:17,593 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-08-25 20:10:17,595 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2015-08-25 20:10:17,595 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-08-25 20:10:17,595 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-08-25 20:10:17,639 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2015-08-25 20:10:17,696 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2015-08-25 20:10:17,696 INFO org.mortbay.log: jetty-6.1.26
2015-08-25 20:10:18,172 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2015-08-25 20:10:18,173 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2015-08-25 20:10:18,245 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2015-08-25 20:10:18,245 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2015-08-25 20:10:18,331 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2015-08-25 20:10:18,331 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2015-08-25 20:10:18,334 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-08-25 20:10:18,336 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-08-25 20:10:18,336 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-08-25 20:10:18,337 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2015-08-25 20:10:18,337 INFO org.apache.hadoop.util.GSet: capacity      = 2^22 = 4194304 entries
2015-08-25 20:10:18,348 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-08-25 20:10:18,348 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-08-25 20:10:18,349 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-08-25 20:10:18,349 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-08-25 20:10:18,349 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-08-25 20:10:18,349 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-08-25 20:10:18,349 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-08-25 20:10:18,349 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-08-25 20:10:18,355 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = liyaohui (auth:SIMPLE)
2015-08-25 20:10:18,355 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-08-25 20:10:18,355 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-08-25 20:10:18,355 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-08-25 20:10:18,356 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-08-25 20:10:18,956 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-08-25 20:10:18,956 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-08-25 20:10:18,957 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2015-08-25 20:10:18,957 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-08-25 20:10:18,959 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-08-25 20:10:18,964 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-08-25 20:10:18,964 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-08-25 20:10:18,964 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-08-25 20:10:18,965 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2015-08-25 20:10:18,965 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2015-08-25 20:10:18,978 INFO org.apache.hadoop.util.GSet: Computing capacity for map Namenode Retry Cache
2015-08-25 20:10:18,978 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-08-25 20:10:18,978 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory = 889 MB
2015-08-25 20:10:18,978 INFO org.apache.hadoop.util.GSet: capacity      = 2^16 = 65536 entries
2015-08-25 20:10:19,058 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/liyaohui/hadoop/tmp/dfs/name/in_use.lock acquired by nodename 2727@ubuntu01
2015-08-25 20:10:19,128 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/liyaohui/hadoop/tmp/dfs/name/current
2015-08-25 20:10:19,239 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000004903 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004903-0000000000000004968
2015-08-25 20:10:19,276 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004902 using no compression
2015-08-25 20:10:19,276 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 689
2015-08-25 20:10:19,319 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2015-08-25 20:10:19,320 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004902 of size 76696 bytes loaded in 0 seconds.
2015-08-25 20:10:19,320 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 4902 from /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004902
2015-08-25 20:10:19,320 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1e7a160 expecting start txid #4903
2015-08-25 20:10:19,320 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004903-0000000000000004968
2015-08-25 20:10:19,322 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004903-0000000000000004968' to transaction ID 4903
2015-08-25 20:10:19,344 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004903-0000000000000004968 of size 1048576 edits # 66 loaded in 0 seconds
2015-08-25 20:10:19,349 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4969
2015-08-25 20:10:19,608 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 3 entries 45 lookups
2015-08-25 20:10:19,608 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 628 msecs
2015-08-25 20:10:20,120 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ubuntu01:9000
2015-08-25 20:10:20,163 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2015-08-25 20:10:20,214 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2015-08-25 20:10:20,243 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2015-08-25 20:10:20,244 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2015-08-25 20:10:20,255 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 549 blocks to reach the threshold 0.9990 of total blocks 549.
Safe mode will be turned off automatically
2015-08-25 20:10:20,288 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-08-25 20:10:20,293 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2015-08-25 20:10:20,299 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ubuntu01/127.0.1.1:9000
2015-08-25 20:10:20,299 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2015-08-25 20:10:23,113 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1, storageID=DS-1927886287-127.0.1.1-50010-1436049057919, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62;nsid=783537164;c=0) storage DS-1927886287-127.0.1.1-50010-1436049057919
2015-08-25 20:10:23,116 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2015-08-25 20:10:23,249 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 548 has reached the threshold 0.9990 of total blocks 549. The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically in 29 seconds.
2015-08-25 20:10:23,249 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2015-08-25 20:10:23,265 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 549
2015-08-25 20:10:23,265 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2015-08-25 20:10:23,265 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 4
2015-08-25 20:10:23,265 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2015-08-25 20:10:23,265 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2015-08-25 20:10:23,265 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 16 msec
2015-08-25 20:10:23,266 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 127.0.0.1:50010 after starting up or becoming active. Its block contents are no longer considered stale
2015-08-25 20:10:23,266 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(127.0.0.1, storageID=DS-1927886287-127.0.1.1-50010-1436049057919, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62;nsid=783537164;c=0), blocks: 549, processing time: 28 msecs
2015-08-25 20:10:43,268 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 549 has reached the threshold 0.9990 of total blocks 549. The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically in 9 seconds.
2015-08-25 20:10:53,269 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 34 secs
2015-08-25 20:10:53,269 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2015-08-25 20:10:53,269 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2015-08-25 20:10:53,269 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 3 blocks
2015-08-25 20:11:27,416 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 57 
2015-08-25 20:11:27,429 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742518_1694 127.0.0.1:50010 
2015-08-25 20:11:27,465 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-08-25 20:11:27,465 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-08-25 20:11:27,466 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 4969
2015-08-25 20:11:27,470 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms): 74 
2015-08-25 20:11:27,471 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000004969 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004969-0000000000000004971
2015-08-25 20:11:27,471 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4972
2015-08-25 20:11:28,175 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=4971&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-08-25 20:11:28,323 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.15s at 513.70 KB/s
2015-08-25 20:11:28,323 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000004971 size 77152 bytes.
2015-08-25 20:11:28,355 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4902
2015-08-25 20:11:28,355 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004604, cpktTxId=0000000000000004604)
2015-08-25 20:11:29,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742518_1694]
2015-08-25 20:13:23,484 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 72 
2015-08-25 20:13:23,560 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/testdata/test1.txt._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742554_1730{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 20:13:23,763 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742554_1730{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 20:13:23,779 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/testdata/test1.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1340691010_1
2015-08-25 20:13:59,089 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440504631392_0001/job.jar. BP-1159783791-127.0.1.1-1436048545002 blk_1073742555_1731{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 20:13:59,753 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742555_1731{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 20:13:59,941 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440504631392_0001/job.jar is closed by DFSClient_NONMAPREDUCE_685262114_1
2015-08-25 20:13:59,951 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440504631392_0001/job.jar
2015-08-25 20:14:00,033 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 1 to 10 for /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440504631392_0001/job.split
2015-08-25 20:14:00,058 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440504631392_0001/job.split. BP-1159783791-127.0.1.1-1436048545002 blk_1073742556_1732{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 20:14:00,067 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742556_1732{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 20:14:00,082 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440504631392_0001/job.split is closed by DFSClient_NONMAPREDUCE_685262114_1
2015-08-25 20:14:00,105 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440504631392_0001/job.splitmetainfo. BP-1159783791-127.0.1.1-1436048545002 blk_1073742557_1733{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 20:14:00,113 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742557_1733{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 20:14:00,123 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440504631392_0001/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_685262114_1
2015-08-25 20:14:00,498 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440504631392_0001/job.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742558_1734{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 20:14:00,506 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742558_1734{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 20:14:00,520 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440504631392_0001/job.xml is closed by DFSClient_NONMAPREDUCE_685262114_1
2015-08-25 20:14:07,397 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440504631392_0001/job_1440504631392_0001_1_conf.xml. BP-1159783791-127.0.1.1-1436048545002 blk_1073742559_1735{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 20:14:07,465 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742559_1735{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 20:14:07,478 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440504631392_0001/job_1440504631392_0001_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-1078183274_1
2015-08-25 20:14:11,539 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440504631392_0001_m_000000_0/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742560_1736{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 20:14:11,580 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742560_1736{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 20:14:11,597 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440504631392_0001_m_000000_0/part-m-00000 is closed by DFSClient_attempt_1440504631392_0001_m_000000_0_1834366070_1
2015-08-25 20:14:11,618 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742560_1736 127.0.0.1:50010 
2015-08-25 20:14:11,671 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440504631392_0001/job_1440504631392_0001_1.jhist. BP-1159783791-127.0.1.1-1436048545002 blk_1073742561_1737{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 20:14:11,682 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440504631392_0001/job_1440504631392_0001_1.jhist for DFSClient_NONMAPREDUCE_-1078183274_1
2015-08-25 20:14:14,286 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742560_1736]
2015-08-25 20:14:15,523 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440504631392_0001_m_000000_1/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742562_1738{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 20:14:15,567 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742562_1738{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 20:14:15,574 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440504631392_0001_m_000000_1/part-m-00000 is closed by DFSClient_attempt_1440504631392_0001_m_000000_1_-1855907345_1
2015-08-25 20:14:15,595 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742562_1738 127.0.0.1:50010 
2015-08-25 20:14:17,286 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742562_1738]
2015-08-25 20:14:19,388 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440504631392_0001_m_000000_2/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742563_1739{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 20:14:19,427 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742563_1739{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 20:14:19,440 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440504631392_0001_m_000000_2/part-m-00000 is closed by DFSClient_attempt_1440504631392_0001_m_000000_2_1093611480_1
2015-08-25 20:14:19,460 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742563_1739 127.0.0.1:50010 
2015-08-25 20:14:20,287 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742563_1739]
2015-08-25 20:14:24,434 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 74 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 0 Number of syncs: 36 SyncTimes(ms): 585 
2015-08-25 20:14:24,498 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440504631392_0001_m_000000_3/part-m-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742564_1740{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 20:14:24,539 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742564_1740{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 20:14:24,546 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/liyaohui/output/data/_temporary/1/_temporary/attempt_1440504631392_0001_m_000000_3/part-m-00000 is closed by DFSClient_attempt_1440504631392_0001_m_000000_3_853421421_1
2015-08-25 20:14:24,567 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742564_1740 127.0.0.1:50010 
2015-08-25 20:14:24,607 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742561_1737{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 20:14:24,617 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/liyaohui/.staging/job_1440504631392_0001/job_1440504631392_0001_1.jhist is closed by DFSClient_NONMAPREDUCE_-1078183274_1
2015-08-25 20:14:24,630 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440504631392_0001.summary_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742565_1741{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 20:14:24,638 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742565_1741{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 20:14:24,648 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440504631392_0001.summary_tmp is closed by DFSClient_NONMAPREDUCE_-1078183274_1
2015-08-25 20:14:24,686 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440504631392_0001-1440504840760-liyaohui-Input+Driver+running+over+input%3A+testdata-1440504864591-0-0-FAILED-default.jhist_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742566_1742{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 20:14:24,698 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742566_1742{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 20:14:24,719 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440504631392_0001-1440504840760-liyaohui-Input+Driver+running+over+input%3A+testdata-1440504864591-0-0-FAILED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-1078183274_1
2015-08-25 20:14:24,753 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440504631392_0001_conf.xml_tmp. BP-1159783791-127.0.1.1-1436048545002 blk_1073742567_1743{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-08-25 20:14:24,762 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742567_1743{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-08-25 20:14:24,770 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/liyaohui/job_1440504631392_0001_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-1078183274_1
2015-08-25 20:14:25,838 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742555_1731 127.0.0.1:50010 
2015-08-25 20:14:25,838 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742556_1732 127.0.0.1:50010 
2015-08-25 20:14:25,838 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742557_1733 127.0.0.1:50010 
2015-08-25 20:14:25,838 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742558_1734 127.0.0.1:50010 
2015-08-25 20:14:25,838 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742561_1737 127.0.0.1:50010 
2015-08-25 20:14:25,838 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742559_1735 127.0.0.1:50010 
2015-08-25 20:14:26,287 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742561_1737, blk_1073742564_1740, blk_1073742555_1731, blk_1073742556_1732, blk_1073742557_1733, blk_1073742558_1734, blk_1073742559_1735]
2015-08-25 20:14:58,617 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2015-08-25 20:14:58,623 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ubuntu01/127.0.1.1
************************************************************/
2015-09-01 20:58:24,715 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-09-01 20:58:24,742 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-09-01 20:58:25,280 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-09-01 20:58:25,580 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-09-01 20:58:25,580 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2015-09-01 20:58:25,753 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-01 20:58:25,955 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-09-01 20:58:26,014 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-09-01 20:58:26,016 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2015-09-01 20:58:26,016 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-09-01 20:58:26,016 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-09-01 20:58:26,065 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2015-09-01 20:58:26,104 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2015-09-01 20:58:26,104 INFO org.mortbay.log: jetty-6.1.26
2015-09-01 20:58:26,574 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2015-09-01 20:58:26,575 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2015-09-01 20:58:26,662 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2015-09-01 20:58:26,662 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2015-09-01 20:58:26,741 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2015-09-01 20:58:26,741 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2015-09-01 20:58:26,743 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-09-01 20:58:26,746 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-09-01 20:58:26,746 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-09-01 20:58:26,747 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2015-09-01 20:58:26,747 INFO org.apache.hadoop.util.GSet: capacity      = 2^22 = 4194304 entries
2015-09-01 20:58:26,759 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-09-01 20:58:26,759 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-09-01 20:58:26,759 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-09-01 20:58:26,759 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-09-01 20:58:26,759 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-09-01 20:58:26,759 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-09-01 20:58:26,759 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-09-01 20:58:26,760 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-09-01 20:58:26,766 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = liyaohui (auth:SIMPLE)
2015-09-01 20:58:26,766 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-09-01 20:58:26,766 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2015-09-01 20:58:26,766 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-09-01 20:58:26,768 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-09-01 20:58:27,353 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-09-01 20:58:27,353 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-09-01 20:58:27,353 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2015-09-01 20:58:27,353 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-09-01 20:58:27,356 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-09-01 20:58:27,361 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-09-01 20:58:27,361 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-09-01 20:58:27,361 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-09-01 20:58:27,362 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2015-09-01 20:58:27,362 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2015-09-01 20:58:27,373 INFO org.apache.hadoop.util.GSet: Computing capacity for map Namenode Retry Cache
2015-09-01 20:58:27,373 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-09-01 20:58:27,373 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory = 889 MB
2015-09-01 20:58:27,374 INFO org.apache.hadoop.util.GSet: capacity      = 2^16 = 65536 entries
2015-09-01 20:58:27,446 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/liyaohui/hadoop/tmp/dfs/name/in_use.lock acquired by nodename 2738@ubuntu01
2015-09-01 20:58:27,524 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/liyaohui/hadoop/tmp/dfs/name/current
2015-09-01 20:58:27,634 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000004972 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004972-0000000000000005074
2015-09-01 20:58:27,661 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004971 using no compression
2015-09-01 20:58:27,662 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 692
2015-09-01 20:58:27,710 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2015-09-01 20:58:27,710 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004971 of size 77152 bytes loaded in 0 seconds.
2015-09-01 20:58:27,710 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 4971 from /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004971
2015-09-01 20:58:27,710 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1e7a160 expecting start txid #4972
2015-09-01 20:58:27,710 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004972-0000000000000005074
2015-09-01 20:58:27,712 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004972-0000000000000005074' to transaction ID 4972
2015-09-01 20:58:27,744 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000004972-0000000000000005074 of size 1048576 edits # 103 loaded in 0 seconds
2015-09-01 20:58:27,752 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage.ckpt_0000000000000005074 using no compression
2015-09-01 20:58:27,803 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage.ckpt_0000000000000005074 of size 77710 bytes saved in 0 seconds.
2015-09-01 20:58:27,859 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 4971
2015-09-01 20:58:27,859 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004902, cpktTxId=0000000000000004902)
2015-09-01 20:58:27,900 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 5075
2015-09-01 20:58:28,202 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 3 entries 45 lookups
2015-09-01 20:58:28,202 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 827 msecs
2015-09-01 20:58:28,667 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ubuntu01:9000
2015-09-01 20:58:28,711 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2015-09-01 20:58:28,755 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2015-09-01 20:58:28,792 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2015-09-01 20:58:28,793 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2015-09-01 20:58:28,803 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 552 blocks to reach the threshold 0.9990 of total blocks 552.
Safe mode will be turned off automatically
2015-09-01 20:58:28,834 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-09-01 20:58:28,834 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2015-09-01 20:58:28,841 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ubuntu01/127.0.1.1:9000
2015-09-01 20:58:28,841 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2015-09-01 20:58:31,407 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1, storageID=DS-1927886287-127.0.1.1-50010-1436049057919, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62;nsid=783537164;c=0) storage DS-1927886287-127.0.1.1-50010-1436049057919
2015-09-01 20:58:31,409 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2015-09-01 20:58:31,545 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 551 has reached the threshold 0.9990 of total blocks 552. The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically in 29 seconds.
2015-09-01 20:58:31,545 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2015-09-01 20:58:31,561 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 552
2015-09-01 20:58:31,562 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2015-09-01 20:58:31,562 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 4
2015-09-01 20:58:31,562 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2015-09-01 20:58:31,562 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2015-09-01 20:58:31,562 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 17 msec
2015-09-01 20:58:31,562 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 127.0.0.1:50010 after starting up or becoming active. Its block contents are no longer considered stale
2015-09-01 20:58:31,562 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(127.0.0.1, storageID=DS-1927886287-127.0.1.1-50010-1436049057919, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62;nsid=783537164;c=0), blocks: 552, processing time: 31 msecs
2015-09-01 20:58:51,564 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 552 has reached the threshold 0.9990 of total blocks 552. The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically in 9 seconds.
2015-09-01 20:59:01,565 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 34 secs
2015-09-01 20:59:01,566 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2015-09-01 20:59:01,566 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2015-09-01 20:59:01,566 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 3 blocks
2015-09-01 20:59:35,471 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-09-01 20:59:35,471 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-09-01 20:59:35,471 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 5075
2015-09-01 20:59:35,471 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 56 
2015-09-01 20:59:35,488 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 73 
2015-09-01 20:59:35,489 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000005075 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000005075-0000000000000005076
2015-09-01 20:59:35,489 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 5077
2015-09-01 20:59:36,143 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=5076&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-01 20:59:36,278 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.13s at 559.70 KB/s
2015-09-01 20:59:36,278 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000005076 size 77710 bytes.
2015-09-01 20:59:36,309 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5074
2015-09-01 20:59:36,309 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000004971, cpktTxId=0000000000000004971)
2015-09-01 21:06:07,242 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-09-01 21:06:07,665 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 21:06:07,677 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 21:06:07,704 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 21:06:07,705 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 21:06:09,777 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 21:06:09,777 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 21:06:09,785 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 21:06:09,786 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 21:06:12,577 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 21:06:12,578 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 21:06:12,584 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 21:06:12,585 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 21:06:14,574 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 21:06:14,575 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 21:06:14,595 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 21:06:14,595 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 21:06:14,642 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 21:06:14,642 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 21:06:14,649 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 21:06:14,649 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 21:06:14,655 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 21:06:14,656 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 21:06:14,823 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 21:06:14,823 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 21:23:44,469 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 21:23:44,469 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 21:23:44,474 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 21:23:44,475 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 21:23:44,534 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 21:23:44,535 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 21:23:44,541 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 21:23:44,542 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 21:23:44,547 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 21:23:44,547 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 21:23:44,566 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 21:23:44,566 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 21:59:36,647 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-09-01 21:59:36,647 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-09-01 21:59:36,647 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 5077
2015-09-01 21:59:36,647 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 58 
2015-09-01 21:59:36,658 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 69 
2015-09-01 21:59:36,659 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000005077 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000005077-0000000000000005079
2015-09-01 21:59:36,659 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 5080
2015-09-01 21:59:36,876 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=5079&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-01 21:59:36,927 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 1470.59 KB/s
2015-09-01 21:59:36,928 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000005079 size 77710 bytes.
2015-09-01 21:59:36,959 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5076
2015-09-01 21:59:36,959 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000005074, cpktTxId=0000000000000005074)
2015-09-01 22:14:51,086 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:14:51,086 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:14:51,092 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:14:51,092 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:14:51,144 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:14:51,144 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:14:51,150 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:14:51,150 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:14:51,156 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:14:51,156 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:14:51,187 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:14:51,188 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:14:55,094 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:14:55,095 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:14:55,100 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:14:55,100 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:14:57,542 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:14:57,543 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:14:57,550 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:14:57,550 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:14:57,569 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:14:57,569 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:14:57,574 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:14:57,575 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:14:57,581 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:14:57,581 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:14:57,674 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:14:57,675 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:15:03,845 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-09-01 22:15:03,858 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:15:03,859 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:15:03,864 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:15:03,864 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:16:05,935 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:16:05,936 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:16:05,940 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:16:05,941 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:16:07,704 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:16:07,705 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:16:07,711 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:16:07,711 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:16:09,102 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:16:09,102 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:16:09,107 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:16:09,108 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:16:09,124 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:16:09,125 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:16:09,130 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:16:09,131 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:16:09,137 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:16:09,137 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:16:09,146 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:16:09,146 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:27:25,573 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(127.0.0.1, storageID=DS-1927886287-127.0.1.1-50010-1436049057919, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62;nsid=783537164;c=0), blocks: 552, processing time: 3 msecs
2015-09-01 22:28:17,637 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:28:17,638 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:28:17,643 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:28:17,643 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:28:18,800 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:28:18,801 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:28:18,806 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:28:18,806 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:30:02,957 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2015-09-01 22:30:02,958 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ubuntu01/127.0.1.1
************************************************************/
2015-09-01 22:32:54,880 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-09-01 22:32:54,892 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-09-01 22:32:55,106 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-09-01 22:32:55,197 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-09-01 22:32:55,198 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2015-09-01 22:32:55,303 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-01 22:32:55,452 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-09-01 22:32:55,504 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-09-01 22:32:55,506 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2015-09-01 22:32:55,506 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-09-01 22:32:55,506 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-09-01 22:32:55,519 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2015-09-01 22:32:55,532 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2015-09-01 22:32:55,532 INFO org.mortbay.log: jetty-6.1.26
2015-09-01 22:32:55,821 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2015-09-01 22:32:55,821 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2015-09-01 22:32:55,846 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2015-09-01 22:32:55,846 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2015-09-01 22:32:55,903 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2015-09-01 22:32:55,904 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2015-09-01 22:32:55,906 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-09-01 22:32:55,908 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-09-01 22:32:55,908 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-09-01 22:32:55,909 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2015-09-01 22:32:55,909 INFO org.apache.hadoop.util.GSet: capacity      = 2^22 = 4194304 entries
2015-09-01 22:32:55,921 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-09-01 22:32:55,921 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-09-01 22:32:55,921 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-09-01 22:32:55,921 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-09-01 22:32:55,921 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-09-01 22:32:55,921 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-09-01 22:32:55,922 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-09-01 22:32:55,922 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-09-01 22:32:55,928 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = liyaohui (auth:SIMPLE)
2015-09-01 22:32:55,928 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-09-01 22:32:55,928 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = false
2015-09-01 22:32:55,928 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-09-01 22:32:55,929 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-09-01 22:32:56,186 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-09-01 22:32:56,186 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-09-01 22:32:56,186 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2015-09-01 22:32:56,186 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-09-01 22:32:56,189 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-09-01 22:32:56,193 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-09-01 22:32:56,193 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-09-01 22:32:56,193 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-09-01 22:32:56,194 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2015-09-01 22:32:56,194 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2015-09-01 22:32:56,196 INFO org.apache.hadoop.util.GSet: Computing capacity for map Namenode Retry Cache
2015-09-01 22:32:56,196 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-09-01 22:32:56,196 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory = 889 MB
2015-09-01 22:32:56,196 INFO org.apache.hadoop.util.GSet: capacity      = 2^16 = 65536 entries
2015-09-01 22:32:56,239 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/liyaohui/hadoop/tmp/dfs/name/in_use.lock acquired by nodename 6724@ubuntu01
2015-09-01 22:32:56,276 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/liyaohui/hadoop/tmp/dfs/name/current
2015-09-01 22:32:56,324 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000005080 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000005080-0000000000000005080
2015-09-01 22:32:56,342 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000005079 using no compression
2015-09-01 22:32:56,342 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 696
2015-09-01 22:32:56,388 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2015-09-01 22:32:56,389 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000005079 of size 77710 bytes loaded in 0 seconds.
2015-09-01 22:32:56,389 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 5079 from /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000005079
2015-09-01 22:32:56,389 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@669da8 expecting start txid #5080
2015-09-01 22:32:56,389 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000005080-0000000000000005080
2015-09-01 22:32:56,391 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000005080-0000000000000005080' to transaction ID 5080
2015-09-01 22:32:56,395 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000005080-0000000000000005080 of size 1048576 edits # 1 loaded in 0 seconds
2015-09-01 22:32:56,401 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 5081
2015-09-01 22:32:56,678 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 3 entries 45 lookups
2015-09-01 22:32:56,678 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 480 msecs
2015-09-01 22:32:56,868 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ubuntu01:9000
2015-09-01 22:32:56,889 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2015-09-01 22:32:56,910 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2015-09-01 22:32:56,919 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2015-09-01 22:32:56,919 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2015-09-01 22:32:56,920 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 552 blocks to reach the threshold 0.9990 of total blocks 552.
Safe mode will be turned off automatically
2015-09-01 22:32:56,940 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2015-09-01 22:32:56,941 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-09-01 22:32:56,943 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ubuntu01/127.0.1.1:9000
2015-09-01 22:32:56,944 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2015-09-01 22:33:06,165 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1, storageID=DS-1927886287-127.0.1.1-50010-1436049057919, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62;nsid=783537164;c=0) storage DS-1927886287-127.0.1.1-50010-1436049057919
2015-09-01 22:33:06,168 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2015-09-01 22:33:06,295 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 551 has reached the threshold 0.9990 of total blocks 552. The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically in 29 seconds.
2015-09-01 22:33:06,295 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2015-09-01 22:33:06,313 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 552
2015-09-01 22:33:06,313 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2015-09-01 22:33:06,313 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 4
2015-09-01 22:33:06,313 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2015-09-01 22:33:06,313 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2015-09-01 22:33:06,313 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 18 msec
2015-09-01 22:33:06,314 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 127.0.0.1:50010 after starting up or becoming active. Its block contents are no longer considered stale
2015-09-01 22:33:06,314 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(127.0.0.1, storageID=DS-1927886287-127.0.1.1-50010-1436049057919, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62;nsid=783537164;c=0), blocks: 552, processing time: 39 msecs
2015-09-01 22:33:26,317 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 552 has reached the threshold 0.9990 of total blocks 552. The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically in 9 seconds.
2015-09-01 22:33:36,318 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 40 secs
2015-09-01 22:33:36,318 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2015-09-01 22:33:36,318 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2015-09-01 22:33:36,318 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 3 blocks
2015-09-01 22:34:05,896 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-09-01 22:34:05,896 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-09-01 22:34:05,897 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 5081
2015-09-01 22:34:05,897 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 64 
2015-09-01 22:34:05,905 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 72 
2015-09-01 22:34:05,907 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000005081 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000005081-0000000000000005082
2015-09-01 22:34:05,907 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 5083
2015-09-01 22:34:06,546 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=5082&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-01 22:34:06,687 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.14s at 535.71 KB/s
2015-09-01 22:34:06,687 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000005082 size 77710 bytes.
2015-09-01 22:34:06,720 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5079
2015-09-01 22:34:06,720 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000005076, cpktTxId=0000000000000005076)
2015-09-01 22:40:45,015 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 74 
2015-09-01 22:40:45,086 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /input1. BP-1159783791-127.0.1.1-1436048545002 blk_1073742568_1744{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-09-01 22:40:45,291 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742568_1744{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-09-01 22:40:45,312 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /input1 is closed by DFSClient_NONMAPREDUCE_-1235580600_1
2015-09-01 22:40:58,551 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:40:58,552 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:40:58,573 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:40:58,574 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:41:00,653 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:41:00,653 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:41:00,664 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:41:00,665 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:41:00,737 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:41:00,738 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:41:00,747 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:41:00,748 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:41:00,797 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-01 22:41:00,797 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-01 22:41:21,511 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2015-09-01 22:41:21,517 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ubuntu01/127.0.1.1
************************************************************/
2015-09-02 09:16:29,900 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ubuntu01/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/liyaohui/hadoop/etc/hadoop:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-math-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/liyaohui/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-06-25T14:34Z
STARTUP_MSG:   java = 1.8.0_45
************************************************************/
2015-09-02 09:16:29,919 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-09-02 09:16:30,281 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-09-02 09:16:30,561 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-09-02 09:16:30,561 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2015-09-02 09:16:30,681 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-02 09:16:30,884 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-09-02 09:16:30,943 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2015-09-02 09:16:30,945 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2015-09-02 09:16:30,945 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-09-02 09:16:30,945 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-09-02 09:16:30,994 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2015-09-02 09:16:31,043 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2015-09-02 09:16:31,043 INFO org.mortbay.log: jetty-6.1.26
2015-09-02 09:16:31,514 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2015-09-02 09:16:31,514 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: 0.0.0.0:50070
2015-09-02 09:16:31,601 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2015-09-02 09:16:31,601 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2015-09-02 09:16:31,680 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2015-09-02 09:16:31,680 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2015-09-02 09:16:31,683 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-09-02 09:16:31,685 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-09-02 09:16:31,685 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-09-02 09:16:31,686 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2015-09-02 09:16:31,686 INFO org.apache.hadoop.util.GSet: capacity      = 2^22 = 4194304 entries
2015-09-02 09:16:31,698 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-09-02 09:16:31,699 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2015-09-02 09:16:31,699 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-09-02 09:16:31,699 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-09-02 09:16:31,699 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-09-02 09:16:31,699 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-09-02 09:16:31,699 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-09-02 09:16:31,699 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-09-02 09:16:31,705 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = liyaohui (auth:SIMPLE)
2015-09-02 09:16:31,705 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-09-02 09:16:31,705 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = false
2015-09-02 09:16:31,706 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-09-02 09:16:31,707 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-09-02 09:16:32,272 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-09-02 09:16:32,272 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-09-02 09:16:32,272 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2015-09-02 09:16:32,272 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-09-02 09:16:32,275 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-09-02 09:16:32,279 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-09-02 09:16:32,279 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-09-02 09:16:32,279 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-09-02 09:16:32,281 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2015-09-02 09:16:32,281 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2015-09-02 09:16:32,292 INFO org.apache.hadoop.util.GSet: Computing capacity for map Namenode Retry Cache
2015-09-02 09:16:32,292 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-09-02 09:16:32,292 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory = 889 MB
2015-09-02 09:16:32,292 INFO org.apache.hadoop.util.GSet: capacity      = 2^16 = 65536 entries
2015-09-02 09:16:32,357 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/liyaohui/hadoop/tmp/dfs/name/in_use.lock acquired by nodename 2605@ubuntu01
2015-09-02 09:16:32,432 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/liyaohui/hadoop/tmp/dfs/name/current
2015-09-02 09:16:32,551 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000005083 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000005083-0000000000000005088
2015-09-02 09:16:32,583 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000005082 using no compression
2015-09-02 09:16:32,583 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 696
2015-09-02 09:16:32,628 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2015-09-02 09:16:32,628 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000005082 of size 77710 bytes loaded in 0 seconds.
2015-09-02 09:16:32,629 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 5082 from /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000005082
2015-09-02 09:16:32,629 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1e7a160 expecting start txid #5083
2015-09-02 09:16:32,629 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000005083-0000000000000005088
2015-09-02 09:16:32,631 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000005083-0000000000000005088' to transaction ID 5083
2015-09-02 09:16:32,653 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000005083-0000000000000005088 of size 1048576 edits # 6 loaded in 0 seconds
2015-09-02 09:16:32,661 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage.ckpt_0000000000000005088 using no compression
2015-09-02 09:16:32,703 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /home/liyaohui/hadoop/tmp/dfs/name/current/fsimage.ckpt_0000000000000005088 of size 77806 bytes saved in 0 seconds.
2015-09-02 09:16:32,757 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5082
2015-09-02 09:16:32,758 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000005079, cpktTxId=0000000000000005079)
2015-09-02 09:16:32,799 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 5089
2015-09-02 09:16:33,102 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 3 entries 45 lookups
2015-09-02 09:16:33,102 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 808 msecs
2015-09-02 09:16:33,648 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ubuntu01:9000
2015-09-02 09:16:33,692 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2015-09-02 09:16:33,742 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2015-09-02 09:16:33,791 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2015-09-02 09:16:33,792 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2015-09-02 09:16:33,803 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 553 blocks to reach the threshold 0.9990 of total blocks 553.
Safe mode will be turned off automatically
2015-09-02 09:16:33,828 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-09-02 09:16:33,830 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2015-09-02 09:16:33,833 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ubuntu01/127.0.1.1:9000
2015-09-02 09:16:33,833 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2015-09-02 09:16:36,663 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1, storageID=DS-1927886287-127.0.1.1-50010-1436049057919, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62;nsid=783537164;c=0) storage DS-1927886287-127.0.1.1-50010-1436049057919
2015-09-02 09:16:36,666 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:50010
2015-09-02 09:16:36,797 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 552 has reached the threshold 0.9990 of total blocks 553. The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically in 29 seconds.
2015-09-02 09:16:36,797 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2015-09-02 09:16:36,812 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 553
2015-09-02 09:16:36,812 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2015-09-02 09:16:36,812 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 4
2015-09-02 09:16:36,812 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2015-09-02 09:16:36,812 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2015-09-02 09:16:36,812 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 15 msec
2015-09-02 09:16:36,813 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 127.0.0.1:50010 after starting up or becoming active. Its block contents are no longer considered stale
2015-09-02 09:16:36,813 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(127.0.0.1, storageID=DS-1927886287-127.0.1.1-50010-1436049057919, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62;nsid=783537164;c=0), blocks: 553, processing time: 27 msecs
2015-09-02 09:16:56,815 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 553 has reached the threshold 0.9990 of total blocks 553. The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically in 9 seconds.
2015-09-02 09:17:06,816 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 35 secs
2015-09-02 09:17:06,816 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2015-09-02 09:17:06,816 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2015-09-02 09:17:06,817 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 3 blocks
2015-09-02 09:17:40,660 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-09-02 09:17:40,660 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-09-02 09:17:40,660 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 5089
2015-09-02 09:17:40,660 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 69 
2015-09-02 09:17:40,681 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 86 
2015-09-02 09:17:40,682 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000005089 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000005089-0000000000000005090
2015-09-02 09:17:40,682 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 5091
2015-09-02 09:17:41,693 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=5090&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-02 09:17:41,866 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.17s at 438.60 KB/s
2015-09-02 09:17:41,866 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000005090 size 77806 bytes.
2015-09-02 09:17:41,958 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5088
2015-09-02 09:17:41,958 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000005082, cpktTxId=0000000000000005082)
2015-09-02 10:17:42,192 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-09-02 10:17:42,192 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-09-02 10:17:42,192 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 5091
2015-09-02 10:17:42,192 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 93 
2015-09-02 10:17:42,200 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 101 
2015-09-02 10:17:42,200 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000005091 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000005091-0000000000000005092
2015-09-02 10:17:42,200 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 5093
2015-09-02 10:17:42,467 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=5092&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-02 10:17:42,508 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 1785.71 KB/s
2015-09-02 10:17:42,508 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000005092 size 77806 bytes.
2015-09-02 10:17:42,540 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5090
2015-09-02 10:17:42,540 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000005088, cpktTxId=0000000000000005088)
2015-09-02 11:17:42,781 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-09-02 11:17:42,781 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-09-02 11:17:42,781 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 5093
2015-09-02 11:17:42,781 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 68 
2015-09-02 11:17:42,789 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 76 
2015-09-02 11:17:42,790 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000005093 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000005093-0000000000000005094
2015-09-02 11:17:42,790 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 5095
2015-09-02 11:17:43,006 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=5094&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-02 11:17:43,046 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 1923.08 KB/s
2015-09-02 11:17:43,046 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000005094 size 77806 bytes.
2015-09-02 11:17:43,077 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5092
2015-09-02 11:17:43,077 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000005090, cpktTxId=0000000000000005090)
2015-09-02 12:17:43,330 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-09-02 12:17:43,330 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-09-02 12:17:43,330 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 5095
2015-09-02 12:17:43,330 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 73 
2015-09-02 12:17:43,342 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 85 
2015-09-02 12:17:43,342 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000005095 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000005095-0000000000000005096
2015-09-02 12:17:43,343 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 5097
2015-09-02 12:17:43,567 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=5096&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-02 12:17:43,616 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.05s at 1530.61 KB/s
2015-09-02 12:17:43,616 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000005096 size 77806 bytes.
2015-09-02 12:17:43,647 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5094
2015-09-02 12:17:43,647 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000005092, cpktTxId=0000000000000005092)
2015-09-02 13:17:43,886 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-09-02 13:17:43,887 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-09-02 13:17:43,887 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 5097
2015-09-02 13:17:43,888 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 75 
2015-09-02 13:17:43,896 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 83 
2015-09-02 13:17:43,897 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000005097 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000005097-0000000000000005098
2015-09-02 13:17:43,897 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 5099
2015-09-02 13:17:44,096 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=5098&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-02 13:17:44,138 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 1829.27 KB/s
2015-09-02 13:17:44,138 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000005098 size 77806 bytes.
2015-09-02 13:17:44,159 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5096
2015-09-02 13:17:44,159 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000005094, cpktTxId=0000000000000005094)
2015-09-02 13:35:37,046 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(127.0.0.1, storageID=DS-1927886287-127.0.1.1-50010-1436049057919, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62;nsid=783537164;c=0), blocks: 553, processing time: 4 msecs
2015-09-02 14:17:44,385 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-09-02 14:17:44,385 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-09-02 14:17:44,385 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 5099
2015-09-02 14:17:44,385 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 67 
2015-09-02 14:17:44,393 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 75 
2015-09-02 14:17:44,394 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000005099 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000005099-0000000000000005100
2015-09-02 14:17:44,394 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 5101
2015-09-02 14:17:44,605 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=5100&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-02 14:17:44,645 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 1875.00 KB/s
2015-09-02 14:17:44,645 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000005100 size 77806 bytes.
2015-09-02 14:17:44,677 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5098
2015-09-02 14:17:44,677 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000005096, cpktTxId=0000000000000005096)
2015-09-02 15:17:44,855 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-09-02 15:17:44,856 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-09-02 15:17:44,856 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 5101
2015-09-02 15:17:44,856 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 66 
2015-09-02 15:17:44,868 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 78 
2015-09-02 15:17:44,868 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000005101 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000005101-0000000000000005102
2015-09-02 15:17:44,869 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 5103
2015-09-02 15:17:45,074 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=5102&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-02 15:17:45,118 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 1704.55 KB/s
2015-09-02 15:17:45,118 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000005102 size 77806 bytes.
2015-09-02 15:17:45,150 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5100
2015-09-02 15:17:45,150 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000005098, cpktTxId=0000000000000005098)
2015-09-02 16:00:01,373 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-09-02 16:00:01,701 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:01,712 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:01,797 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:01,797 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:03,777 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:03,778 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:03,788 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:03,788 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:10,909 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:10,910 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:10,932 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:10,933 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:11,007 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:11,007 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:11,018 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:11,018 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:11,143 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:11,143 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:13,869 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:13,869 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:13,875 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:13,875 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:16,022 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:16,022 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:16,027 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:16,027 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:16,049 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:16,049 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:16,055 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:16,055 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:16,065 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:16,065 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:16,117 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:16,118 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:25,991 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:25,992 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:25,996 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:25,996 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:27,968 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:27,969 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:27,974 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:27,974 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:27,992 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:28,002 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:28,013 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:28,014 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:28,028 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:28,029 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:28,059 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:28,060 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:37,197 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:37,198 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:37,202 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:37,202 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:37,261 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:37,262 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:37,267 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:37,267 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:37,272 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:37,272 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:00:37,306 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:00:37,307 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:01:57,459 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 6 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 68 
2015-09-02 16:01:57,470 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742568_1744 127.0.0.1:50010 
2015-09-02 16:01:58,733 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742568_1744]
2015-09-02 16:02:00,929 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:02:00,929 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:02:00,934 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:02:00,935 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:02:05,698 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:02:05,699 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:02:05,704 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:02:05,705 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:02:11,424 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:02:11,424 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:02:11,429 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:02:11,430 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:03:34,613 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 7 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 78 
2015-09-02 16:03:34,622 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742462_1638 127.0.0.1:50010 
2015-09-02 16:03:34,737 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742462_1638]
2015-09-02 16:03:44,013 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:03:44,014 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:03:44,019 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:03:44,019 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:03:53,196 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741825_1001 127.0.0.1:50010 
2015-09-02 16:03:53,196 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741826_1002 127.0.0.1:50010 
2015-09-02 16:03:53,196 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741827_1003 127.0.0.1:50010 
2015-09-02 16:03:53,196 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741828_1004 127.0.0.1:50010 
2015-09-02 16:03:53,196 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741829_1005 127.0.0.1:50010 
2015-09-02 16:03:53,196 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741830_1006 127.0.0.1:50010 
2015-09-02 16:03:53,196 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741831_1007 127.0.0.1:50010 
2015-09-02 16:03:53,196 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741832_1008 127.0.0.1:50010 
2015-09-02 16:03:53,196 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741833_1009 127.0.0.1:50010 
2015-09-02 16:03:53,196 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741834_1010 127.0.0.1:50010 
2015-09-02 16:03:53,196 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741835_1011 127.0.0.1:50010 
2015-09-02 16:03:53,196 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741836_1012 127.0.0.1:50010 
2015-09-02 16:03:53,196 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741837_1013 127.0.0.1:50010 
2015-09-02 16:03:53,196 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741838_1014 127.0.0.1:50010 
2015-09-02 16:03:53,196 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741839_1015 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741840_1016 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741841_1017 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741842_1018 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741843_1019 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741844_1020 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741845_1021 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741846_1022 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741847_1023 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741848_1024 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741849_1025 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741850_1026 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741851_1027 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741852_1028 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741853_1029 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741854_1030 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741855_1031 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741856_1032 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741857_1033 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741858_1034 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741859_1035 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741860_1036 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741861_1037 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741862_1038 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741863_1039 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741864_1040 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741865_1041 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741866_1042 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741867_1043 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741868_1044 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741869_1045 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741870_1046 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741871_1047 127.0.0.1:50010 
2015-09-02 16:03:53,197 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741872_1048 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741873_1049 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741874_1050 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741875_1051 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741876_1052 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741877_1053 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741878_1054 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741879_1055 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741880_1056 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741881_1057 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741882_1058 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741883_1059 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741884_1060 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741885_1061 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741886_1062 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741887_1063 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741888_1064 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741889_1065 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741890_1066 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741891_1067 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741892_1068 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741893_1069 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741894_1070 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741895_1071 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741896_1072 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741897_1073 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741898_1074 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741899_1075 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741900_1076 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741901_1077 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741902_1078 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741903_1079 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741904_1080 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741905_1081 127.0.0.1:50010 
2015-09-02 16:03:53,198 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741906_1082 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741907_1083 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741908_1084 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741909_1085 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741910_1086 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741911_1087 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741912_1088 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741913_1089 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741914_1090 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741915_1091 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741916_1092 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741917_1093 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741918_1094 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741919_1095 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741920_1096 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741921_1097 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741922_1098 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741923_1099 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741924_1100 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741925_1101 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741926_1102 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741927_1103 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741928_1104 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741929_1105 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741930_1106 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741931_1107 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741932_1108 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741933_1109 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741934_1110 127.0.0.1:50010 
2015-09-02 16:03:53,199 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741935_1111 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741936_1112 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741937_1113 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741938_1114 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741939_1115 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741940_1116 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741941_1117 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741942_1118 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741943_1119 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741944_1120 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741945_1121 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741946_1122 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741947_1123 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741948_1124 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741949_1125 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741950_1126 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741951_1127 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741952_1128 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741953_1129 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741954_1130 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741955_1131 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741956_1132 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741957_1133 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741958_1134 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741959_1135 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741960_1136 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741961_1137 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741962_1138 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741963_1139 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741964_1140 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741965_1141 127.0.0.1:50010 
2015-09-02 16:03:53,200 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741966_1142 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741967_1143 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741968_1144 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741969_1145 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741970_1146 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741971_1147 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741972_1148 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741973_1149 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741974_1150 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741975_1151 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741976_1152 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741977_1153 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741978_1154 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741979_1155 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741980_1156 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741981_1157 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741982_1158 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741983_1159 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741984_1160 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741985_1161 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741986_1162 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741987_1163 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741988_1164 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741989_1165 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741990_1166 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741991_1167 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741992_1168 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741993_1169 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741994_1170 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741995_1171 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741996_1172 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741997_1173 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741998_1174 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741999_1175 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742000_1176 127.0.0.1:50010 
2015-09-02 16:03:53,201 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742001_1177 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742002_1178 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742003_1179 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742004_1180 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742005_1181 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742006_1182 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742007_1183 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742008_1184 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742009_1185 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742010_1186 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742011_1187 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742012_1188 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742013_1189 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742014_1190 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742015_1191 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742016_1192 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742017_1193 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742018_1194 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742019_1195 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742020_1196 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742021_1197 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742022_1198 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742023_1199 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742024_1200 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742025_1201 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742026_1202 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742027_1203 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742028_1204 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742029_1205 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742030_1206 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742031_1207 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742032_1208 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742033_1209 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742034_1210 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742035_1211 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742036_1212 127.0.0.1:50010 
2015-09-02 16:03:53,202 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742037_1213 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742038_1214 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742039_1215 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742040_1216 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742041_1217 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742042_1218 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742043_1219 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742044_1220 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742045_1221 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742046_1222 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742047_1223 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742048_1224 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742049_1225 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742050_1226 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742051_1227 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742052_1228 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742053_1229 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742054_1230 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742055_1231 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742056_1232 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742057_1233 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742058_1234 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742059_1235 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742060_1236 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742061_1237 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742062_1238 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742063_1239 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742064_1240 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742065_1241 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742066_1242 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742067_1243 127.0.0.1:50010 
2015-09-02 16:03:53,203 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742068_1244 127.0.0.1:50010 
2015-09-02 16:03:53,204 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742069_1245 127.0.0.1:50010 
2015-09-02 16:03:53,204 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742070_1246 127.0.0.1:50010 
2015-09-02 16:03:53,204 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742071_1247 127.0.0.1:50010 
2015-09-02 16:03:53,204 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742072_1248 127.0.0.1:50010 
2015-09-02 16:03:53,204 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742073_1249 127.0.0.1:50010 
2015-09-02 16:03:53,204 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742074_1250 127.0.0.1:50010 
2015-09-02 16:03:53,204 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742075_1251 127.0.0.1:50010 
2015-09-02 16:03:53,204 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742076_1252 127.0.0.1:50010 
2015-09-02 16:03:53,204 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742077_1253 127.0.0.1:50010 
2015-09-02 16:03:53,204 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742078_1254 127.0.0.1:50010 
2015-09-02 16:03:53,204 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742079_1255 127.0.0.1:50010 
2015-09-02 16:03:53,204 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742080_1256 127.0.0.1:50010 
2015-09-02 16:03:53,204 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742081_1257 127.0.0.1:50010 
2015-09-02 16:03:53,204 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742082_1258 127.0.0.1:50010 
2015-09-02 16:03:53,204 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742083_1259 127.0.0.1:50010 
2015-09-02 16:03:53,204 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742084_1260 127.0.0.1:50010 
2015-09-02 16:03:53,204 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742085_1261 127.0.0.1:50010 
2015-09-02 16:03:53,204 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742086_1262 127.0.0.1:50010 
2015-09-02 16:03:53,204 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742087_1263 127.0.0.1:50010 
2015-09-02 16:03:53,204 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742088_1264 127.0.0.1:50010 
2015-09-02 16:03:53,204 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742089_1265 127.0.0.1:50010 
2015-09-02 16:03:53,204 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742090_1266 127.0.0.1:50010 
2015-09-02 16:03:53,206 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742091_1267 127.0.0.1:50010 
2015-09-02 16:03:53,206 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742092_1268 127.0.0.1:50010 
2015-09-02 16:03:53,206 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742093_1269 127.0.0.1:50010 
2015-09-02 16:03:53,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742094_1270 127.0.0.1:50010 
2015-09-02 16:03:53,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742095_1271 127.0.0.1:50010 
2015-09-02 16:03:53,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742096_1272 127.0.0.1:50010 
2015-09-02 16:03:53,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742097_1273 127.0.0.1:50010 
2015-09-02 16:03:53,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742098_1274 127.0.0.1:50010 
2015-09-02 16:03:53,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742099_1275 127.0.0.1:50010 
2015-09-02 16:03:53,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742100_1276 127.0.0.1:50010 
2015-09-02 16:03:53,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742101_1277 127.0.0.1:50010 
2015-09-02 16:03:53,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742102_1278 127.0.0.1:50010 
2015-09-02 16:03:53,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742103_1279 127.0.0.1:50010 
2015-09-02 16:03:53,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742104_1280 127.0.0.1:50010 
2015-09-02 16:03:53,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742105_1281 127.0.0.1:50010 
2015-09-02 16:03:53,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742106_1282 127.0.0.1:50010 
2015-09-02 16:03:53,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742107_1283 127.0.0.1:50010 
2015-09-02 16:03:53,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742108_1284 127.0.0.1:50010 
2015-09-02 16:03:53,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742109_1285 127.0.0.1:50010 
2015-09-02 16:03:53,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742110_1286 127.0.0.1:50010 
2015-09-02 16:03:53,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742111_1287 127.0.0.1:50010 
2015-09-02 16:03:53,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742112_1288 127.0.0.1:50010 
2015-09-02 16:03:53,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742113_1289 127.0.0.1:50010 
2015-09-02 16:03:53,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742114_1290 127.0.0.1:50010 
2015-09-02 16:03:53,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742115_1291 127.0.0.1:50010 
2015-09-02 16:03:53,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742116_1292 127.0.0.1:50010 
2015-09-02 16:03:53,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742117_1293 127.0.0.1:50010 
2015-09-02 16:03:53,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742118_1294 127.0.0.1:50010 
2015-09-02 16:03:53,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742119_1295 127.0.0.1:50010 
2015-09-02 16:03:53,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742120_1296 127.0.0.1:50010 
2015-09-02 16:03:53,207 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742121_1297 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742122_1298 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742123_1299 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742124_1300 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742125_1301 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742126_1302 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742127_1303 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742128_1304 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742129_1305 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742130_1306 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742131_1307 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742132_1308 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742133_1309 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742134_1310 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742135_1311 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742136_1312 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742137_1313 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742138_1314 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742139_1315 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742140_1316 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742141_1317 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742142_1318 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742143_1319 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742144_1320 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742145_1321 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742146_1322 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742147_1323 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742148_1324 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742149_1325 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742150_1326 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742151_1327 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742152_1328 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742153_1329 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742154_1330 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742155_1331 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742156_1332 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742157_1333 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742158_1334 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742159_1335 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742160_1336 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742161_1337 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742162_1338 127.0.0.1:50010 
2015-09-02 16:03:53,208 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742163_1339 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742164_1340 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742165_1341 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742166_1342 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742167_1343 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742168_1344 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742169_1345 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742170_1346 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742171_1347 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742172_1348 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742173_1349 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742174_1350 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742175_1351 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742176_1352 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742177_1353 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742178_1354 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742179_1355 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742180_1356 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742181_1357 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742182_1358 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742183_1359 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742184_1360 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742185_1361 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742186_1362 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742187_1363 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742188_1364 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742189_1365 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742190_1366 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742191_1367 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742192_1368 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742193_1369 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742194_1370 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742195_1371 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742196_1372 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742197_1373 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742198_1374 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742199_1375 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742200_1376 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742201_1377 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742202_1378 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742203_1379 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742204_1380 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742205_1381 127.0.0.1:50010 
2015-09-02 16:03:53,209 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742206_1382 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742207_1383 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742208_1384 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742209_1385 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742210_1386 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742211_1387 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742212_1388 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742213_1389 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742214_1390 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742215_1391 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742216_1392 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742217_1393 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742218_1394 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742219_1395 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742220_1396 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742221_1397 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742222_1398 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742223_1399 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742224_1400 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742225_1401 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742226_1402 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742227_1403 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742228_1404 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742229_1405 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742230_1406 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742231_1407 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742232_1408 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742233_1409 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742234_1410 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742235_1411 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742236_1412 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742237_1413 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742238_1414 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742239_1415 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742240_1416 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742241_1417 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742242_1418 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742243_1419 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742244_1420 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742245_1421 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742246_1422 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742247_1423 127.0.0.1:50010 
2015-09-02 16:03:53,210 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742248_1424 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742249_1425 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742250_1426 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742251_1427 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742252_1428 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742253_1429 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742254_1430 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742255_1431 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742256_1432 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742257_1433 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742258_1434 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742259_1435 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742260_1436 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742261_1437 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742262_1438 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742263_1439 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742264_1440 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742265_1441 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742266_1442 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742267_1443 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742268_1444 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742269_1445 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742270_1446 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742271_1447 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742272_1448 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742273_1449 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742274_1450 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742275_1451 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742276_1452 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742277_1453 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742278_1454 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742279_1455 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742280_1456 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742281_1457 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742282_1458 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742283_1459 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742284_1460 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742285_1461 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742286_1462 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742287_1463 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742288_1464 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742289_1465 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742290_1466 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742291_1467 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742292_1468 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742293_1469 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742294_1470 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742295_1471 127.0.0.1:50010 
2015-09-02 16:03:53,211 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742296_1472 127.0.0.1:50010 
2015-09-02 16:03:53,212 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742297_1473 127.0.0.1:50010 
2015-09-02 16:03:53,212 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742298_1474 127.0.0.1:50010 
2015-09-02 16:03:53,212 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742299_1475 127.0.0.1:50010 
2015-09-02 16:03:53,212 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742300_1476 127.0.0.1:50010 
2015-09-02 16:03:53,212 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742301_1477 127.0.0.1:50010 
2015-09-02 16:03:53,212 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742302_1478 127.0.0.1:50010 
2015-09-02 16:03:53,212 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742303_1479 127.0.0.1:50010 
2015-09-02 16:03:55,740 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073741825_1001, blk_1073741826_1002, blk_1073741827_1003, blk_1073741828_1004, blk_1073741829_1005, blk_1073741830_1006, blk_1073741831_1007, blk_1073741832_1008, blk_1073741833_1009, blk_1073741834_1010, blk_1073741835_1011, blk_1073741836_1012, blk_1073741837_1013, blk_1073741838_1014, blk_1073741839_1015, blk_1073741840_1016, blk_1073741841_1017, blk_1073741842_1018, blk_1073741843_1019, blk_1073741844_1020, blk_1073741845_1021, blk_1073741846_1022, blk_1073741847_1023, blk_1073741848_1024, blk_1073741849_1025, blk_1073741850_1026, blk_1073741851_1027, blk_1073741852_1028, blk_1073741853_1029, blk_1073741854_1030, blk_1073741855_1031, blk_1073741856_1032, blk_1073741857_1033, blk_1073741858_1034, blk_1073741859_1035, blk_1073741860_1036, blk_1073741861_1037, blk_1073741862_1038, blk_1073741863_1039, blk_1073741864_1040, blk_1073741865_1041, blk_1073741866_1042, blk_1073741867_1043, blk_1073741868_1044, blk_1073741869_1045, blk_1073741870_1046, blk_1073741871_1047, blk_1073741872_1048, blk_1073741873_1049, blk_1073741874_1050, blk_1073741875_1051, blk_1073741876_1052, blk_1073741877_1053, blk_1073741878_1054, blk_1073741879_1055, blk_1073741880_1056, blk_1073741881_1057, blk_1073741882_1058, blk_1073741883_1059, blk_1073741884_1060, blk_1073741885_1061, blk_1073741886_1062, blk_1073741887_1063, blk_1073741888_1064, blk_1073741889_1065, blk_1073741890_1066, blk_1073741891_1067, blk_1073741892_1068, blk_1073741893_1069, blk_1073741894_1070, blk_1073741895_1071, blk_1073741896_1072, blk_1073741897_1073, blk_1073741898_1074, blk_1073741899_1075, blk_1073741900_1076, blk_1073741901_1077, blk_1073741902_1078, blk_1073741903_1079, blk_1073741904_1080, blk_1073741905_1081, blk_1073741906_1082, blk_1073741907_1083, blk_1073741908_1084, blk_1073741909_1085, blk_1073741910_1086, blk_1073741911_1087, blk_1073741912_1088, blk_1073741913_1089, blk_1073741914_1090, blk_1073741915_1091, blk_1073741916_1092, blk_1073741917_1093, blk_1073741918_1094, blk_1073741919_1095, blk_1073741920_1096, blk_1073741921_1097, blk_1073741922_1098, blk_1073741923_1099, blk_1073741924_1100, blk_1073741925_1101, blk_1073741926_1102, blk_1073741927_1103, blk_1073741928_1104, blk_1073741929_1105, blk_1073741930_1106, blk_1073741931_1107, blk_1073741932_1108, blk_1073741933_1109, blk_1073741934_1110, blk_1073741935_1111, blk_1073741936_1112, blk_1073741937_1113, blk_1073741938_1114, blk_1073741939_1115, blk_1073741940_1116, blk_1073741941_1117, blk_1073741942_1118, blk_1073741943_1119, blk_1073741944_1120, blk_1073741945_1121, blk_1073741946_1122, blk_1073741947_1123, blk_1073741948_1124, blk_1073741949_1125, blk_1073741950_1126, blk_1073741951_1127, blk_1073741952_1128, blk_1073741953_1129, blk_1073741954_1130, blk_1073741955_1131, blk_1073741956_1132, blk_1073741957_1133, blk_1073741958_1134, blk_1073741959_1135, blk_1073741960_1136, blk_1073741961_1137, blk_1073741962_1138, blk_1073741963_1139, blk_1073741964_1140, blk_1073741965_1141, blk_1073741966_1142, blk_1073741967_1143, blk_1073741968_1144, blk_1073741969_1145, blk_1073741970_1146, blk_1073741971_1147, blk_1073741972_1148, blk_1073741973_1149, blk_1073741974_1150, blk_1073741975_1151, blk_1073741976_1152, blk_1073741977_1153, blk_1073741978_1154, blk_1073741979_1155, blk_1073741980_1156, blk_1073741981_1157, blk_1073741982_1158, blk_1073741983_1159, blk_1073741984_1160, blk_1073741985_1161, blk_1073741986_1162, blk_1073741987_1163, blk_1073741988_1164, blk_1073741989_1165, blk_1073741990_1166, blk_1073741991_1167, blk_1073741992_1168, blk_1073741993_1169, blk_1073741994_1170, blk_1073741995_1171, blk_1073741996_1172, blk_1073741997_1173, blk_1073741998_1174, blk_1073741999_1175, blk_1073742000_1176, blk_1073742001_1177, blk_1073742002_1178, blk_1073742003_1179, blk_1073742004_1180, blk_1073742005_1181, blk_1073742006_1182, blk_1073742007_1183, blk_1073742008_1184, blk_1073742009_1185, blk_1073742010_1186, blk_1073742011_1187, blk_1073742012_1188, blk_1073742013_1189, blk_1073742014_1190, blk_1073742015_1191, blk_1073742016_1192, blk_1073742017_1193, blk_1073742018_1194, blk_1073742019_1195, blk_1073742020_1196, blk_1073742021_1197, blk_1073742022_1198, blk_1073742023_1199, blk_1073742024_1200, blk_1073742025_1201, blk_1073742026_1202, blk_1073742027_1203, blk_1073742028_1204, blk_1073742029_1205, blk_1073742030_1206, blk_1073742031_1207, blk_1073742032_1208, blk_1073742033_1209, blk_1073742034_1210, blk_1073742035_1211, blk_1073742036_1212, blk_1073742037_1213, blk_1073742038_1214, blk_1073742039_1215, blk_1073742040_1216, blk_1073742041_1217, blk_1073742042_1218, blk_1073742043_1219, blk_1073742044_1220, blk_1073742045_1221, blk_1073742046_1222, blk_1073742047_1223, blk_1073742048_1224, blk_1073742049_1225, blk_1073742050_1226, blk_1073742051_1227, blk_1073742052_1228, blk_1073742053_1229, blk_1073742054_1230, blk_1073742055_1231, blk_1073742056_1232, blk_1073742057_1233, blk_1073742058_1234, blk_1073742059_1235, blk_1073742060_1236, blk_1073742061_1237, blk_1073742062_1238, blk_1073742063_1239, blk_1073742064_1240, blk_1073742065_1241, blk_1073742066_1242, blk_1073742067_1243, blk_1073742068_1244, blk_1073742069_1245, blk_1073742070_1246, blk_1073742071_1247, blk_1073742072_1248, blk_1073742073_1249, blk_1073742074_1250, blk_1073742075_1251, blk_1073742076_1252, blk_1073742077_1253, blk_1073742078_1254, blk_1073742079_1255, blk_1073742080_1256, blk_1073742081_1257, blk_1073742082_1258, blk_1073742083_1259, blk_1073742084_1260, blk_1073742085_1261, blk_1073742086_1262, blk_1073742087_1263, blk_1073742088_1264, blk_1073742089_1265, blk_1073742090_1266, blk_1073742091_1267, blk_1073742092_1268, blk_1073742093_1269, blk_1073742094_1270, blk_1073742095_1271, blk_1073742096_1272, blk_1073742097_1273, blk_1073742098_1274, blk_1073742099_1275, blk_1073742100_1276, blk_1073742101_1277, blk_1073742102_1278, blk_1073742103_1279, blk_1073742104_1280, blk_1073742105_1281, blk_1073742106_1282, blk_1073742107_1283, blk_1073742108_1284, blk_1073742109_1285, blk_1073742110_1286, blk_1073742111_1287, blk_1073742112_1288, blk_1073742113_1289, blk_1073742114_1290, blk_1073742115_1291, blk_1073742116_1292, blk_1073742117_1293, blk_1073742118_1294, blk_1073742119_1295, blk_1073742120_1296, blk_1073742121_1297, blk_1073742122_1298, blk_1073742123_1299, blk_1073742124_1300, blk_1073742125_1301, blk_1073742126_1302, blk_1073742127_1303, blk_1073742128_1304, blk_1073742129_1305, blk_1073742130_1306, blk_1073742131_1307, blk_1073742132_1308, blk_1073742133_1309, blk_1073742134_1310, blk_1073742135_1311, blk_1073742136_1312, blk_1073742137_1313, blk_1073742138_1314, blk_1073742139_1315, blk_1073742140_1316, blk_1073742141_1317, blk_1073742142_1318, blk_1073742143_1319, blk_1073742144_1320, blk_1073742145_1321, blk_1073742146_1322, blk_1073742147_1323, blk_1073742148_1324, blk_1073742149_1325, blk_1073742150_1326, blk_1073742151_1327, blk_1073742152_1328, blk_1073742153_1329, blk_1073742154_1330, blk_1073742155_1331, blk_1073742156_1332, blk_1073742157_1333, blk_1073742158_1334, blk_1073742159_1335, blk_1073742160_1336, blk_1073742161_1337, blk_1073742162_1338, blk_1073742163_1339, blk_1073742164_1340, blk_1073742165_1341, blk_1073742166_1342, blk_1073742167_1343, blk_1073742168_1344, blk_1073742169_1345, blk_1073742170_1346, blk_1073742171_1347, blk_1073742172_1348, blk_1073742173_1349, blk_1073742174_1350, blk_1073742175_1351, blk_1073742176_1352, blk_1073742177_1353, blk_1073742178_1354, blk_1073742179_1355, blk_1073742180_1356, blk_1073742181_1357, blk_1073742182_1358, blk_1073742183_1359, blk_1073742184_1360, blk_1073742185_1361, blk_1073742186_1362, blk_1073742187_1363, blk_1073742188_1364, blk_1073742189_1365, blk_1073742190_1366, blk_1073742191_1367, blk_1073742192_1368, blk_1073742193_1369, blk_1073742194_1370, blk_1073742195_1371, blk_1073742196_1372, blk_1073742197_1373, blk_1073742198_1374, blk_1073742199_1375, blk_1073742200_1376, blk_1073742201_1377, blk_1073742202_1378, blk_1073742203_1379, blk_1073742204_1380, blk_1073742205_1381, blk_1073742206_1382, blk_1073742207_1383, blk_1073742208_1384, blk_1073742209_1385, blk_1073742210_1386, blk_1073742211_1387, blk_1073742212_1388, blk_1073742213_1389, blk_1073742214_1390, blk_1073742215_1391, blk_1073742216_1392, blk_1073742217_1393, blk_1073742218_1394, blk_1073742219_1395, blk_1073742220_1396, blk_1073742221_1397, blk_1073742222_1398, blk_1073742223_1399, blk_1073742224_1400, blk_1073742225_1401, blk_1073742226_1402, blk_1073742227_1403, blk_1073742228_1404, blk_1073742229_1405, blk_1073742230_1406, blk_1073742231_1407, blk_1073742232_1408, blk_1073742233_1409, blk_1073742234_1410, blk_1073742235_1411, blk_1073742236_1412, blk_1073742237_1413, blk_1073742238_1414, blk_1073742239_1415, blk_1073742240_1416, blk_1073742241_1417, blk_1073742242_1418, blk_1073742243_1419, blk_1073742244_1420, blk_1073742245_1421, blk_1073742246_1422, blk_1073742247_1423, blk_1073742248_1424, blk_1073742249_1425, blk_1073742250_1426, blk_1073742251_1427, blk_1073742252_1428, blk_1073742253_1429, blk_1073742254_1430, blk_1073742255_1431, blk_1073742256_1432, blk_1073742257_1433, blk_1073742258_1434, blk_1073742259_1435, blk_1073742260_1436, blk_1073742261_1437, blk_1073742262_1438, blk_1073742263_1439, blk_1073742264_1440, blk_1073742265_1441, blk_1073742266_1442, blk_1073742267_1443, blk_1073742268_1444, blk_1073742269_1445, blk_1073742270_1446, blk_1073742271_1447, blk_1073742272_1448, blk_1073742273_1449, blk_1073742274_1450, blk_1073742275_1451, blk_1073742276_1452, blk_1073742277_1453, blk_1073742278_1454, blk_1073742279_1455, blk_1073742280_1456, blk_1073742281_1457, blk_1073742282_1458, blk_1073742283_1459, blk_1073742284_1460, blk_1073742285_1461, blk_1073742286_1462, blk_1073742287_1463, blk_1073742288_1464, blk_1073742289_1465, blk_1073742290_1466, blk_1073742291_1467, blk_1073742292_1468, blk_1073742293_1469, blk_1073742294_1470, blk_1073742295_1471, blk_1073742296_1472, blk_1073742297_1473, blk_1073742298_1474, blk_1073742299_1475, blk_1073742300_1476, blk_1073742301_1477, blk_1073742302_1478, blk_1073742303_1479]
2015-09-02 16:03:56,185 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:03:56,186 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:03:56,191 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:03:56,191 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:03:58,429 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:03:58,430 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:03:58,436 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:03:58,436 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:04:00,156 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:04:00,156 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:04:00,161 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:04:00,161 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:04:01,428 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:04:01,429 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:04:01,436 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:04:01,436 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:04:03,149 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:04:03,150 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:04:03,154 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:04:03,155 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:04:04,524 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:04:04,525 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:04:04,530 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:04:04,530 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:04:05,397 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:04:05,397 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:04:05,405 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:04:05,406 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:04:23,029 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:04:23,029 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:04:23,036 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:04:23,036 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:06:27,257 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:06:27,258 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:06:27,263 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:06:27,263 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:06:27,357 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:06:27,357 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:06:27,362 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:06:27,363 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:06:27,410 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:06:27,410 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:08:45,479 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 10 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 101 
2015-09-02 16:08:45,487 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742317_1493 127.0.0.1:50010 
2015-09-02 16:08:46,753 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742317_1493]
2015-09-02 16:08:56,855 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:08:56,855 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:08:56,860 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:08:56,860 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:09:15,886 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:09:15,886 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:09:15,891 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:09:15,891 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:09:22,570 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:09:22,571 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:09:22,576 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:09:22,576 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:09:55,689 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 11 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 6 SyncTimes(ms): 109 
2015-09-02 16:09:55,704 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742319_1495 127.0.0.1:50010 
2015-09-02 16:09:55,756 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 127.0.0.1:50010 to delete [blk_1073742319_1495]
2015-09-02 16:09:58,943 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:09:58,943 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:09:58,948 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:09:58,948 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:11:10,712 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 12 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 7 SyncTimes(ms): 124 
2015-09-02 16:11:10,776 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /testdata/file1._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742569_1745{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-09-02 16:11:10,908 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* checkFileProgress: blk_1073742569_1745{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} has not reached minimal replication 1
2015-09-02 16:11:10,909 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /testdata/file1._COPYING_ is closed by DFSClient_NONMAPREDUCE_-276625431_1
2015-09-02 16:11:10,909 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742569_1745{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 88
2015-09-02 16:11:11,333 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /testdata/file1._COPYING_ is closed by DFSClient_NONMAPREDUCE_-276625431_1
2015-09-02 16:11:20,376 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /testdata/file2._COPYING_. BP-1159783791-127.0.1.1-1436048545002 blk_1073742570_1746{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-09-02 16:11:20,478 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742570_1746{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-09-02 16:11:20,488 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /testdata/file2._COPYING_ is closed by DFSClient_NONMAPREDUCE_1559654624_1
2015-09-02 16:11:23,746 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:11:23,747 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:11:23,751 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:11:23,751 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:11:25,454 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:11:25,455 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:11:25,460 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:11:25,461 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:11:25,511 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:11:25,512 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:11:25,517 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:11:25,518 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:11:25,524 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:11:25,525 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:11:25,536 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:11:25,537 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:11:28,132 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:11:28,133 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:11:28,138 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:11:28,138 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:11:28,155 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:11:28,156 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:11:28,162 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:11:28,162 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:11:28,170 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:11:28,170 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:11:28,181 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:11:28,182 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:16:06,162 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 26 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 1 Number of syncs: 13 SyncTimes(ms): 194 
2015-09-02 16:16:06,833 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /dedup_out/_temporary/0/_temporary/attempt_local2020462120_0001_r_000000_0/part-r-00000. BP-1159783791-127.0.1.1-1436048545002 blk_1073742571_1747{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]}
2015-09-02 16:16:06,877 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blk_1073742571_1747{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:50010|RBW]]} size 0
2015-09-02 16:16:06,889 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /dedup_out/_temporary/0/_temporary/attempt_local2020462120_0001_r_000000_0/part-r-00000 is closed by DFSClient_NONMAPREDUCE_-1427654478_1
2015-09-02 16:16:06,961 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /dedup_out/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1427654478_1
2015-09-02 16:16:21,978 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:16:21,978 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:16:21,983 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:16:21,983 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:16:23,689 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:16:23,689 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:16:23,695 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:16:23,695 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:16:25,030 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:16:25,030 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:16:25,036 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:16:25,036 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:16:25,048 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:16:25,049 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:16:25,054 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:16:25,054 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:16:25,059 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:16:25,060 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:16:25,069 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:16:25,069 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:16:45,209 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: trying to get DT with no secret manager running
2015-09-02 16:16:45,225 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:16:45,225 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:16:45,230 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:16:45,230 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:16:46,640 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:16:46,640 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:16:46,645 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:16:46,646 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:16:48,447 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:16:48,448 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:16:48,456 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:16:48,456 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:16:48,511 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:16:48,511 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:16:48,518 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:16:48,518 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:16:48,523 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:16:48,523 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:16:48,532 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:16:48,532 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:17:45,361 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
2015-09-02 16:17:45,361 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-09-02 16:17:45,361 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 5103
2015-09-02 16:17:45,361 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 39 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 1 Number of syncs: 21 SyncTimes(ms): 303 
2015-09-02 16:17:45,374 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 39 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 1 Number of syncs: 22 SyncTimes(ms): 316 
2015-09-02 16:17:45,375 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/liyaohui/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000005103 -> /home/liyaohui/hadoop/tmp/dfs/name/current/edits_0000000000000005103-0000000000000005141
2015-09-02 16:17:45,375 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 5142
2015-09-02 16:17:45,583 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50090/getimage?getimage=1&txid=5141&storageInfo=-47:783537164:0:CID-cccbb85c-b641-4ac3-926e-6de5aa8f3b62
2015-09-02 16:17:45,623 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 300.00 KB/s
2015-09-02 16:17:45,623 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000005141 size 13109 bytes.
2015-09-02 16:17:45,655 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 5102
2015-09-02 16:17:45,655 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/liyaohui/hadoop/tmp/dfs/name/current/fsimage_0000000000000005100, cpktTxId=0000000000000005100)
2015-09-02 16:29:37,575 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:29:37,576 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:29:37,581 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:29:37,581 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:29:38,910 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:29:38,910 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:29:38,916 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:29:38,916 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:29:40,461 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:29:40,461 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:29:40,467 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:29:40,467 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:29:42,838 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:29:42,839 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:29:42,844 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:29:42,844 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:29:46,209 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:29:46,209 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:29:46,214 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(FSNamesystem.java:3875)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3864)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:737)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getListing(ClientNamenodeProtocolServerSideTranslatorPB.java:514)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59600)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:29:46,214 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:29:47,365 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:29:47,366 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:29:47,372 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:29:47,373 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:29:47,385 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:29:47,385 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:29:47,391 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:29:47,391 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:29:47,397 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:29:47,397 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:29:47,411 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:29:47,411 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:30:32,068 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3274)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:749)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59628)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:30:32,068 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:30:32,072 WARN org.apache.hadoop.security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user dr.who
org.apache.hadoop.util.Shell$ExitCodeException: id: dr.who: no such user

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:83)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:52)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:50)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:89)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1352)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.<init>(FSPermissionChecker.java:63)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getPermissionChecker(FSNamesystem.java:3099)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1471)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1428)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1402)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:468)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:269)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:59566)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2015-09-02 16:30:32,073 WARN org.apache.hadoop.security.UserGroupInformation: No groups available for user dr.who
2015-09-02 16:59:24,232 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2015-09-02 16:59:24,236 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ubuntu01/127.0.1.1
************************************************************/
